{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37c2fdb3-668d-446c-959f-b78e769e8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "391a358b-be9f-4412-964f-bb63d0230de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key= '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',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40aef282-107e-456f-b2c4-7b42614e7867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_datehour</th>\n",
       "      <th>pid</th>\n",
       "      <th>placename</th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>lat_lng</th>\n",
       "      <th>addr</th>\n",
       "      <th>hash_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-09 00</td>\n",
       "      <td>23467</td>\n",
       "      <td>CU</td>\n",
       "      <td>등촌원룸점</td>\n",
       "      <td>Convenience Store</td>\n",
       "      <td>37.5565109631,126.860730127</td>\n",
       "      <td>서울 강서구 등촌동 636</td>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-09 12</td>\n",
       "      <td>86057</td>\n",
       "      <td>서울9호선 증미역</td>\n",
       "      <td>종합운동장 방면 2-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>37.5580690136,126.860647984</td>\n",
       "      <td>서울 강서구 등촌동 666-40</td>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-09 12</td>\n",
       "      <td>86066</td>\n",
       "      <td>서울9호선 신목동역</td>\n",
       "      <td>종합운동장 방면 2-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>37.5441703286,126.88310042</td>\n",
       "      <td>서울 양천구 목동 138-19</td>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-12-09 13</td>\n",
       "      <td>208705</td>\n",
       "      <td>이맛콩나물국밥</td>\n",
       "      <td>삼성1호점</td>\n",
       "      <td>Korean Food Restaurants</td>\n",
       "      <td>37.5102950657,127.057353344</td>\n",
       "      <td>서울 강남구 삼성동 153-57</td>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-09 17</td>\n",
       "      <td>84592</td>\n",
       "      <td>서울9호선 봉은사역</td>\n",
       "      <td>개화 방면 2-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>37.5142419355,127.06028413</td>\n",
       "      <td>서울 강남구 삼성동 111-8</td>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773509</th>\n",
       "      <td>2018-01-02 08</td>\n",
       "      <td>218736</td>\n",
       "      <td>스타필드 코엑스몰점</td>\n",
       "      <td>/코즈니/준오헤어</td>\n",
       "      <td>Outlet/ Shopping Mall</td>\n",
       "      <td>37.5093729161,127.059693374</td>\n",
       "      <td>서울 강남구 삼성동 159-9</td>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773510</th>\n",
       "      <td>2018-01-02 11</td>\n",
       "      <td>255314</td>\n",
       "      <td>유명국양평해장국</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Korean Food Restaurants</td>\n",
       "      <td>37.5164864303,127.018625519</td>\n",
       "      <td>서울 서초구 잠원동 13-12</td>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773511</th>\n",
       "      <td>2018-01-03 15</td>\n",
       "      <td>218727</td>\n",
       "      <td>스타필드 코엑스몰점</td>\n",
       "      <td>/케리마켓/ANLE COFFEE</td>\n",
       "      <td>Outlet/ Shopping Mall</td>\n",
       "      <td>37.509522385,127.05979798</td>\n",
       "      <td>서울 강남구 삼성동 159-9</td>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773512</th>\n",
       "      <td>2018-01-04 15</td>\n",
       "      <td>88341</td>\n",
       "      <td>서울6호선 합정역</td>\n",
       "      <td>응암순환행 6-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>37.5489424459,126.913731247</td>\n",
       "      <td>서울 마포구 합정동 420</td>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773514</th>\n",
       "      <td>2018-01-04 16</td>\n",
       "      <td>9814</td>\n",
       "      <td>이마트 은평점</td>\n",
       "      <td>/비식품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>37.6005156078,126.920202412</td>\n",
       "      <td>서울 은평구 응암동 90-1</td>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       local_datehour     pid   placename                tag  \\\n",
       "2       2017-12-09 00   23467          CU              등촌원룸점   \n",
       "3       2017-12-09 12   86057   서울9호선 증미역       종합운동장 방면 2-4   \n",
       "4       2017-12-09 12   86066  서울9호선 신목동역       종합운동장 방면 2-4   \n",
       "5       2017-12-09 13  208705     이맛콩나물국밥              삼성1호점   \n",
       "6       2017-12-09 17   84592  서울9호선 봉은사역          개화 방면 2-4   \n",
       "...               ...     ...         ...                ...   \n",
       "773509  2018-01-02 08  218736  스타필드 코엑스몰점          /코즈니/준오헤어   \n",
       "773510  2018-01-02 11  255314    유명국양평해장국                NaN   \n",
       "773511  2018-01-03 15  218727  스타필드 코엑스몰점  /케리마켓/ANLE COFFEE   \n",
       "773512  2018-01-04 15   88341   서울6호선 합정역          응암순환행 6-4   \n",
       "773514  2018-01-04 16    9814     이마트 은평점               /비식품   \n",
       "\n",
       "                              cat                      lat_lng  \\\n",
       "2               Convenience Store  37.5565109631,126.860730127   \n",
       "3                  Subway Station  37.5580690136,126.860647984   \n",
       "4                  Subway Station   37.5441703286,126.88310042   \n",
       "5         Korean Food Restaurants  37.5102950657,127.057353344   \n",
       "6                  Subway Station   37.5142419355,127.06028413   \n",
       "...                           ...                          ...   \n",
       "773509      Outlet/ Shopping Mall  37.5093729161,127.059693374   \n",
       "773510    Korean Food Restaurants  37.5164864303,127.018625519   \n",
       "773511      Outlet/ Shopping Mall    37.509522385,127.05979798   \n",
       "773512             Subway Station  37.5489424459,126.913731247   \n",
       "773514  Discount Department Store  37.6005156078,126.920202412   \n",
       "\n",
       "                     addr                                      hash_uid  \n",
       "2          서울 강서구 등촌동 636  AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  \n",
       "3       서울 강서구 등촌동 666-40  AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  \n",
       "4        서울 양천구 목동 138-19  AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  \n",
       "5       서울 강남구 삼성동 153-57  AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  \n",
       "6        서울 강남구 삼성동 111-8  AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  \n",
       "...                   ...                                           ...  \n",
       "773509   서울 강남구 삼성동 159-9  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  \n",
       "773510   서울 서초구 잠원동 13-12  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  \n",
       "773511   서울 강남구 삼성동 159-9  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  \n",
       "773512     서울 마포구 합정동 420  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  \n",
       "773514    서울 은평구 응암동 90-1  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  \n",
       "\n",
       "[614401 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./sample_data_coex_visitors_visits_20171201_20180105.csv', sep=',', skiprows = 3)\n",
    "data = data[~data['addr'].isnull()]\n",
    "data = data[data['addr'].str.contains('서울')]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7fb4fc6-bd4e-4484-8b40-1f430679434a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_category</th>\n",
       "      <th>place_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>00</td>\n",
       "      <td>CU 등촌원룸점</td>\n",
       "      <td>Convenience Store</td>\n",
       "      <td>서울 강서구 등촌동 636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>12</td>\n",
       "      <td>서울9호선 증미역 종합운동장 방면 2-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>서울 강서구 등촌동 666-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>12</td>\n",
       "      <td>서울9호선 신목동역 종합운동장 방면 2-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>서울 양천구 목동 138-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>13</td>\n",
       "      <td>이맛콩나물국밥 삼성1호점</td>\n",
       "      <td>Korean Food Restaurants</td>\n",
       "      <td>서울 강남구 삼성동 153-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>17</td>\n",
       "      <td>서울9호선 봉은사역 개화 방면 2-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>서울 강남구 삼성동 111-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614396</th>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>08</td>\n",
       "      <td>스타필드 코엑스몰점 /코즈니/준오헤어</td>\n",
       "      <td>Outlet/ Shopping Mall</td>\n",
       "      <td>서울 강남구 삼성동 159-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614397</th>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>유명국양평해장국</td>\n",
       "      <td>Korean Food Restaurants</td>\n",
       "      <td>서울 서초구 잠원동 13-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614398</th>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>15</td>\n",
       "      <td>스타필드 코엑스몰점 /케리마켓/ANLE COFFEE</td>\n",
       "      <td>Outlet/ Shopping Mall</td>\n",
       "      <td>서울 강남구 삼성동 159-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614399</th>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15</td>\n",
       "      <td>서울6호선 합정역 응암순환행 6-4</td>\n",
       "      <td>Subway Station</td>\n",
       "      <td>서울 마포구 합정동 420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614400</th>\n",
       "      <td>//kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16</td>\n",
       "      <td>이마트 은평점 /비식품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 은평구 응암동 90-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hash_uid        date hour  \\\n",
       "0       AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  2017-12-09   00   \n",
       "1       AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  2017-12-09   12   \n",
       "2       AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  2017-12-09   12   \n",
       "3       AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  2017-12-09   13   \n",
       "4       AACepmlRCBduWs47hBiedMwYEXaoAdQfQ+gZuNjcJnE=  2017-12-09   17   \n",
       "...                                              ...         ...  ...   \n",
       "614396  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  2018-01-02   08   \n",
       "614397  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  2018-01-02   11   \n",
       "614398  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  2018-01-03   15   \n",
       "614399  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  2018-01-04   15   \n",
       "614400  //kIAIl1UY8yg6bTw21m0ubi1fOG1jVal7Z8FDQv19o=  2018-01-04   16   \n",
       "\n",
       "                          place_name             place_category  \\\n",
       "0                           CU 등촌원룸점          Convenience Store   \n",
       "1             서울9호선 증미역 종합운동장 방면 2-4             Subway Station   \n",
       "2            서울9호선 신목동역 종합운동장 방면 2-4             Subway Station   \n",
       "3                      이맛콩나물국밥 삼성1호점    Korean Food Restaurants   \n",
       "4               서울9호선 봉은사역 개화 방면 2-4             Subway Station   \n",
       "...                              ...                        ...   \n",
       "614396          스타필드 코엑스몰점 /코즈니/준오헤어      Outlet/ Shopping Mall   \n",
       "614397                      유명국양평해장국    Korean Food Restaurants   \n",
       "614398  스타필드 코엑스몰점 /케리마켓/ANLE COFFEE      Outlet/ Shopping Mall   \n",
       "614399           서울6호선 합정역 응암순환행 6-4             Subway Station   \n",
       "614400                  이마트 은평점 /비식품  Discount Department Store   \n",
       "\n",
       "            place_address  \n",
       "0          서울 강서구 등촌동 636  \n",
       "1       서울 강서구 등촌동 666-40  \n",
       "2        서울 양천구 목동 138-19  \n",
       "3       서울 강남구 삼성동 153-57  \n",
       "4        서울 강남구 삼성동 111-8  \n",
       "...                   ...  \n",
       "614396   서울 강남구 삼성동 159-9  \n",
       "614397   서울 서초구 잠원동 13-12  \n",
       "614398   서울 강남구 삼성동 159-9  \n",
       "614399     서울 마포구 합정동 420  \n",
       "614400    서울 은평구 응암동 90-1  \n",
       "\n",
       "[614401 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame()\n",
    "new_data['hash_uid'] = data['hash_uid']\n",
    "# new_data['date'] = pd.to_datetime(data['local_datehour'], format='%Y-%m-%d %H').dt.date\n",
    "# new_data['hour'] = pd.to_datetime(data['local_datehour'], format='%Y-%m-%d %H').dt.hour\n",
    "new_data['date'] = data['local_datehour'].str.split(\" \", expand = True)[0]\n",
    "new_data['hour'] = data['local_datehour'].str.split(\" \", expand = True)[1]\n",
    "new_data['place_name']= data['placename'] + ' ' + data['tag'].fillna('')\n",
    "new_data['place_name'] = new_data['place_name'].str.strip()\n",
    "new_data['place_category'] = data['cat']\n",
    "new_data['place_address'] = data['addr']\n",
    "\n",
    "new_data.reset_index(inplace=True, drop=True)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac2c6ab2-c2d4-4c9e-953c-718f2ac24dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_category</th>\n",
       "      <th>place_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hash_uid, date, hour, place_name, place_category, place_address]\n",
       "Index: []"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[new_data['place_name'] == '주경야돈 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7052a98-e1b4-4f9a-85e8-586b27481681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_category</th>\n",
       "      <th>place_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82906</th>\n",
       "      <td>ItQumMfHat6KAn+djAmQ/A904B8ao4ufcvJsQnKmKyM=</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>00</td>\n",
       "      <td>주경야돈</td>\n",
       "      <td>Others(Restaurants)</td>\n",
       "      <td>서울 광진구 화양동 17-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           hash_uid        date hour  \\\n",
       "82906  ItQumMfHat6KAn+djAmQ/A904B8ao4ufcvJsQnKmKyM=  2017-12-29   00   \n",
       "\n",
       "      place_name       place_category    place_address  \n",
       "82906       주경야돈  Others(Restaurants)  서울 광진구 화양동 17-5  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[new_data['place_name'] == '주경야돈']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bea3b3-3da7-432b-842d-cadf5f970b20",
   "metadata": {},
   "source": [
    "<font size = \"5\">DFLoader</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0433b33d-35ba-4836-934f-2d6205982275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfloader(df):\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    loaderformat = \"pd.DataFrame({\" + \"\\n\" + \"\\t\" \\\n",
    "                    + \"date : \" + str(df['date'].tolist()) + \",\" + \"\\n\" + \"\\t\" \\\n",
    "                    + \"hour : \" + str(df['hour'].tolist()) + \",\" + \"\\n\" + \"\\t\" \\\n",
    "                    + \"place_name : \" + str(df['place_name'].tolist()) + \",\" + \"\\n\" + \"\\t\" \\\n",
    "                    + \"place_category : \" + str(df['place_category'].tolist()) + \",\" + \"\\n\" + \"\\t\" \\\n",
    "                    + \"place_address : \" + str(df['place_address'].tolist()) + \",\" + \"\\n\" + \"\\t\" \\\n",
    "                    + \"index : \" + str(df.index.tolist()) + \",\" + \"\\n\" + \"\\t\" + \")\"\n",
    "    \n",
    "    return loaderformat\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7390e80e-ed07-4aaf-b2c8-8a4ad333efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfloader_wont(df):\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    loaderformat = \"pd.DataFrame({\" \\\n",
    "                    + \"date : \" + str(df['date'].tolist()) + \",\" \\\n",
    "                    + \"hour : \" + str(df['hour'].tolist()) + \",\" \\\n",
    "                    + \"place_name : \" + str(df['place_name'].tolist()) + \",\" \\\n",
    "                    + \"place_category : \" + str(df['place_category'].tolist()) + \",\" \\\n",
    "                    + \"place_address : \" + str(df['place_address'].tolist()) + \",\" \\\n",
    "                    + \"index : \" + str(df.index.tolist()) + \",\" + \")\"\n",
    "    \n",
    "    return loaderformat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8670e-d85c-4bfd-a652-cb1cdc0bb6f6",
   "metadata": {},
   "source": [
    "<font size = \"5\">JSON</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6013d54-1825-45bf-9f84-2f715aa915c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json(df):\n",
    "\n",
    "    jsonformat = \"{\" + \"\\n\" + \"\\t\"\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        jsonformat += \"\\\"\" + str(i) + \"\\\":{\" \\\n",
    "                    + \"\\\"date\\\":\\\"\" + str(df.iloc[i,0]) +\"\\\",\\\"hour\\\":\\\"\" + str(df.iloc[i,1]) \\\n",
    "                    + \"\\\"place_name\\\":\\\"\" + str(df.iloc[i,2]) +\"\\\",\\\"place_category\\\":\\\"\" + str(df.iloc[i,3]) \\\n",
    "                    + \"\\\"place_address\\\":\\\"\" + str(df.iloc[i,4]) + \"\\\"}\"\n",
    "        \n",
    "        if i != len(df) - 1:\n",
    "            jsonformat += \",\" + \"\\n\" + \"\\t\"\n",
    "            \n",
    "    jsonformat += \"\\n\" + \"}\"\n",
    "\n",
    "    return jsonformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aafaea3d-2628-4925-bf95-3121d8ba4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_wont(df):\n",
    "\n",
    "    jsonformat = \"{\"\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        jsonformat += \"\\\"\" + str(i) + \"\\\":{\" \\\n",
    "                    + \"\\\"date\\\":\\\"\" + str(df.iloc[i,0]) +\"\\\",\\\"hour\\\":\\\"\" + str(df.iloc[i,1]) \\\n",
    "                    + \"\\\"place_name\\\":\\\"\" + str(df.iloc[i,2]) +\"\\\",\\\"place_category\\\":\\\"\" + str(df.iloc[i,3]) \\\n",
    "                    + \"\\\"place_address\\\":\\\"\" + str(df.iloc[i,4]) + \"\\\"}\"\n",
    "        \n",
    "        if i != len(df) - 1:\n",
    "            jsonformat += \",\"\n",
    "            \n",
    "    jsonformat += \"}\"\n",
    "\n",
    "    return jsonformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed60766-0d0c-4438-a86b-1e248ddbbd80",
   "metadata": {},
   "source": [
    "<font size = \"5\">Tab Separated</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02945b36-f3e1-4f4d-8c93-4dbd1e7b4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabsep(df):\n",
    "    \n",
    "    commaformat = re.sub('  +', ',', df.to_string())\n",
    "    commaformat = re.sub('date hour', 'date,hour', commaformat)\n",
    "    tabformat = re.sub(',', '\\t', commaformat)\n",
    "    \n",
    "    # tabformat = 'index' + re.sub('  +', '\\t', df.to_string())\n",
    "    # tabformat = re.sub('  +', '\\t', df.to_string())\n",
    "    # tabformat = re.sub('date hour', 'date' + '\\t' + '\\t' + 'hour', tabformat)\n",
    "\n",
    "    return tabformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8bbb0-f934-4562-9937-1e0d2e8e5664",
   "metadata": {},
   "source": [
    "<font size = \"5\">Comma Separated</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "522f1fb7-63da-4b2a-9661-8fc854e2782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commasep(df):\n",
    "    \n",
    "    # commaformat = 'index' + re.sub('  +', ',', df.to_string())\n",
    "    commaformat = re.sub('  +', ',', df.to_string())\n",
    "    commaformat = re.sub('date hour', 'date,hour', commaformat)\n",
    "\n",
    "    return commaformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdae0f5-c649-49d8-9bd2-873e093dfb20",
   "metadata": {},
   "source": [
    "<font size = \"5\">ToText</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "949631ae-58b2-44f5-b9e3-124a21f66679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totext(dataframe):\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    df = df.sort_values(by=['date', 'hour'])\n",
    "\n",
    "    # result = \"A person's visit history from \" + df.loc[0, 'date'][5:10] + df.loc[0, 'date'][4] + df.loc[0, 'date'][0:4] \\\n",
    "    #    + \" to \" + df.loc[len(df) - 1, 'date'][5:10] + df.loc[len(df) - 1, 'date'][4] + df.loc[len(df) - 1, 'date'][0:4] + \" is as follows:\\n\"\n",
    "    \n",
    "    result = \"A person's visit history from \" + df.loc[0, 'date'][0:10] + \" to \" + df.loc[len(df) - 1, 'date'][0:10] + \" is as follows: \\n \" \n",
    "     \n",
    "    # result = \"A person's visit history from \" + str(df.loc[0, 'date'].month) + \"-\" + str(df.loc[0, 'date'].day) + \"-\" + str(df.loc[0, 'date'].year) \\\n",
    "    #    + \" to \" + str(df.loc[len(df) - 1, 'date'].month) + \"-\" + str(df.loc[len(df) - 1, 'date'].day) + \"-\" + str(df.loc[len(df) - 1, 'date'].year) + \" is as follows:\\n\"\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        irow = df.iloc[i, :]\n",
    "\n",
    "        if irow['place_name'][-1] == \" \":\n",
    "            pn = str(irow['place_name'][:-1])\n",
    "        else:\n",
    "            pn = str(irow['place_name'])\n",
    "\n",
    "        if i == 0:\n",
    "            result += \"The person visited \" + pn + \", which is a\" + irow['place_category'].lower() + \"located at \" +  \\\n",
    "                        irow['place_address'] + \", at \" + str(irow['hour']) + \" on \" + irow['date'][0:10]\n",
    "            \n",
    "        elif i == len(df) - 1:\n",
    "            result += \", and \" + pn + \", which is a\" + irow['place_category'].lower() + \"located at \" + \\\n",
    "                        irow['place_address'] + \", at \" + str(irow['hour']) + \" on \" + irow['date'][0:10] + \".\"\n",
    "            \n",
    "        else:\n",
    "            result += \", \" + pn + \", which is a\" + irow['place_category'].lower() + \"located at \" + \\\n",
    "                        irow['place_address'] + \" at \" + str(irow['hour']) + \" on \" + irow['date'][0:10]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3230c7-184c-458b-8dec-814b2424bc6c",
   "metadata": {},
   "source": [
    "<font size = \"5\">ToTextVisited</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0760732-e039-48c2-a54f-30093ff470ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totextvisited(dataframe):\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    df = df.sort_values(by = ['date', 'hour'])\n",
    "\n",
    "    result = \"A person's visit history from \" + df.loc[0, 'date'][0:10] \\\n",
    "          + \" to \" + df.loc[len(df) - 1, 'date'][0:10] + \" is as follows: \\n \"\n",
    "\n",
    "    \n",
    "    visited = {}\n",
    "    visitedcataddr = {}\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        irow = df.iloc[i, :]\n",
    "        \n",
    "        \n",
    "        if irow['place_name'][-1] == \" \":\n",
    "        \n",
    "            pn = str(irow['place_name'][:-1])\n",
    "\n",
    "        else:\n",
    "            pn = str(irow['place_name'])\n",
    "\n",
    "\n",
    "        \n",
    "        if pn in visited.keys():      \n",
    "            visited[pn] += \", at \" + str(irow['hour']) + \" on \" + irow['date'][0:10]\n",
    "            \n",
    "        elif pn not in visited.keys():\n",
    "            visited.update({pn : \" at \" + str(irow['hour']) + \" on \" + irow['date'][0:10]})\n",
    "            visitedcataddr.update({pn : [irow['place_category'].lower(), irow['place_address']]})\n",
    "            \n",
    "\n",
    "    result += \"The person visited\"\n",
    "    for key, value in visited.items():\n",
    "        if key == list(visited.keys())[-1]:\n",
    "            result += \" \" + key + \", which is a\" + visitedcataddr[key][0] \\\n",
    "                    + \" located at \" + visitedcataddr[key][1] + \",\" + value + \".\"\n",
    "        else:\n",
    "            result += \" \" + key + \", which is a\" + visitedcataddr[key][0] \\\n",
    "                    + \" located at \" + visitedcataddr[key][1] + \",\" + value + \",\"\n",
    "                \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa88cb8-60f3-4705-85ab-ca8ee8a71f62",
   "metadata": {},
   "source": [
    "<font size = \"5\">GPT_API</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b016e986-52e9-44ce-a10b-c3facfa85c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_api(system_prompt, user_prompt, user_log, model=\"gpt-3.5-turbo-0613\", verbose=False):\n",
    "\n",
    "    user_prompt += '\\n' + user_log\n",
    "    \n",
    "    if verbose:\n",
    "      print(user_prompt)\n",
    "\n",
    "    messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt}, \n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "    token = response.usage.total_tokens\n",
    "    \n",
    "    # print('answer : ', output)\n",
    "    # print('token : ', token)\n",
    "\n",
    "    return output, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b4c88cc-e4f6-4cac-af35-b9a7d78f11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_50plus = new_data['hash_uid'].value_counts()[new_data['hash_uid'].value_counts().values>=50].index\n",
    "select_user_50plus = [user_50plus[i] for i in random.sample(range(0, len(user_50plus)), 500)]\n",
    "\n",
    "log_number = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "515d4147-8224-46e9-a24e-c0477c83e3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qtm4hnBRbwHiD0hFHe38J144UpHVVcjthsvf7Y8yYKE=',\n",
       " 'VTBhDccU48aucC3ri8x/JkI67UcAg7Lvb6ggOnB/7f8=',\n",
       " 'FsLabIlJz3HG0Nvr6bCSq/xhudIAxjMr4/GMFIFF/CM=',\n",
       " 'D0R41t6y0vIt8eSSF9m16jIbc5CyKDOI4+FdhVFZw3M=',\n",
       " '69v2eIbCvURvdNjwak82OyrGSmJaM6QFFo46friqRkM=',\n",
       " '+cK9JNQ5rhR2ioY0VpXIErOyOutl2JCdhfq8vzNn7wk=',\n",
       " 'gu4GbGs8CbA7pMOXyC/JTkkPc39pgOQEZ9bh56AgE5Y=',\n",
       " 'ytRnWIq3erTJC1BUtKTBoTYLjnxd6XcPRZK1TLQGufg=',\n",
       " 'Z1Dh9+/xB2M/cBT9kR9mldof+bhhijDDjqVDdf1PdCw=',\n",
       " 'myYXHncZFsXHPjlIXemna+CR8c1kmobEG7A6cpO4zxg=',\n",
       " '12AYwnaN8N0zQD1Xl0v+NnwNvBZjUrh3Xb4AqT5PnJk=',\n",
       " 'cPqbGQ50QuSguC7KGSYkbo3VODNXkLWhVDRNcD2QWAM=',\n",
       " 'X1CNjarRJvAEpEqlF5Uf8UQvoBB2V6xsZlxVqZzciyY=',\n",
       " '3Y1Ft4Ir1h02mW7Qt8KmfqUMb7nvq+esAxgSZlCTaWU=',\n",
       " 'sSSQjiOvKGaV5JRSbeunfROzMxOCeIuwA8CZQzvTcHM=',\n",
       " 'F8Oc1PMteyKANIfw7/JeFNE6mXyuEg7AIgNHhiApEa4=',\n",
       " 'PeANng/8La8Wmd1qHWHTDk7QU9RvGzhxTqIKCNXXP78=',\n",
       " 'SOrDmwL+70A0LGE183uhwd/lcEPUF03UkL1l5h4wruA=',\n",
       " '81rib4jcN2G9o3Hc+AMYqYn7t2xI49jGTbXP8b/Xs8k=',\n",
       " 'VCtpDFAlazRW+HJ/Mo3z9q/6Cyz9fEZarw2aNA3eh8A=',\n",
       " 'tMHZIKR8Px9WUtAnIoQKakPjir+CPtZiMw7BawIpoaY=',\n",
       " '1Tag5pLMWA/gmU3KdV0UXzvw0F7L6jc/OCAUtvrApd4=',\n",
       " 'tuJDOUIP686tkHdYSjGl51HSY4DmAW/+c3EWXiS9O1Q=',\n",
       " 'SS2Vox7z/zISL+n/IZkWV6sYiKwFNNAl5bLTAM9jMsM=',\n",
       " '5U0np8rKr7J5SR4NgfW2CEA1ZVQ5zqZvFlcIiYYsExQ=',\n",
       " 'dgYIoQbUGS39BQAzxk1vozRx5Qw5YEwXAgv7thYF3+4=',\n",
       " '6EfeEjtcqz3+qFFCJg0QULmvhjlVs8/IyEBpc7W5uww=',\n",
       " 'Z5TTHM7zxO2VMdIezZo/5E3+yrQxTl9vdttTvr4lW/g=',\n",
       " 'tpGmOBdIycC3463y4RBgm2FfcEWhFoJndlD6D8mmEcc=',\n",
       " 'UmrzhQ1zjmxADFWM6YHIL5OgUIhZvAMOHk1DqzZjB1o=',\n",
       " '7HsJ81pcNTM/DoyIUezrY8I7gsofvuZpSBFgwKoezg8=',\n",
       " 'gFEiEge/i/sR1k4ZP3E4j9iTkOy1tJytNLJG267wkpg=',\n",
       " 'U74bCgi1iaji0197RLugvAG851Cu/rvY+2YUxf+F4gM=',\n",
       " 'EPzuULSPQ6wFkWsprUtkVhzMFLtF4dCc7SeSGfKR86o=',\n",
       " 'uaXe1CpdEG71Bh655WB2x1LNrf/Enz/xyzenlOZvJ3c=',\n",
       " 'i/5kFxcryKZWy7PxwVvdOiPIUd6oxPzdZYo44XFm0dc=',\n",
       " 'sIW076HjaVi9ggz5u/MJA8jWa0lhYqVmwrX4VdhzK74=',\n",
       " 'WccO/NUBO1PtpQWDbqXgYWEBgu05sZHgmjxXBq7RaTY=',\n",
       " '1gltRUij1cHrBxCvvq2Jw/6lEPJzhbo4zC9hnnikM6E=',\n",
       " '28+MADJlnYcOqV+mV3oysb5VGQCBdeyRukmArvH8fbs=',\n",
       " '7zv8gdhWFmovjAg4UMEYJKqFtpXihHm5axvar/xHz5I=',\n",
       " '2P5nAXDH8yjz8qNKvGuq7qDbw3tHXfkwTF4hdbQ7W3A=',\n",
       " 'xpl91uesm5LMoX6NMelsbGPBLWHXTKgmnuJCGojbFU0=',\n",
       " '85GcoQpPyOzjSG2QS1syzt+B4vbxmcklJVK61cSWL2g=',\n",
       " 'vXLeg9LXp1A16umQnWrStdKw3hmDiIY48IJf9RwsZps=',\n",
       " 'ysQ9XjDg17PURldyPDBjNpBKzU6EIOuXcEmNt0FwGw4=',\n",
       " 'y0QCnxKT8Ys5n2FCw0AoGttKOHf1+9FUSW4VqkZgEpA=',\n",
       " 'TRjrf6fJ6s0HTiVimYr6zFNsLTHHflEbZ7EyCh079ZI=',\n",
       " 'GDY5QcUHcv6cl7zsr/TbUvmk80Tcj5TBfXQoFRJdCWY=',\n",
       " '2ss2QtObkiYJ8ec2jjjOckegWxrDk9oFFnemoF6MnAs=',\n",
       " 'LSVsu0aBR4pV7sffrCHtdbNlIRVVROp3CqKQEuV4Umw=',\n",
       " 'X86vQ4xTq0a5t9E7WffZdTLJx8zTabc2IUd0aV1yu28=',\n",
       " 'CyOVD876fAvz9XLDVo2w30w//Dhrabxw/1ss21qxzu4=',\n",
       " '/MjrxcV1EUFREX50EPRQ5kim9AwKqa7laslQ5DpBwpw=',\n",
       " 'bVvU0kFpzXAPhJduMhBwV41f/SM9HbrpW1cIB6dxF3c=',\n",
       " 'g5z8pH0Y6lbPvagXEtkeZ1RwAyuRn9n9/VatHYJeZpI=',\n",
       " '8oUMlDRIzh8x15fu22DA45aNlJrSCQVZsPHRZ9ZCGEU=',\n",
       " 'ZIvn9zFrvgj4DtEvqTN+o7N9Uy7QFNwYECq/fXi/wAI=',\n",
       " '/NEhg9xQ5El0AgekzBWeDCzoIgZCHvjjSWya07j86lM=',\n",
       " 'WgjqRj+hqhBP1xTi8NBhCryAbeXU8KkINEncISUqNZs=',\n",
       " 'WngdMaBVaN9OfACvGU3Zm9QzduRWpTl9HVDoSh1eD5g=',\n",
       " 'l9gL5Gzt3Opy8HsSJw0fIbEG9wqPdzL+zTSZdUBJWCo=',\n",
       " 'wwxCiiUqwEVK0jLYs2+opRrY+WjgyaQXkX1Kfu7QvbE=',\n",
       " 'WnKTnXB631psJ3TE/lmZj39UeEhyp7HdtX1uXdfoENE=',\n",
       " 'EcVNQyn22Lc3J+WyWyuV53dpYmYiPp6p1WqBVjQG82w=',\n",
       " 'ag8Aj3QjW5rUWNdO4RRXEII6DHflVK6dbJM/wWu8zQo=',\n",
       " '02qPkNjLDG8xB/+KrD6OJOTruPTT1blyE3No6RbSevE=',\n",
       " 'CB1wWuPsll+ssOY8SqJ2oes979eByW8+Gl2yLnqYlKM=',\n",
       " 'M1Lpo+YaDnwArB6FAXCey+16K3Ghe7e+Q0KAEdxMS5Q=',\n",
       " '7y83Nm5f03JHJkioBbg1JcTOHdC4vj8mMzGJMgMfKik=',\n",
       " 'FyXGzMJZV1jiIRJyXmuoJ2Vd2raLubJ+zOU15ilpXZ8=',\n",
       " 'WM42t+5ajZQI1IG2NA34rk2ZT0Y1jWqsUbvBwvV+Y9E=',\n",
       " 'yus4x75vRPVxYuYgpq91VIHVVeVWD+F6coybwli7Gh0=',\n",
       " '5lLt1RKzmXD7T3b4UZlJDw5pf7BPlOXkNUeHgaT0Iko=',\n",
       " 'KxNKGgOmWeqIA8/GDi79yHg4gBa6IoZWsFz+94OaLsU=',\n",
       " '7VmfvsLarATp3jCyuRtpyNq2RkBk44G3I1Oh5cJq7aQ=',\n",
       " 'S7RSObkNPC7O1ffelMX2+1g6mUCIgcalhHQCqIdl3XA=',\n",
       " 'FuELv+5nWA+cXm3XLDEa2VpdGP1MMBZ9w+UTh7bKsaY=',\n",
       " 'b+aUVfNmdVO+rauzFslE4LkQUKyDzasJE5YKX2b5rWo=',\n",
       " 'Gnzq446DzCuvQRfL2wAMp2YUY9qvywUF2t+YmdUHRz8=',\n",
       " 'z12mhjuKQCALKIy43rEnTiIu2qdn6UPx90iq7y/kELI=',\n",
       " 'zQ6a4KKPHOdY+9pePhoZuOLFZ8VjIOo/li7VJFkQfZo=',\n",
       " 'PTNtJ+Gpxi5kSZ1xB5nXS8GVoqUI/Cf7ytgthHEuSoI=',\n",
       " 'XhJNbNEz1xWIePzMGmh7ADIm5BANX5h/OM20xvm6Bnw=',\n",
       " 's3Gvd68rIrgi0TevWgxJont/2pi9vXb8D2l1QuoIwrI=',\n",
       " 'wPRng+fp7NmRu3BjCSCePvKUbnScMaO7b7UPrdFzIL0=',\n",
       " 'HFVJPbfWi8/pO9zPzTouf4GzmZ4tgzskwfNrhh/9/Xg=',\n",
       " 'dxRHUI3+TWJI2Ri+inLQtTVfohiIw9nBX0hOnLjsrQk=',\n",
       " 'xrTimbZVc/5UZVAPu5PANQQ+phDZfoXvKs1f6qGkZ1c=',\n",
       " '7+tJeX1VbUb8hwzcKfhE5cTxav8oQ+dX+5hwaFi/5rc=',\n",
       " 'MoMPaSSZGESUgyM2IKA+p0V1TfZBsiiHGgO4ygMVfjk=',\n",
       " 'KH53yi9lySwx+Zl2jR9g9R9kuhLn9zB96TkqHLegCqA=',\n",
       " 'AiyLJQvZ/PIkRasjIpK7FvKDDzAIDEWIHyiyq27Bnb4=',\n",
       " 'cOoikkV9VZ9wzEn1s1JZbAKaYzzVvM/kukxO/Ca3DO0=',\n",
       " 'VDS/wi00l3YwtKCgiX7Y0hHA654EspLoJ3Bny3215+o=',\n",
       " 'k3P7dkf5PNmUFtpEnYabJNg+VYLlcS5GTs0A3pQM66A=',\n",
       " 'Aw6Wcsh847jpFRv4dNx4vwxAelLM75+LW9M7IvlbY/U=',\n",
       " 'GyiVoNhKqFKTTgjMrBfqtNs7htrlp//kc29JK1WLOdA=',\n",
       " 'QjDr4ZfaTI4VnIPYwwsmfQF4GiXg10+FgKeC529ZWGw=',\n",
       " 'MKr0StR6T3d0o45j4UXOiPnLi19Fhl9VPNfJanxDKBA=',\n",
       " 'xKAo78TLtABkxObyzrmxBuAwpMtKUfPq0eCeNDVXLZ8=',\n",
       " '05J1InzmlnC3rbHbNZn7ACtfGe5u/q8LCE7xZmaEQbk=',\n",
       " 'e+uwB4fgx4NscLVF1yVT729yBw+c1VfMA5IzMfLOuY8=',\n",
       " '5opPPJwktF/e4PZmA/r7BrWo7vyDqoPVr3dyyeu7ddQ=',\n",
       " 'z7x7r2GdFKohj8aFebBtufWEKsthmtjNF+SnwcZvFEU=',\n",
       " 'Ft/9uepjaKGSbF4MhQlGljJ30tk0z94oBmYssjPTgX8=',\n",
       " 'XgSeyjYBipjezxOFS35EToFzUhPIF+id282YSCToj30=',\n",
       " 'kpZInsD9XYLnWAy3uvrFvKzJGfjEN6uPgA3EQnJw/ME=',\n",
       " 'vp/O+dXGUoM9uzqQVCIN0y5VBL5HIDjfiY5KXCKhBE8=',\n",
       " 'Kz4Gtq2MeebUaEDDwIL6A+vSuz5Whv/j9kFw+swGOew=',\n",
       " 'V6iCHlSXmz2EVPWJkBbDxzN63CobQ0quuiq0X9fVLvE=',\n",
       " 'tu/bgMik+dL+aegdh+beapWKRrH3rixXHtkFuZT2zbQ=',\n",
       " 'SG8Z68jVrGhyIo4IcLxx8kNynOQNZjwa1orw2rUK8Ag=',\n",
       " 'FLeEvO4+aAlyVsuXh9fk839NYt4om7/zdAOBVCj8mhs=',\n",
       " '25ZctleUGHKF7u+KcVbI5lM67jl2XewQ5kbABP+dE5A=',\n",
       " '9Yjp3vHGOzLy1mrkw2xRJBz+DwkCKgL8+R7E8oeoy9c=',\n",
       " 'RN2db52p50lIqredOtgg2Xn5dLxdgnINDSAXihcJ+og=',\n",
       " 'ofQ+hmNGcvIAyb3/Xgewf4R6vbKeNCvK5z3lFzMMiVM=',\n",
       " 'KV1u/MI8EYGFd/EEl76Ep4F8wqBxHcbDeoVwRYn0e9M=',\n",
       " 'gbBxk+bMr3ljLVIuy7yK2keB0nQnoaFbi4whUIv0W2w=',\n",
       " 'diVtjfFQziJIA0ErjVzgxvECWh4QP7/zM6GVd3WA3NE=',\n",
       " '4KCv1Tuf/pcOMn3QxiBms15LAIquwU57gz3DlaRHZsU=',\n",
       " 'Aug+N9Uk74yox1tRN1c5W+rNRk9NX16KPdcgixZWCm0=',\n",
       " 'fQ97wJ6thqOQjLLh6Qnc4qFD9p2MLTbfbvAvtOiC1sI=',\n",
       " 'QLpTmcYBuBePDlrxeO8EfqrdjRYySScyiJNzI7jTpA8=',\n",
       " 'XBGZJ6ITjRM/OZOgn1ShnEklbaQah1E7YO59SlP3UiE=',\n",
       " 'zYfAJdIbGvQ4trPUkkkAOT7UUZDHMgJt2OLm89t0BNE=',\n",
       " 'qRjcLAsTB7haejIdrhyYbZo5M6roPkm1t6EHbeLYnGs=',\n",
       " '/PX3C4qTW3g6kyQnWqW/PbNDtqEiv2irx3YhD1DQ/8Q=',\n",
       " '2AvcwZxflKX5ZiXEWRMSHx2FIgoDEAZJ6u6LRBczyhQ=',\n",
       " 'IxzZkHyWftjBNCGsSnfaaXOsmd3N0C45cVGcecaBx6g=',\n",
       " 'NEuaazqJfJWckaEx/AX6FZS3giSCiqcM3CsbZ7HzM8o=',\n",
       " 'zRwjJTK3pbkuVXyjsuHLTdS+S5fzvraui3ML0HCBaZA=',\n",
       " 'sgG3sjU70WMLEB4zXqY52BpJbnpEILqiQxUOVf3GInM=',\n",
       " '6wO2h5QNoz6VCOhJ1VWHL6s95c2w4GTGI8rxBRd6mL4=',\n",
       " '7kgr6qLoanejSoOJhxOl8khH2DyLfjVv9BAJBPcmwb8=',\n",
       " 'LFqcF9hhCAgqkc21v5l9cmkH3nctdLljKVlqjYuCIgA=',\n",
       " 'TF45nXsos7/uxWQ2tT1WAOaS1tE+6yObCYBVMEhN1w4=',\n",
       " 'BPGd7DJChmLmOaYofS+pcOgmQHqqrU4bd9QjjgnHpgU=',\n",
       " '4dYlOZCOudHTLfcjhFFj0tvgl2KS60oA7ODfkC1DDtQ=',\n",
       " 'SNdMf1EQ7eZT5RBXd2j8BDY56CS4HAA9flbyP939DM8=',\n",
       " 'LsTOpjmV9BKbQX0HqBB50awFUOLafN4p6tFb6ZZ2hkk=',\n",
       " 'NBSaalgYvExiXgzKxJABpRhvi4kFaiFHRpXG0ojj0pc=',\n",
       " 'V/2Hf72zYQVDHvRDMFKL4Xj1AwWVPLsKc99BDBK5gKU=',\n",
       " 'MymgKyvbPK4Yp/HtYc1B+AbC/Smdahh3YUUXPL99fcw=',\n",
       " 'd86j06BS/33E7vARFkFGvNuHastdf0F2n4ewqmhRd68=',\n",
       " 'P+nRp2CwzxgD3YRBCiCvfMt5Y8hVq+e9EYplgDhhcxk=',\n",
       " 'Sftg8Y+lGmsRgfXi+izeBwDsweZM0i0KWEyRPzLNOm8=',\n",
       " 'eNUm6cipNN3jObbJMkdymFI9Rb6/nwYFqgAeyX01fb0=',\n",
       " 'J6ZSlPspzcgKYCClQAdl0SSIBuqK0KQClRZg1EPpJ28=',\n",
       " 'LIl8FWQjhzUCfWL0TXJXYE0o9zUM5JypvulQ9ecVHAA=',\n",
       " 'yThMQ1vzwq7s0ouViEmfSSQEQ69ilGm//sBe5ym9P4Y=',\n",
       " 'Z6xOXF7qPZfE6DGLDE5/y+Fj7djM8DbEPJgKlEi2n50=',\n",
       " 'G/6sFLe3pMyxjsh7oFELoxSdTdPd3OhIGerKy2+zQ7w=',\n",
       " 'Ulc9cKn2LvAnUwmTTvIqLAD1nypOo5vK6V748vHPSA4=',\n",
       " 'XvNfPX1r/Q6wF9IeZGPLPBcljOmfzgXh4DurC7p/2Z8=',\n",
       " 'eyCYFhrgZNoDEBH/5zNyGLZ+/nnFyt3Q+bPsGJhME7g=',\n",
       " 'IS8M6AXm4ak4rqIm3+LTBLwzFglltp1+qkq9re4B1j8=',\n",
       " 'E19fPuF9pqxgD0lPrJBL5iyOfe3wnjHJANGHvAX/PuQ=',\n",
       " 'fBbHahB1u82oWCvVO3z4MmOEVFoq3oVYpBOtYzoLB64=',\n",
       " 'zyHLCcgc8MoeRHb3dtO+nvi5vhglgx8fdflTNwoI43Q=',\n",
       " 'tRl7fLHTdxuT+1c8Z2myQVeTc9L4bQbLG+xRO91OJJ8=',\n",
       " 'K4VVOE2r93ow0nfSGuDlxXItOAFwvKnGsfpEOtRF7TQ=',\n",
       " 'boLz6Odzty3Vei48Xkt0GWBwsGoRJcE83EQalX4c4G8=',\n",
       " 'z3FQgu9URaJCpIGpnkzECT1xTMtD3NYc0HloOUxA7Oc=',\n",
       " 'vvmDcDq0OOOnj2wLcf8z9//VzWVtHR9tzyjPa/XTXtE=',\n",
       " '2KwzDWGCZDy/3coidP0bb1zlgDcq4shOOp3dZUqIzXw=',\n",
       " 'CGumFSDvu+I+lYj3iKX7gJ62rVsnqTRTn+i6MT5QWlo=',\n",
       " 'oXITj7xs8i1eLnsfsj60gRNGWAAOm8R0h/eu9e+AEkA=',\n",
       " '1H2Qrxsj97PR/gWrbphh7zR3WTo9gGZ/4VgpV5HU05I=',\n",
       " 'F98l+zAruTJDDVPJIRFphjmgyBGR5UfA6emJdUFr46c=',\n",
       " '8iOU1hQNwaYjEb3Ij4F66b9Ao6kXLI+fx6jPUWK2JxM=',\n",
       " 'MsHIcVOr7TwohFSRjZN54jM6H8d+QwFG4k0GK6ygj0k=',\n",
       " '3ova53rU/iaqNnXUfAV0ooU5iQdt6NfX12Surhekr8s=',\n",
       " 'GYNX9D7+Wg7149s4sbBMjptlPTV+7qq6YHemszm9sEE=',\n",
       " 'K+sD9/clQqTCH8kOP8LLaqV5dPpPwcxEbreQqFxfywM=',\n",
       " 'SNdsR8vo55r5Q7uRqPiY0DbJQWdpreYFjYl2UQ0qdJs=',\n",
       " 'HLW2SySmPW3uZE/JMB0a2iavX5+e/F2WIb3gSTQYsHo=',\n",
       " 'WGL38rl+NEhjwrEmsIpcD3Yk83bbiTzWHt5RwiqxNx8=',\n",
       " 'ELKhceMeSJshMjQeBCu6NplNdqmHmYkILGJ+f/CoGgA=',\n",
       " '7McxzJ+6HId8nw2gCoMcxQ5WYDANkuTgXB86qIfsiMQ=',\n",
       " 'B3+csmDq/Mjq9iSGwzx0U+ZYz+8tuTJD3FrNSb9al5c=',\n",
       " 'WvX6LMypLL7/ybDRUnUofQ7F+8MCzUa11GieJVQpvO8=',\n",
       " 'dDU/EcTjgoqXyyTijthP/CMPA60Z9GE1KEaQrN5KQuw=',\n",
       " 'EoUYQOg7VkQPJccK/3zQxLTXDLNYl6xJZzBKtJx00yw=',\n",
       " '4HqdPYXgHbZMwJNgJhjbbonycsuVs0Z6y6yphw/swbo=',\n",
       " 'yISpT1RVxNaUUrRHmWPnBKJg1N/p4yMIQP118L5rIq4=',\n",
       " 'ZP+e/9CC8ScWcDHH4iVe2rk4NK/4MyjAS203WfQWKz0=',\n",
       " 'p7d0pOEnZ0b5h95T/wFC4FeSbUkd35agFm2PfFeTn00=',\n",
       " 'CoDvipHh1PjNFZiPS4FMYoUuIZ87HwaiWEzaqT5WeXU=',\n",
       " 'fbWu/PEDkVTJ/rtvMjZnsGGn9g82y7ICGRSAha2L60k=',\n",
       " 'vhnk/wyxyN4HAsJo2OGBpQPPWKkI476qY8Wyeh5WQfc=',\n",
       " 'FGG50kVgPJlz2GFbNMHPL1m4FFGevCYXeh72s4ybmxA=',\n",
       " 'sBq5WccqIPjQsqIWtqmUkp2mPv6yqHBuxHekgiOg8QU=',\n",
       " 'SHc6pdmIGvZ7HrPeTtRn8Zcoi2Zdmqi3fCWfdCWBDeI=',\n",
       " 'dQ42N5FVacnZuVWSKlAavcsguZ3JNXVAxJOE3/KS8ZQ=',\n",
       " 'qPOqdInix+0oCbZz7UD2gtcj5phKAASSXH/TPETQvKY=',\n",
       " 'nJXN+nmqJDycMo1m85aqRKILLXwhgPJyzQo0p0u7kc0=',\n",
       " '2WEMmNq8Nvwi/e814tC2TlbMFFPPzz/kDzD2THOu4aM=',\n",
       " '+DD3D/Tnk2sCtb5CGuSMmodnlC5EwBuRYF2tOA+w96Q=',\n",
       " 'AN91824qTIH8ZL7KRfStX6reUomKbAqj0e/LZhoE4R8=',\n",
       " 'zry8lXnGsQrKp9BJ0zPA10FQYZhdwG+6HBHSezL6Bc8=',\n",
       " 'DG/YxQE+kyXjwGlOYc4J6C1Ol5rXRYl8dvf+lkr/whg=',\n",
       " '733uAFEs6uJIMoz8/9PCGn6n9hlrNW5UtVdtcHXxEXA=',\n",
       " 'b9jKZ/yBRD4ca6k0XtJnW5e2RXEtTysFNkgYoYBffQY=',\n",
       " '0cH3/bjk8X7u7PBSVE+4eWU9WHIbbM/pe2T/Q5Js520=',\n",
       " 'vx+Xifx7cUSoOXJ2xkvqiRi25B5WqeYo4JWSVXYLIEE=',\n",
       " 'pBa3JawrWhu5GNIZa0aGOs2oAiwBc2+QjHpcuYBVKtI=',\n",
       " 'rLSAGCs+tQ9dY1lDcS0X5OU9Af6AMWex5oK8zsbdT0w=',\n",
       " 'SWIihtxJg9VKskr6+j73gHNkpqRPbV+AoRzepgNDmYQ=',\n",
       " 'bna0Z9XwmO8Qgi7xO0r2Qq2mnQaj0k6yWOG11x+LNqQ=',\n",
       " 'RbUOR7j3yv5h8YhiJ1oZ87tuMGfG4HuQakYo+lHAYuI=',\n",
       " 'pN5DFZnEBOKjuzWTOqr4pd7yFWIbDYKt2zjz9Uu4ub0=',\n",
       " 'mok7JvRzdnhhDy7q5n6yGfcekJ2GqlHcuT9d3LIw0QA=',\n",
       " 'FuNaHkVVB/5Hvlu6/z49Q5teUFjmyiShGooztS5SyKg=',\n",
       " 'IUv+qHw5BtjbXZbTMYTrglYiLMAcrhFMJnbSaZXwwa8=',\n",
       " 'B9ed602//dKxoNUfBIvkT/u1ErAK31DzorDCM8KxHao=',\n",
       " 'kj/K5QI4m1QevmwiIcl2076LNQf2NOy3WUCpUMBqWHw=',\n",
       " 'hgTSs/YPlzk1pCCSDUAgNNVjONiaFsVQNfUvGQHhrjY=',\n",
       " 'fPOfXt/zG/LpPONKVvike4qSgTo/uZY/U1wpSI2pb5M=',\n",
       " 'rmPUvD/SjMTm4LI1yHqndoD48IC0kGtvbj3iSzzYt7k=',\n",
       " 'pzEc9GPlleW5gfk6rFWjoBgGGBdgl8H+LTZaQsr2cAo=',\n",
       " '+v5RnIDlxSWPVDkja03yxwPgfWwaAO40C7Dox7C387w=',\n",
       " 'cIQV3WKgmcnAtteUp8XmZ/WPZrYKfispY5MF8cATMvU=',\n",
       " 'Hl2d+U6xs+SO3x+nx9XZpByQEHLOt3FyLa0TSSRxEXI=',\n",
       " 'jp4E4ZumgX1mKYa/VTdN0vm5sEcNsieP6glTTEovgoY=',\n",
       " 'QpP8UANZ/QficqRKiEoVW1wrw6M8hDmWkBuSEcn5HII=',\n",
       " 'ysDpFnz2bBnxyKGlCJern3I9HlahN/w6x4YKDfWs8P8=',\n",
       " 'Umx5ZFuR4DrMVcFxPCc82WZJJJrQu1lPMwvO01N5XKI=',\n",
       " 'WkiEiPRRy8dw3hS1hWSsnMsXllQ5/oJTA2RJrZLgWTI=',\n",
       " 'jUtaTz/F59indCYeACyvdsoO2I/9/RNOP8izK4YIcbU=',\n",
       " 'geUnfU9ZyKCgUyvmVMZfKZ/gmKAax46EvmYuseE7nv4=',\n",
       " 'XsEkwaM5HJPU9zc8wG61VSjq7XuwczqTpikSozaO8bY=',\n",
       " 'U7+OqONKew/Gaw7b75ljJQvrWzIrBIykzg9vG60Agx4=',\n",
       " '5VQpNhzfWIBI1B1x0HCD2FhdhoShzRm7TmaBhRt1Ce0=',\n",
       " 'qN+WdmIPkqA8IyXAShqws8FoK4kluChxEmdDClI4zXM=',\n",
       " 'rN+FbPlzWjLC5SdcjnpiXJJQgO4Zifz47nuv1auDbz0=',\n",
       " '2FN842JIzdI858/Jy/TOnHJ8ZNRITmimV/kHI9uVLFM=',\n",
       " 'f2BaEEFI/LWnJlka6V1MHHnnJ/OlAYX30QGa5FGPpbc=',\n",
       " 'NLmUCjuEz8IDq8p8nyE7uAKC7JfTfZjCM5KxYSu31Zk=',\n",
       " 'tQxDUEUdLNjM8NRIILkIZRSnVjfY+Q0RLUkjg+LsEa4=',\n",
       " 'NYgUdeDkttkEcIBVfIxRZnfQmtNapoHChV8WmlJhlJY=',\n",
       " 'ayHPYlHsx8QeHdvG8v4PoEk7eihfN309f8J5ivT+01k=',\n",
       " 'w9TEkpeqWSDKnmq2NHskA+PwaCvEj0UlnGw8DM4AMjo=',\n",
       " '6qf0t32SpMc++tzDSBSqyUZB+dtvspAiogyYE8h0iFw=',\n",
       " '+QK3iWEESM6AjGM8agF0lcmjl4GLxaTQNHYCZvCLCm4=',\n",
       " 'zuXFH5XZxBUo/KLUud5Ttu3TrUerKT7mgvgqNIg3Fmw=',\n",
       " 'PEPgwxP/dO7nDNhXgcSopjrfLFC7hvPnfsVmwaRhinw=',\n",
       " 'rIgBDGenncyfL7/+Dz6KNNGNRzHnALBU+WFYMbiAgEI=',\n",
       " 'oiZ+8Sc/pf9cB0OpnubDwMLfo65Z+RKxr/hSTM1iltE=',\n",
       " '9mvwQxwms+EhywRfwWYd5/A5+EOOvpMprnhWQO2IL3A=',\n",
       " 'lpS/DpaeD9h3i4Pl6NGI/Fm+8tK0L0ijmSqkbxWrjBA=',\n",
       " 'hNxfQAba22GnkXlKjN86dhmDKNIs+bpmzFJl3UvHDlk=',\n",
       " 'EJz8wk63M3Il9s66FwnRPHdmosRiBU7b2GA3IlwBxR4=',\n",
       " '5H/8+AmxKV9JQYeg/8whiDW0B2yG73NSjNlZcrHrp4c=',\n",
       " 'vX5djwIy1Se20uskrMgnVSjYLI7LnAyOXRKAf+TCpHo=',\n",
       " 'EGo8U1rxlkAKvmcfgRrHmJfrMFzYMa1Lh7WwqWFnp/g=',\n",
       " 'sVnOCnE4aaw6O75C+ZeUwpEg+smRmG5w4jwJzep5ElA=',\n",
       " 'N/KQYmQoDRzIGvUxhWU9faVQAL5VveND1K/9234QHjg=',\n",
       " 'u1S+f6RqyK9YGxUZFPBGBcbUw+Rpk44dldvnl2K6EE0=',\n",
       " 'C7FNIIHEkE9hYrVOf6o21uAEuOH2uemUtsFVDDQumgk=',\n",
       " 'ulXOOl1zW8Ge+A+1LUFSG+l5+4BlMjLy8FcLO0LVKfs=',\n",
       " 'WnVJgQh6Jnf4Qq2mW1YJ1ef4h6CxRhn7+xkqHNnrb5o=',\n",
       " 'tg0s4+sONe2eeIYzKMdYdxdU7fkORB022v+Cz8cirs0=',\n",
       " '1xXvQODdX2wwtGE10FNwkaVg5jugMB6oDeeadLtbPoI=',\n",
       " 'IwwaZw74tg4JqT3ass5O0gHT7/qqwtJ5DmnpQLfy2FQ=',\n",
       " 'UiyDbTbgGXwXoS6/kGB8f+K9EJ4yBOTw1QNsLeriJHs=',\n",
       " 'hjZYjQxVc1Aa46CF429zTOdNpiEtZPTBj0I22WNqsKk=',\n",
       " 't8jBLaJuHdXYXoSBZqX0OX0H4AfoKbJG2stem/sIodk=',\n",
       " '3r3Lw5LpbIjvcx7fThM7EBgMeXdYPJAS8OVef3YhrGg=',\n",
       " 'I5m/+pqhkN9qZUKXTsifNmfR8vgX5bb9zd9671HAxGM=',\n",
       " '4VccshtpHKtWVkN6hSwkenVn0vu5TPacMm2rbkFAghQ=',\n",
       " 'K3XVpiH2Hvg9ayprGBYdcOcJU6SSYRXLHd1EgDcjKWY=',\n",
       " 'NMstlX/MpSg+oiwwXiGgfiTm4F0BYYE5lTboAjWLwls=',\n",
       " 'WxJc9o/IsdkWJecEG0Q2P3utULoaATbMt1urxjrhyVA=',\n",
       " 'NxaLaAQ8RCz/H9ndzHgexgL3T1ZF8zxb0od4E0z7AwQ=',\n",
       " 'Dn0rnsaIe+shsP8pvu7jrBQc1a3JyopO0rMlsmFRHgY=',\n",
       " '8gsFLQwpBKyvc/7xZ7ccqpQ9T233xO/cnGfB6Yfp/rw=',\n",
       " 'J/AHnL6q+Ee0OtmfkiKvi308xbwb5BZOn+KfPTE6scc=',\n",
       " '0e3r0YoM1jrBBc88DF/4D0YBKi6Qv4w089RcBDDev4A=',\n",
       " 'Y+TDsXu5xadTaRc7dM7EplXvZ3RpV7DO9jw+/6x66qQ=',\n",
       " 'I6IOlG6dyi3kxIaXbb1WpVnFx9Q1KgAPqvxvKfj/FbA=',\n",
       " 'ocYyz0ESeWC2Aj6InIXkbuout8EOhE3PoQ6riNz935I=',\n",
       " 'jKuwgVKke21jwRNO7258y1ac7Ml0vXcjwmLG6gf/z4o=',\n",
       " 'jXXlVDd4MSOUmnpIbtV5Woeu6dss5f95MPnkTHoGoBc=',\n",
       " 'nIrv/vQCbNLvHW5dV11Q5YxsraCY14wyI/6FKBw76Fg=',\n",
       " '+10mr5XAP+Bj3c/gv+WOatr0GiuarDCrF2vmuKoJAdQ=',\n",
       " 'kholQglCikVUNB2AqsUeE5Zrhz8gix/+zJ+0ECDca90=',\n",
       " 'tTaumRaZUXTrMPqhtr3Q8BF65d3+R9A41AGY1czk9lA=',\n",
       " 'OsbQd2bvWITTqyJn/tx7x1yuAhPlqa/M8kZ2RJT+MEk=',\n",
       " 'fAE1DowyG8RJGDQDhGNHuvMyQDQe7nhFCrkZiVBckiY=',\n",
       " 'TjCIRce0L1+c0ZcuXhXV7aZfjmrev90oGtsI5g1X/lQ=',\n",
       " 'vgYjzXv2i7fth4BHn5AkNfAOSeQF4bHguOW4JP4BA1Q=',\n",
       " 'qTcGThZMWKK4l+ParQVyl79bH9K0walR/ZXRu6jWIHI=',\n",
       " 'dXIf52xFniZpyhMz9k6lMHOZkKzJDPjsZv9qzJUr0Ec=',\n",
       " '6OY6yu42Pr3F7D7lllmCSzlsvQr74nY2+LOhlXVSFsQ=',\n",
       " 'pQb3YIatEAAtWOMg3NH3KtdAVHrh5pVdfwCzo+D0qb0=',\n",
       " 'EI6X9EEKQq4489LReMemeOy2+whpsBufC+Re/FrbBXc=',\n",
       " 'OKUmiE1tR/GivilYJBxqGq/+GP5fo1NRvcFFOj76Z8k=',\n",
       " 'iH8zOmMdgcLNDTMS/vbgeimkCYva6epENPHAGAHkv+U=',\n",
       " 'h2WP9KGqrWNzL3Rfnxk3RmqpuDoRISMKr1aVg8j6YMw=',\n",
       " 'QLm1mdnvM6UvP67BnxshuO5Czq6q6Ob2DOV3LL2soGU=',\n",
       " 'SLNLSFcy/iQ9NTwcVLMx2lO8ox1nsuzVUpXz5P7z1r0=',\n",
       " 'UXnJQ1/djwHqHBHjrxaZMkKvcYZfJSeWakVtzLifecE=',\n",
       " 'JWxPsuhcLC8G7I4K/sQAZWdiQ/CE38DsCZ0r6ZMxm7w=',\n",
       " 'KRNA+/VRARB2Kjz6w1+b2OMt/Dx04B9uxcGi/yf130s=',\n",
       " '1yGYnac8HC2k0xzUGW3Xnu3LogfaTgPzJmwmGGgV8d0=',\n",
       " 'lKuTCPqVkuwYpYlsE1EJyuS1HIc+spN9Mt9CuwjjWfs=',\n",
       " '0ZVIyi7zXRKYxATmGnt8/tzWitNAHoH58tnMQeVzulU=',\n",
       " 'wqG7sMKSXFZRA+lnAgBYQRkGWCV47eSJeLZuE1lRxx8=',\n",
       " 'fbzaZxF69iXl4J4sGiTrj1vpn3D59VbcqZhX4Tu+HlY=',\n",
       " 'AjPRSr3ZBPSU/tSaI83ZR2V6DxovKQhdBNLUXbueZOw=',\n",
       " '8QjcDEC/obylOLnhX75a9wB8nylxAVJvXXWZWQMG9GU=',\n",
       " 'VbYjtnQSYg/zz5Yifcj/TULy3JkfxyIooyjBLGcJrgc=',\n",
       " 'dWgrLCEIZk2xPTuyYUjInb1mDVeGAe3yyVHOsCW9awM=',\n",
       " 'NshJIVyOVaFljjbYlBQ+I1Cc2xNLYh69WSaEd5boCgc=',\n",
       " 'z7o3x0I1x6WVuI7tbbIMrEhZNty2oUJdDaHl9izdrJg=',\n",
       " 'UFu0/IkxWME62gSVv+pBaGBjd2Sb4QJO4gU9HBJJsmk=',\n",
       " '+p7TZpFDrULZeUHPQ4aPnSIzFynMCnuMeQQele4RLOc=',\n",
       " 'WSQBseDhaD8WdO3TgBgrh/DSBJHb+f19yof5WxalE9s=',\n",
       " '4mvAdamJLDfeDY8ulsunNGPbnLeVBICZh0AdUM17o2w=',\n",
       " 'y6DoWOo9ZgnIMjiNch7sWJtZrsH7gQ80tfS/lY2UQuI=',\n",
       " 'oNWRKAIY455MBGMp9H7fi1SWmnu6wf447+QT1VuktgE=',\n",
       " 'gvSZ0MzxGbXFkW0C9xatWkobb2U0jnxtqsCMminkVvo=',\n",
       " '5zgCFytP8S4yUw7K7RXJHmvo0ySTujmVfss+VmIaVKE=',\n",
       " 'fv8adjB57V2KNl8Et3HQxbdJS/C/fS4EFyC9P+NE/NI=',\n",
       " 'fctU17p8hitO1y2lcJLwZ42KmvymSK09j3UqPIWJZgI=',\n",
       " 'wuj9C1pekWd84kTaIVkQfGU9+bq0FL+K9ouzAH2U6WY=',\n",
       " 'P3Thlyy22MkBjq1OqGrAgyhZKDq2Wa+JvutqwcxYkZ4=',\n",
       " 'boLzKryEbGDID+dw395bLvKSJ7IuCr6An7hXWxLjCTg=',\n",
       " 'thlqtZ1KRrt0ldACuLw9UYuMZoX4YEzSMLBHKX36L84=',\n",
       " 'VYSIgS35/CVYTVEBOaFE8RlVpJ07Wfvhlg7F8n7V+8A=',\n",
       " 'cZ5TlEPLHQ84WVZ+0+Jt7bYV0HmzFHpXKwwhRqUX6Ng=',\n",
       " 'q4GLIeJOUX1uhTzIQhTpU8kq8xgrylbwt4wWE+K0tQQ=',\n",
       " 'wJMf17oNd/evTvjSzx0E26FCCerZ6CEq3uLVCQV1aBg=',\n",
       " 'oKwJHkIdqdGQ7gHl67xvamVP1N8xTvIgQR1bCwObEd4=',\n",
       " '7n2Rk+Nzf9FGdGu6vAkEqCZB+TPZv2R8luGg1DqkZgw=',\n",
       " 'zIoEwgcG+G7IgSa5ACGkwhJlui66rHib3ufEzliYYVk=',\n",
       " 'V8hiu+bxMMLuPb6tKHLgBS6QHpxogj660pAICx+9lTk=',\n",
       " 'HdIn07SykvMOhg02WDPhgKIGYmegOUTje8leR8mEe0A=',\n",
       " 'fOV3Qo12TppI19BgZ4zkf0GShSTo03euda+tPZBl/G4=',\n",
       " 'H9uDRIFCkeRVqm8VnH4+CtwBPIyoRxIh9Ht0DYt+xCw=',\n",
       " 'ToP2BvCkatd66a4IOVZ9IRMPKAuBg0Dai+amuAUHHJ8=',\n",
       " 'dx7H26Znyv029/bHZarQGrdfss0Ir/2MJ3La6DwuTFc=',\n",
       " 'Hte9IGibfBq0gKSnWh7cUhF4R7nEGsOY1h/vHvrw/sw=',\n",
       " '9U0ceVFvihDTk8lyL2v0xGf2KTGOOSRsu+P8WoHNsi0=',\n",
       " 'cEPLaL6J/rCN69jCz1L0R0KuHt8DuxV6zWaT7qm83J0=',\n",
       " 'JnsXRZgVmHd2qqg0kwfTqSa71J75Pb/X0+D5Z1Wrjg8=',\n",
       " 'dX1+wwGxyLOwYHmJNgBnpm4eJ3Sk+bEAxIQNKTaDjaE=',\n",
       " 'fQkVrM6WPOclYnnGcyD8idFZk3nAyHUMaWZ3SJnECbo=',\n",
       " 'ROtBYjoZ0iU5/2hdwNjm/T4Y8QE7cOer2lMxyVm8Vjo=',\n",
       " 'auF3Qx6npScHPBybxQb13l6X607fM169l5IvuEhp3bs=',\n",
       " '1eRYrzH9yS8wamPuarABrsj+akROjIdVNMLLzu2CbWw=',\n",
       " '2c3QYV7r3HIzVPRDKoaLqOjTf4/0rCy3D0+iM4Hec4g=',\n",
       " '2LwVtcD7/pw51B3+kc7u1FjsOZZplUiRPN2rhu7URf4=',\n",
       " 'cWMdP+b9t3acMw8cPxVx7lsIDBoEYbjEPYW7cHBDh64=',\n",
       " 'HZUGdNGfHJ3TgWyv7MZv+ZXwv9yUzYFDk8t80rUteZI=',\n",
       " 'V9zgC9Skm1kbjYwvdEoo1Xuaic9n8I+yQDPlhY53ztc=',\n",
       " 'j/qNnTPbStNojgts60f+3hbFhRbPkivansPBJt5+yJg=',\n",
       " 'gJHit4pP3oNBWU7sRJbgx7EmvE3H/7m7+EnaqPChq/0=',\n",
       " 'ZwDMOSntxLfvaV4SrU8c8xomSJ4aZapqOjRqKBuBBGg=',\n",
       " 'SJyR2EjELbC3h/Z9CzKbUWSvr50pk1KVKWW9S/EYrCE=',\n",
       " '+/4q4EtmNQ/2MEvt7WbraOj2w+GzOuJdB3csX3ap5Uo=',\n",
       " '3rH4ySFQCP1l+VJf7axyPwTqZptGE+P7rJOkd1WmRSQ=',\n",
       " 'I0YayftTGeF/0Ba76H2KEjzchLKkl+2BPs+z+evK8o8=',\n",
       " 'lLPHCOUfdh/mRiurhhWDEZwJMPrvjwmD4K+3Y7/kdWE=',\n",
       " '2K3NrbA2LeDYV2p/1xI0VKn/FEZib6gj6bfK6klAzUc=',\n",
       " '1MS1DTvfrSNlthXZzz3ntcyy2XVIEOZT79VJens+yUY=',\n",
       " 'ZkP4Jc4OD/X/ltGxNJuj+ORfotcRzFFytlAZvop2+BY=',\n",
       " 'QvbdI25aS17SG9dIkxnJEgK/BBIlMH8NI1PqZZzzQ9Q=',\n",
       " 'ezhkpwTBBRJJj/SV5fo2LIqSWUKXSgafpkZTaDe/2YY=',\n",
       " '39tUAOrhenHuFs/tKOYdtuSrNt7twxvFA3gvULzNDCo=',\n",
       " 'Amm4dL4M8/QhRF01C9nivAShFZPUP2EfXbSoJWM9kDo=',\n",
       " 'MSQgGbm5wIoeRynQ4LmfUjWrPJGyxv/bagY6c6f8S8Y=',\n",
       " 'J5GuP33g51GzqvmdGFKG29+oWoYjw9Dhhz6vgLrI5lM=',\n",
       " '7b7Kru3lsOg/8afL02qjHc1MDEKG3bxhv+3ZK9r3Uzw=',\n",
       " 'C8AURC9J3JXR/7cEVvXOlf0oZi650clEgRLcvGmJuos=',\n",
       " 'dRnsBhaFoal1qTFCFcRnBHGHd3YQR+IpZoVP2x+/OcE=',\n",
       " 'PPYRG1Vy5IvRzFhrsR6kIFtI8iV8nTzN/m15KvtaIbs=',\n",
       " '6rbaA+GsUBtPXp6i6TUbOPyaG55xQNOqasqkHQqfiyM=',\n",
       " 'uDrAvc19x3/4CBfWi9SC3LzXkO6GOUshVd0JaD9hNC4=',\n",
       " 'xonkmZ3bbCfST4Jd7tjkrP9V6aCH8HwTjkSuNYDZysU=',\n",
       " 'mNcK5qtY4vo0CSMXWeE4JNbH6Fyb02NQ0CHTiZ27+q4=',\n",
       " 'Q5pcJF+C345xxVIBmFdABMeQW6bLvmauB6RjxF/2Rdk=',\n",
       " 'B9EEeKORKTzlvlLnVFjrHBQX+X+nrU2cCHDSTfkNlHg=',\n",
       " 'nWnSfCEmr/aquoPhxDeG6peZyotWPbq1l9m0jlTuEd4=',\n",
       " '0lrJUSzx6AFFNZrDrrq/BOE61XZ2WtVa5AufPl5wNe0=',\n",
       " '/SQXmNJAiyEEsL6wgTls5qA3yy6dsmYC9G4NcCUqswo=',\n",
       " 'yNtoUwRtXtDUFbLOszAc11YzTIbKI4gd33jqcS7QjsQ=',\n",
       " 'jXINNm0jo9xKBRQz9mNltvPTJgkweS/gxR1lOW35SMg=',\n",
       " 'qusSV1SwQVhhHs2Pi5nBr2NLTT/WtgdXSf4qO+bNweY=',\n",
       " 'FlHeXX7D3c7+Pj/dp2eCr+jttnF6gZCY/TSO8H5M3gI=',\n",
       " '1ERe+J9DP//njrBWNksfvcLLoY7VWreycoY19SQLnck=',\n",
       " 'KWhajDs5z4VjmjubNiHkJDZKN4+R2k2utvQxrSuFQUs=',\n",
       " 'f2LEvgyVDjSyY15VFKqeuGir/ySK716IN6I5+LmU46Q=',\n",
       " 'N/Rc5KXDVpOFieH64oXb9Tj6KHemJmz+CJZrG1D97+8=',\n",
       " '/1W3dsvQ7DoOpxJRXKbKEZuMtjhnrrq0LBh0HXNZp4g=',\n",
       " 'mFUG8Q0DqstCYtWwjcv3Kx/ZgX8zFK8KoRswY9YNbvg=',\n",
       " '0MXf3v/i2MNcKtnyYMUjrKAk4o8dOqW7g1eDoNkpYeM=',\n",
       " 'u0d7kA3oZaNhYgmEA/TBKcbSzSNPr9lHrUPDGGAb+e0=',\n",
       " 'x3EWclmjpsyBC4ZMusgxZtwaNjY3e80T44ksoU4bGzE=',\n",
       " 'ugr+WIzFJDlbSWn/LcDDMMmyIi2+/eHcNe41B0w0W6s=',\n",
       " 'ngCs67avH/bvriALuoT952tl8Id2gl7hRs+/PnKOh78=',\n",
       " 'bCplR8m985wlTSYHsmKg9m48YdNrIZkCRL5hsmjw84k=',\n",
       " 'HjnhnGSFVsTAxA6ZfxR/mokPX5ZkoqDAwu4Z9TED2lk=',\n",
       " 'BjyMyzHwR6h0bB8+6LoRmNidOH4q13GtL74uvG4diXo=',\n",
       " '9cg4eGLmzQl8LZ2AsLwDF5Uz9j4ffxHzVWoA4P9u8BM=',\n",
       " 'GnPoe9QHAAB8AnGKibr+kHSVfZEN7VeziIr+dunUT1I=',\n",
       " 'iMGIcqqikbWboR3Jb15vxBi+ZZKbNiDy7FG/7JPrp9Y=',\n",
       " 'uDjxleAytIQa4s7aUpYdhXgm1p/EIUBA5hzaJXPKHpQ=',\n",
       " 'Npgvv3fdtWPVcr+GuaBrNxf05i4bK3LwDcjJOnpGSi0=',\n",
       " 'sDPraBtK+qmjp/jcnb1eFLN8uCj0xXtf0aIr5AQWliw=',\n",
       " 'PLlE1djSzyCVSjoIk5qq5Dh/vKJFk2hO2Du9c1zSTBw=',\n",
       " 'L88b78pLeLmhrdoYguh9RDfUzyVXj0AezVrY5uy6pRA=',\n",
       " 'LYEIR8Pdkpnpb4wZkHCgMpxg60IKrSc4aFPrMedLb5c=',\n",
       " 'wC7QJ1pt3yCuKsA/fkVFq9YFVMJaU/XUyAwxMyJT7ts=',\n",
       " 'YDsU2ELwCIrYVUCQr1SxyUdk3HNDeOyQoQ4gp38aW5U=',\n",
       " 'vUEu9KQcVwAQZ9UFErA0VqwK2xgDW8955BnEbQ1ApYE=',\n",
       " 'fIJxi/ep0eijPHx4LV6vo0oLCpz8JV2kSqbb/ctCGKs=',\n",
       " 'DpLvoPEw39w9feI88iNjjpV4ciEWDwKFd8dGnuKpQc0=',\n",
       " 'IqpNwXQGHnGIIUxKsuSR0unuViYNoUZzkm2zwnt/PRk=',\n",
       " 'c+d2EPI0jT1Zwm1UMokUammqNoMez17Pr0CtuqcWFpE=',\n",
       " 'DPGA8H97YREMO2LXFnWNhkOx7aNj6x5BfHpmeVwRSCw=',\n",
       " 'njaifRdIO9t1zFMCG2Kp8im4LpXvCvxyTV326nTPQog=',\n",
       " '9arVQLjD3driaOJJGiS8G5tPzB8b9AbAtj2aG96Tt2Y=',\n",
       " 'age+PXXZDc3AzfLKHe22zK5ZNRwWk5MKWEQGdlddknM=',\n",
       " 'oPMvKlHt3Y2SpujZXZaMFH02P6E9J+qgVkS51LGK/8Q=',\n",
       " 'wbeWXSK+UYNo0Jvs10AfJp+fqAlMf8A23ZJLagzJMGA=',\n",
       " 'A1qs1N+84Ct6qO51dwFgTxux2trOTmU7namj2D6TwD4=',\n",
       " 'Kr5ie6UEH1PvFHZ6Q5WdSEXqDqmlG5TuOvWgwcQwdSw=',\n",
       " 'qAIZHkBVU3ctgVRi1oFrJj2tvs9lG6VeAzH45Nu0hGs=',\n",
       " 'YBlWpbtPKYg+nqOLHw/b3t8pAzLdEmCy5Haghzk1864=',\n",
       " 'shI8eWHE0go5+b4y74KEDfts5UY/Sv/W0eacftLqKmc=',\n",
       " 'RSKSbXQfND+4JZQ3nXMDHvcgatiOvc0PnDnueKh/k1Y=',\n",
       " 'u8pekcGZqQLnkM1nRa5reA11l9NMjnG75pbPUL7CXM4=',\n",
       " '/1NGpDSeBO/9xfjCo9peffmXejCr8vbfCx0JCm83dVc=',\n",
       " 'nAh0P4FgIPI3KwWjI2UHoTsBB9MNE+Q03PGadAVPl9E=',\n",
       " 'YBkHSz8CiP/YJRApVW7yyLMdN1vIxEooMqFIrSLwqKs=',\n",
       " 'Q7R4RG2THEWroo4AHiDouHE1M/kfksBiS0622TQhYbk=',\n",
       " '/thKAyzKkDQ3x7UNZoL+wMYMxaKDRIOW6gsM+rLNo/w=',\n",
       " 'xRaMaoqzs4Jg9vVSgV4JjrnSPUHIF5UPuqOCyiXu/qw=',\n",
       " 'huVrsrCJkh9I3glKx+iG5pjC0XwmawtDfsSAEJMC9j4=',\n",
       " 'xxMn9ikQqYLGQ5IL/pMh8ScHlPPEZYi2754FuGu8zuY=',\n",
       " 'PzmM00/17BAql+esPFQSSaaDbGMmwpPjG9mShfNBLYc=',\n",
       " '0rFt1RPTHDv6bzRz5MpBS+E1Aokersk0TSa0389mqvY=',\n",
       " 's/JoPMfOqiQT0B5GYxlTc24HKj6UHrD3LuBrbuZiobs=',\n",
       " 'SjV5WLvf2kt0tg3aLisDy+hGANh3Lu8ggn488o0sZGo=',\n",
       " 'GhL0TFDh0ZIkCX1RQGOp3K7xOtb7h9OouWSR3qIMgeQ=',\n",
       " 'paNz1gnaBeBACGGkG42kQvG+JeRyazsLDwcFXA2MylQ=',\n",
       " 'oLt3UeOaVSLOu8WurrRtcXriwNJStNSHAck/JAtMGio=',\n",
       " 'k9FUVFVb9q81pqyLbwiJW7VMlnQxsTozgdahbveFSRo=',\n",
       " 'r1Z0+wzfbakDn7i1izvhwm3z200X971ZGO8NQXXaF9I=',\n",
       " '6nEk5uTlSMi61fjB0kJb2B8YzRG8R9Je8MxVuvcPC7U=',\n",
       " '16m79z7D2IvkxTHMvwXHfiZuXDT/amj0XY5mOIqJHM8=',\n",
       " 'slobCx9GzqXPs7dyB0KRxtBWqeGymPfsTnATvuWrOYg=',\n",
       " 'bhxpmqhlv3GE4M8DBnNd3d8FvgCn7sAurNTd9mGOsV0=',\n",
       " 'uFXgFPdfURiTL2eKoyVwlafqtdn+XB8KP2zBcdd2mDY=',\n",
       " 'MpibbFsbMsK7urwbwymD2aoJd6WkgWLxxp+GO7Wb10g=',\n",
       " 'itDGIqR05CVoqv5M5ydTMRcQjVJwZ4qosW2ILUAFL54=',\n",
       " 'NbFmE0MyA1dHyRaw/pioKCAPBUIYE15pGZRshFPr0jk=',\n",
       " 'LADuDLkn0Q5fp02VtUVy/nzw6GS/ssjESaFcWY6ydsw=',\n",
       " 'BbjgfRt2/V71XLbYswp34ZNSi3C/jA45LPu8V5gcZHI=',\n",
       " 'WQG9A/WwDjMQTo6gWVjyiwkc7Ge4mZLNFLc3I2JXEIA=',\n",
       " 'wwff5D6AgOewjFhKBNE7tp8rljLdAGFUryMjeiOVSZQ=',\n",
       " 'lv8jMLjkRAGtmG802DCnSftbBlRRF4tmas7+tCJO4ks=',\n",
       " 'SvhcdPTGljjcqkAKmEEaR9rGzW1GjbxQgM5CQ96Q0YA=',\n",
       " 'a13JBpbBDnl1QMqdxBaYgBw9IhgN7QUBzQzf2FDIl5A=',\n",
       " '/H+OIlmOoBwe/fz/zw5iDh38rEmYr+yHJtJUo1Hi7GI=',\n",
       " 'zuKwJuIoDPQi/SR6zVo6/iXkmfIOp3lomnTNQ+Md5co=',\n",
       " '6LBKx669VcslaeymjZ/pxWrjKBYZbZ3/Vq509WMKGmU=',\n",
       " 'DhsAERVWwX6iPMs/HeVde112KfMoCXJEgdQea9iLFgU=',\n",
       " 'lCdh4e+uq0A4tkvl4BXQ36favFJ9/8JGjahFiIOoSuI=',\n",
       " 'XGGYpnGj9astRNlGmZmWV+xHst1Wdotp4CF6ePe6fo8=',\n",
       " 'Z2R3iGst7JS6Wv36EBDghF5pCNRb5t8WdC+Rbmi7CWo=',\n",
       " 'SED7wvviMXoTSl9TW6EpTK5c+EiS/cdfwzCp5+7XrsA=',\n",
       " 'tpBrIWcGIzZ0pIWxTuyBtfF7lH5Q8mlM/nm+zDC07l0=',\n",
       " 'wd9d3vb71ZgfWpOEjZay7bw6YdQJIPswgagqrlTJ8fE=',\n",
       " 'fH0c0EGvU8BTXHm0LZde6ICVCxd2o8N98NxT/Vbq/0A=',\n",
       " 'cUIalWaefE8ymluVvOeHnBu2aD4YCeMYuRvIKuH21Ro=',\n",
       " 'NfUz/VVYb4Dw8BpIr9Rj6fyv0597HVkfgVMVrGa1WzQ=',\n",
       " 'AZzFZ+xQOSx0i6x6RK4u50nIFUlUzh/DM6kEbmfId2E=',\n",
       " 'nRhKn0TPS7inwHF7z3JLBMbITxRSb9upoUE6psGSDLs=',\n",
       " 'RQLwlCLvI5xnePtBm5rX/xRQ7GpdaNAWz79Ao/iIDWo=',\n",
       " '3wihKAmABJwHtM6gWdBQXf/EyIhX+IQvAJMsX4yYCdw=',\n",
       " 'vd/EgrHY4GyrPahkc2QHhJpSZSeZZOjb22jrFdP8BGc=',\n",
       " 'fGDRyBiqcRxYb2oW5Nmoaf2zvOR8ssQxZzuaTFPzsXk=',\n",
       " 'X/Fe/5vW2vqF15OVmWV0dIE7poYZQLG5WoSpDsXRF+g=',\n",
       " '/YOrvla9ZUWF6CcOJfJCElr+XRnZkecqKuWBaqPTSu0=',\n",
       " 'XG1d5njk6hERxQQtPvJDeCaqtTxiTP2SQ0rlikMn0dM=',\n",
       " 'EfWGLMTflViH+BebR7ArqOQLTlCnzYq1nC5AYoNsE/w=',\n",
       " 'wG/AGTejZZq2u9i1cPopWFmwTU9Kw+4SajYxAJQ8QwE=',\n",
       " 'A5Dy7WMEWl9yMU5URgfeMmv3fWFUPdrxDNmJeBdVFGs=',\n",
       " 'dmJbyMskE5xGvNdX+M29vPL5cdQBAnVoXCH2pXKXa78=',\n",
       " '/LwH2WhBYWvx/8bk5t1hgXTEOl6f8fEs7u+lY2iflbA=',\n",
       " '2AQNTCxm8jFt0otXJfc2oO70fMVnsB7BIVYgvGL4jMs=',\n",
       " 'Do8B130ThjN9jmI01+SJCLshbBKlGCQsUkeow0dfd7o=',\n",
       " 'a2fdPFi0rRBR/jmcKgjCOXmnxrJVazzmzdmpwdMVl5s=',\n",
       " 'UktvZSJwotZu9B+NtC1eBqsbj7q+nyLXfb0aUQU4+y4=',\n",
       " 'Lu2C83jOlUVwksATBYKXim0B1k1HMSmslasFgW3FXoY=',\n",
       " 'CcAc1YW4cqCecwsTtIXQVuTH5EKEO8qeOF73JlNWhN4=']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_user_50plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5e7c2f2-3cb5-44e1-9f1a-c3a4a5982d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "duration_ans = [] \n",
    "most_visited_date_ans = []\n",
    "most_visited_hour_ans = []\n",
    "most_visited_timestamp_ans = []\n",
    "longest_time_diff_ans = []\n",
    "\n",
    "\n",
    "dates_and_places_to_ask = {}\n",
    "the_dates = []\n",
    "possible_dates_ans = []\n",
    "the_places= []\n",
    "possible_places_ans = []\n",
    "\n",
    "for i in select_user_50plus:\n",
    "    # print('----- ',cnt,' -----')\n",
    "    \n",
    "    user_log = new_data[new_data['hash_uid'] == i]\n",
    "    user_log = user_log.drop('hash_uid', axis=1)\n",
    "    user_log = user_log[-log_number:]\n",
    "    # user_log.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # user_log_shuffle = user_log.sample(frac=1).reset_index(drop=True)\n",
    "    # user_log_shuffle = user_log.sample(frac = 1)\n",
    "    \n",
    "    # 이후 api call에서 저장된 dataframe을 통해 로그를 보낼 예정이라면 따로 저장 필요.\n",
    "    user_log.to_csv(f'./data/subtasks_lookup/user_log/user_log_{cnt}.csv', index=False)\n",
    "    # user_log_shuffle.to_csv(f'./data/subtasks_temporal/user_log_shuffle/user_log_shuffle_{cnt}.csv', index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    for j in random.sample(range(0, len(user_log)), 1):\n",
    "        the_log = user_log.iloc[j, :]\n",
    "        the_date = the_log['date']\n",
    "        the_place = the_log['place_name']\n",
    "        dates_and_places_to_ask.update({i : [the_date, the_place]})\n",
    "        the_dates.append(the_date)\n",
    "        the_places.append(the_place)\n",
    "        \n",
    "    possible_dates_df = user_log[user_log['place_name'] == the_place]\n",
    "    possible_dates_ans.append(possible_dates_df['date'].tolist())\n",
    "\n",
    "    possible_places_df = user_log[user_log['date'] == the_date]\n",
    "    possible_places_ans.append(possible_places_df['place_name'].tolist())\n",
    "    \n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6385ef19-e472-42db-86b9-c69f021399c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/subtasks_lookup/the_dates', the_dates)\n",
    "np.save('./data/subtasks_lookup/the_places', the_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35de0417-84d9-4aa8-977b-e30629e25109",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_number = 112\n",
    "\n",
    "the_places = np.load('./data/subtasks_lookup/the_places.npy')\n",
    "the_dates = np.load('./data/subtasks_lookup/the_dates.npy')\n",
    "the_places = the_places[:user_number]\n",
    "the_dates = the_dates[:user_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f802d857-c85f-4cc1-be7e-139fdb51884f",
   "metadata": {},
   "source": [
    "<font size = \"5\">Count Task</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9be9bc88-846c-44c1-80dd-659f57558593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14015474-1d5b-4ce6-b539-3bc6e76bd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lztWsEhfW4izKDhydIQPc6sqvpXYK9VPn597KyYQUGo=',\n",
    "#  'nSsQrLz+aRBh01NUDYnPNt7zYVus9fs132rfFXf9FA8=',\n",
    "#  'Uru5Avt875xZfeIlo5SijjLrq4DNsrF71gZQeJXrP8I=',\n",
    "#  'AoUA5eWtgKJq55332rcvAgTItFhfaFM8AXgi7MiFanQ=',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fc427b0-a1b1-4f7d-bb03-aa12550d2965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user1_log = new_data[new_data['hash_uid'] == 'lztWsEhfW4izKDhydIQPc6sqvpXYK9VPn597KyYQUGo=']\n",
    "# user1_log = user1_log.drop('hash_uid', axis=1)\n",
    "# user1_log = user1_log[-40:]\n",
    "# user1_log.reset_index(inplace=True, drop=True)\n",
    "# user1_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "087c22c0-3d16-4271-a487-519096a7d11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user1_log['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab944a3a-a5a3-4a32-9a5c-c3ddff29eb36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user1_log['place_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fab136a9-3dab-4803-8147-5d62ae57b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user2_log = new_data[new_data['hash_uid'] == 'nSsQrLz+aRBh01NUDYnPNt7zYVus9fs132rfFXf9FA8=']\n",
    "# user2_log = user2_log.drop('hash_uid', axis=1)\n",
    "# user2_log = user2_log[-40:]\n",
    "# user2_log.reset_index(inplace=True, drop=True)\n",
    "# user2_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dfd33df9-5616-4211-8b66-dc91d78467ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user2_log['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4cb8afb-3ad8-4a9d-971d-0d07c8fd455a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user2_log['place_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b169c38-be1f-457e-aab8-402d128781da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_category</th>\n",
       "      <th>place_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>롯데백화점 관악점 /식품</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 738-106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>롯데백화점 관악점 /화장품/핸드백/액서세리</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>롯데백화점 관악점 /영캐주얼</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>롯데백화점 관악점 /영스퀘어</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점 /식당가/상품권</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점 /아웃도어/스포츠/아동</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점/바르미샤브샤브</td>\n",
       "      <td>Japanese Food Restaurants</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점 /가전/가전용품/점행사장</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점 /여성패션/란제리</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점/Saboten 롯데관악점</td>\n",
       "      <td>Japanese Food Restaurants</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점/함흥면가</td>\n",
       "      <td>Korean Food Restaurants</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점 /남성패션/골프</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>13</td>\n",
       "      <td>롯데백화점 관악점 /영캐주얼</td>\n",
       "      <td>Department Store</td>\n",
       "      <td>서울 관악구 봉천동 729-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /목욕용품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /침구류</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /세탁용품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /속옷류</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /초코렛</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /푸드코트</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /주방용품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점/키즈카페</td>\n",
       "      <td>Kids Cafe</td>\n",
       "      <td>서울 금천구 가산동 60-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /냉동식품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /라면류</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /남섬정장</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /애완용품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /건강보조용품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /화장품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /청과류</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점/키즈카페 금천점</td>\n",
       "      <td>Kids Cafe</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /생활용품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /육류</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /제빵</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점/쿨펫동물병원 빅마켓금천점</td>\n",
       "      <td>Veterinary Clinic</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14</td>\n",
       "      <td>빅마켓 금천점 /주류</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 295-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15</td>\n",
       "      <td>홈플러스 금천점 /식품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 291-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15</td>\n",
       "      <td>홈플러스 금천점 /문화센터</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 291-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15</td>\n",
       "      <td>홈플러스 금천점 /프드코트</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 독산동 291-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15</td>\n",
       "      <td>홈플러스 금천점/THE FACE SHOP 홈플러스금천점</td>\n",
       "      <td>Cosmetics Shop</td>\n",
       "      <td>서울 금천구 독산동 291-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16</td>\n",
       "      <td>홈플러스 시흥점 /비식품</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 시흥동 992-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16</td>\n",
       "      <td>홈플러스 시흥점 /문화센터</td>\n",
       "      <td>Discount Department Store</td>\n",
       "      <td>서울 금천구 시흥동 992-47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date hour                      place_name  \\\n",
       "0   2018-01-04   12                   롯데백화점 관악점 /식품   \n",
       "1   2018-01-04   12         롯데백화점 관악점 /화장품/핸드백/액서세리   \n",
       "2   2018-01-04   12                 롯데백화점 관악점 /영캐주얼   \n",
       "3   2018-01-04   12                 롯데백화점 관악점 /영스퀘어   \n",
       "4   2018-01-04   13              롯데백화점 관악점 /식당가/상품권   \n",
       "5   2018-01-04   13          롯데백화점 관악점 /아웃도어/스포츠/아동   \n",
       "6   2018-01-04   13               롯데백화점 관악점/바르미샤브샤브   \n",
       "7   2018-01-04   13         롯데백화점 관악점 /가전/가전용품/점행사장   \n",
       "8   2018-01-04   13             롯데백화점 관악점 /여성패션/란제리   \n",
       "9   2018-01-04   13         롯데백화점 관악점/Saboten 롯데관악점   \n",
       "10  2018-01-04   13                  롯데백화점 관악점/함흥면가   \n",
       "11  2018-01-04   13              롯데백화점 관악점 /남성패션/골프   \n",
       "12  2018-01-04   13                 롯데백화점 관악점 /영캐주얼   \n",
       "13  2018-01-04   14                   빅마켓 금천점 /목욕용품   \n",
       "14  2018-01-04   14                    빅마켓 금천점 /침구류   \n",
       "15  2018-01-04   14                   빅마켓 금천점 /세탁용품   \n",
       "16  2018-01-04   14                    빅마켓 금천점 /속옷류   \n",
       "17  2018-01-04   14                    빅마켓 금천점 /초코렛   \n",
       "18  2018-01-04   14                   빅마켓 금천점 /푸드코트   \n",
       "19  2018-01-04   14                   빅마켓 금천점 /주방용품   \n",
       "20  2018-01-04   14                    빅마켓 금천점/키즈카페   \n",
       "21  2018-01-04   14                   빅마켓 금천점 /냉동식품   \n",
       "22  2018-01-04   14                    빅마켓 금천점 /라면류   \n",
       "23  2018-01-04   14                   빅마켓 금천점 /남섬정장   \n",
       "24  2018-01-04   14                   빅마켓 금천점 /애완용품   \n",
       "25  2018-01-04   14                 빅마켓 금천점 /건강보조용품   \n",
       "26  2018-01-04   14                    빅마켓 금천점 /화장품   \n",
       "27  2018-01-04   14                    빅마켓 금천점 /청과류   \n",
       "28  2018-01-04   14                빅마켓 금천점/키즈카페 금천점   \n",
       "29  2018-01-04   14                   빅마켓 금천점 /생활용품   \n",
       "30  2018-01-04   14                     빅마켓 금천점 /육류   \n",
       "31  2018-01-04   14                     빅마켓 금천점 /제빵   \n",
       "32  2018-01-04   14           빅마켓 금천점/쿨펫동물병원 빅마켓금천점   \n",
       "33  2018-01-04   14                     빅마켓 금천점 /주류   \n",
       "34  2018-01-04   15                    홈플러스 금천점 /식품   \n",
       "35  2018-01-04   15                  홈플러스 금천점 /문화센터   \n",
       "36  2018-01-04   15                  홈플러스 금천점 /프드코트   \n",
       "37  2018-01-04   15  홈플러스 금천점/THE FACE SHOP 홈플러스금천점   \n",
       "38  2018-01-04   16                   홈플러스 시흥점 /비식품   \n",
       "39  2018-01-04   16                  홈플러스 시흥점 /문화센터   \n",
       "\n",
       "               place_category       place_address  \n",
       "0            Department Store  서울 관악구 봉천동 738-106  \n",
       "1            Department Store   서울 관악구 봉천동 729-22  \n",
       "2            Department Store   서울 관악구 봉천동 729-22  \n",
       "3            Department Store   서울 관악구 봉천동 729-22  \n",
       "4            Department Store   서울 관악구 봉천동 729-22  \n",
       "5            Department Store   서울 관악구 봉천동 729-22  \n",
       "6   Japanese Food Restaurants   서울 관악구 봉천동 729-22  \n",
       "7            Department Store   서울 관악구 봉천동 729-22  \n",
       "8            Department Store   서울 관악구 봉천동 729-22  \n",
       "9   Japanese Food Restaurants   서울 관악구 봉천동 729-22  \n",
       "10    Korean Food Restaurants   서울 관악구 봉천동 729-22  \n",
       "11           Department Store   서울 관악구 봉천동 729-22  \n",
       "12           Department Store   서울 관악구 봉천동 729-22  \n",
       "13  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "14  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "15  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "16  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "17  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "18  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "19  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "20                  Kids Cafe     서울 금천구 가산동 60-8  \n",
       "21  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "22  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "23  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "24  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "25  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "26  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "27  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "28                  Kids Cafe   서울 금천구 독산동 295-10  \n",
       "29  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "30  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "31  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "32          Veterinary Clinic   서울 금천구 독산동 295-10  \n",
       "33  Discount Department Store   서울 금천구 독산동 295-10  \n",
       "34  Discount Department Store    서울 금천구 독산동 291-7  \n",
       "35  Discount Department Store    서울 금천구 독산동 291-7  \n",
       "36  Discount Department Store    서울 금천구 독산동 291-7  \n",
       "37             Cosmetics Shop    서울 금천구 독산동 291-7  \n",
       "38  Discount Department Store   서울 금천구 시흥동 992-47  \n",
       "39  Discount Department Store   서울 금천구 시흥동 992-47  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user3_log = new_data[new_data['hash_uid'] == 'Uru5Avt875xZfeIlo5SijjLrq4DNsrF71gZQeJXrP8I=']\n",
    "user3_log = user3_log.drop('hash_uid', axis=1)\n",
    "user3_log = user3_log[-40:]\n",
    "user3_log.reset_index(inplace=True, drop=True)\n",
    "user3_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5608277b-b2d8-4f69-8f63-97e4c0bcc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user3_log['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e2baa79-2427-4fcf-8227-80c648aafb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user3_log['place_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c75756dd-8d60-4644-a08a-51f6b1411a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user4_log = new_data[new_data['hash_uid'] == 'AoUA5eWtgKJq55332rcvAgTItFhfaFM8AXgi7MiFanQ=']\n",
    "# user4_log = user4_log.drop('hash_uid', axis=1)\n",
    "# user4_log = user4_log[-40:]\n",
    "# user4_log.reset_index(inplace=True, drop=True)\n",
    "# user4_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fd4aac96-bb68-4624-9110-72688bfd66fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user4_log['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2000d322-7564-448c-a6d4-1f749b429a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user4_log['place_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b5bd9b7-7ed2-476a-ab43-611a2335bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user_log = new_data[new_data['hash_uid'] == 'lztWsEhfW4izKDhydIQPc6sqvpXYK9VPn597KyYQUGo=']\n",
    "# ,'nSsQrLz+aRBh01NUDYnPNt7zYVus9fs132rfFXf9FA8=','Uru5Avt875xZfeIlo5SijjLrq4DNsrF71gZQeJXrP8I=','AoUA5eWtgKJq55332rcvAgTItFhfaFM8AXgi7MiFanQ=']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19cb5d41-6869-46f7-8305-d2e856688316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_ans = []\n",
    "# test_cat_ans = []\n",
    "\n",
    "# # test_date_ans = np.asarray(test_date_ans, dtype=\"object\")\n",
    "# # test_cat_ans = np.asarray(test_cat_ans, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96184ee3-08fb-4b0e-98a2-6065328bbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_visit_count_by_date = user2_log['date'].value_counts()\n",
    "# test_most_visited_date = test_visit_count_by_date.idxmax()\n",
    "\n",
    "# test_date_visited_number = len(user2_log[user2_log['date'] == test_most_visited_date])\n",
    "#     # dates_number = visit_count_by_date.tolist().count(date_visited_number)\n",
    "# test_dates_index = [i for i, e in enumerate(test_visit_count_by_date.tolist()) if e == test_date_visited_number]\n",
    "   \n",
    "# # test_most_visited_date_list = []\n",
    "# # test_most_visited_date_list.append(test_visit_count_by_date.keys().tolist()[:len(test_dates_index)])\n",
    "    \n",
    "#     # most_visited_date_ans.append(most_visited_date_list)\n",
    "#     # most_visited_date_ans = np.asarray(most_visited_date_ans, dtype=\"object\")\n",
    "# # dates = []\n",
    "# dates = test_visit_count_by_date.keys().tolist()[:len(test_dates_index)]\n",
    "\n",
    "# test_date_ans.append(dates)\n",
    "\n",
    "# test_date_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37d2747f-65f0-4655-8618-a626ce8f4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_ans = np.append(test_date_ans, ['2018-01-03', '2018-01-03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "913c49c3-73dc-41ea-8323-75c235d04ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "631e524e-7996-49cf-b1d9-b46b9ff6b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_visit_count_by_cat = user4_log['place_category'].value_counts()\n",
    "# test_most_visited_cat = test_visit_count_by_cat.idxmax()\n",
    "\n",
    "# test_cat_visited_number = len(user4_log[user3_log['place_category'] == test_most_visited_cat])\n",
    "# test_cats_index = [j for j, n in enumerate(test_visit_count_by_cat.tolist()) if n == test_cat_visited_number]\n",
    "\n",
    "# # test_most_visited_cat_list = []\n",
    "# # most_visited_cat_list.append(test_visit_count_by_cat.keys().tolist()[:len(cats_index)])\n",
    "    \n",
    "#     # most_visited_cat_ans.append(most_visited_cat_list)\n",
    "#     # most_visited_cat_ans = np.asarray(most_visited_cat_ans, dtype=\"object\")\n",
    "# test_cat_ans = np.append(test_cat_ans, test_visit_count_by_cat.keys().tolist()[:len(test_cats_index)])\n",
    "\n",
    "# test_cat_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "177c6b05-a54d-43c6-aba1-1c5d179b5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73d9a79b-0fcc-4cb7-ae9a-e5a83bbeec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cat_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "55412d03-c5d8-430c-b674-de656d913828",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "most_visited_date_ans = []\n",
    "most_visited_cat_ans = []\n",
    "\n",
    "# most_visited_date_ans = np.asarray(most_visited_date_ans, dtype=\"object\")\n",
    "# most_visited_cat_ans = np.asarray(most_visited_cat_ans, dtype=\"object\")\n",
    "\n",
    "for i in select_user_50plus:\n",
    "    # print('----- ',cnt,' -----')\n",
    "    \n",
    "    user_log = new_data[new_data['hash_uid'] == i]\n",
    "    user_log = user_log.drop('hash_uid', axis=1)\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # user_log_shuffle = user_log.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # 이후 api call에서 저장된 dataframe을 통해 로그를 보낼 예정이라면 따로 저장 필요.\n",
    "    user_log.to_csv(f'./data/subtasks_temporal/user_log/user_log_{cnt}.csv', index=False)\n",
    "    # user_log_shuffle.to_csv(f'./data/subtasks_temporal/user_log_shuffle/user_log_shuffle_{cnt}.csv', index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    visit_count_by_date = user_log['date'].value_counts()\n",
    "    most_visited_date = visit_count_by_date.idxmax()\n",
    "\n",
    "    date_visited_number = len(user_log[user_log['date'] == most_visited_date])\n",
    "    # dates_number = visit_count_by_date.tolist().count(date_visited_number)\n",
    "    dates_index = [i for i, e in enumerate(visit_count_by_date.tolist()) if e == date_visited_number]\n",
    "\n",
    "\n",
    "    dates = visit_count_by_date.keys().tolist()[:len(dates_index)]\n",
    "\n",
    "    most_visited_date_ans.append(dates)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # most_visited_date_list = []\n",
    "    # most_visited_date_list.append(visit_count_by_date.keys().tolist()[:len(dates_index)])\n",
    "    \n",
    "    \n",
    "    # most_visited_date_ans = np.append(most_visited_date_ans, most_visited_date_list)\n",
    "\n",
    "\n",
    "\n",
    "                                  \n",
    "    visit_count_by_cat = user_log['place_category'].value_counts()\n",
    "    most_visited_cat = visit_count_by_cat.idxmax()\n",
    "\n",
    "    cat_visited_number = len(user_log[user_log['place_category'] == most_visited_cat])\n",
    "    cats_index = [j for j, n in enumerate(visit_count_by_cat.tolist()) if n == cat_visited_number]\n",
    "\n",
    "    cats = visit_count_by_cat.keys().tolist()[:len(cats_index)]\n",
    "\n",
    "    most_visited_cat_ans.append(cats)\n",
    "    \n",
    "    # most_visited_cat_list = []\n",
    "    # most_visited_cat_list.append(visit_count_by_cat.keys().tolist()[:len(cats_index)])\n",
    "    \n",
    "    # # most_visited_cat_ans.append(most_visited_cat_list)\n",
    "    # # most_visited_cat_ans = np.asarray(most_visited_cat_ans, dtype=\"object\")\n",
    "    # most_visited_cat_ans = np.append(most_visited_cat_ans, most_visited_cat_list)\n",
    "    \n",
    "    \n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db8d53ed-89b0-4785-9388-039d890d9814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer를 저장해서 사용하려면 저장 필요\n",
    "# np.save('./data/subtasks_temporal/most_visited_date_ans', most_visited_date_ans)\n",
    "# np.save('./data/subtasks_temporal/most_visited_cat_ans', most_visited_cat_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56e9d227-6512-4d13-9470-df11706410fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# most_visited_cat_ans = np.load('./data/subtasks_temporal/most_visited_cat_ans.npy', allow_pickle=True)\n",
    "# most_visited_date_ans = np.load('./data/subtasks_temporal/most_visited_date_ans.npy', allow_pickle=True)\n",
    "most_visited_cat_ans = most_visited_cat_ans[:user_number]\n",
    "most_visited_date_ans = most_visited_date_ans[:user_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e2315-63d0-4ab3-8a58-4ac82bfeaa34",
   "metadata": {},
   "source": [
    "<font size=\"5\">Standard</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04bd7a33-7bed-4757-94e7-b4f8f9b99e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standard_api(system_prompt, user_prompt_q, user_prompt_a, user_log, model=\"gpt-3.5-turbo-0613\", verbose=False):\n",
    "\n",
    "#     user_prompt = user_prompt_q + '\\n' + user_log + '\\n' + user_prompt_a\n",
    "    \n",
    "#     if verbose:\n",
    "#       print(user_prompt)\n",
    "\n",
    "#     messages = [\n",
    "#                 {\"role\": \"system\", \"content\": system_prompt}, \n",
    "#                 {\"role\": \"user\", \"content\": user_prompt}\n",
    "#                 ]\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=messages,\n",
    "#         temperature=0,\n",
    "#     )\n",
    "\n",
    "#     output = response.choices[0].message.content\n",
    "#     token = response.usage.total_tokens\n",
    "    \n",
    "#     # print('answer : ', output)\n",
    "#     # print('token : ', token)\n",
    "\n",
    "#     return output, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a67a8d32-eb3a-434e-a791-4459b033bf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 -------\n",
      "------ 1 -------\n",
      "------ 2 -------\n",
      "------ 3 -------\n",
      "------ 4 -------\n",
      "------ 5 -------\n",
      "------ 6 -------\n",
      "------ 7 -------\n",
      "------ 8 -------\n",
      "------ 9 -------\n",
      "------ 10 -------\n",
      "------ 11 -------\n",
      "------ 12 -------\n",
      "------ 13 -------\n",
      "------ 14 -------\n",
      "------ 15 -------\n",
      "------ 16 -------\n",
      "------ 17 -------\n",
      "------ 18 -------\n",
      "------ 19 -------\n",
      "------ 20 -------\n",
      "------ 21 -------\n",
      "------ 22 -------\n",
      "------ 23 -------\n",
      "------ 24 -------\n",
      "------ 25 -------\n",
      "------ 26 -------\n",
      "------ 27 -------\n",
      "------ 28 -------\n",
      "------ 29 -------\n",
      "------ 30 -------\n",
      "------ 31 -------\n",
      "------ 32 -------\n",
      "------ 33 -------\n",
      "------ 34 -------\n",
      "------ 35 -------\n",
      "------ 36 -------\n",
      "------ 37 -------\n",
      "------ 38 -------\n",
      "------ 39 -------\n",
      "------ 40 -------\n",
      "------ 41 -------\n",
      "------ 42 -------\n",
      "------ 43 -------\n",
      "------ 44 -------\n",
      "------ 45 -------\n",
      "------ 46 -------\n",
      "------ 47 -------\n",
      "------ 48 -------\n",
      "------ 49 -------\n",
      "------ 50 -------\n",
      "------ 51 -------\n",
      "------ 52 -------\n",
      "------ 53 -------\n",
      "------ 54 -------\n",
      "------ 55 -------\n",
      "------ 56 -------\n",
      "------ 57 -------\n",
      "------ 58 -------\n",
      "------ 59 -------\n",
      "------ 60 -------\n",
      "------ 61 -------\n",
      "------ 62 -------\n",
      "------ 63 -------\n",
      "------ 64 -------\n",
      "------ 65 -------\n",
      "------ 66 -------\n",
      "------ 67 -------\n",
      "------ 68 -------\n",
      "------ 69 -------\n",
      "------ 70 -------\n",
      "------ 71 -------\n",
      "------ 72 -------\n",
      "------ 73 -------\n",
      "------ 74 -------\n",
      "------ 75 -------\n",
      "------ 76 -------\n",
      "------ 77 -------\n",
      "------ 78 -------\n",
      "------ 79 -------\n",
      "------ 80 -------\n",
      "------ 81 -------\n",
      "------ 82 -------\n",
      "------ 83 -------\n",
      "------ 84 -------\n",
      "------ 85 -------\n",
      "------ 86 -------\n",
      "------ 87 -------\n",
      "------ 88 -------\n",
      "------ 89 -------\n",
      "------ 90 -------\n",
      "------ 91 -------\n",
      "------ 92 -------\n",
      "------ 93 -------\n",
      "------ 94 -------\n",
      "------ 95 -------\n",
      "------ 96 -------\n",
      "------ 97 -------\n",
      "------ 98 -------\n",
      "------ 99 -------\n",
      "------ 100 -------\n",
      "------ 101 -------\n",
      "------ 102 -------\n",
      "------ 103 -------\n",
      "------ 104 -------\n",
      "------ 105 -------\n",
      "------ 106 -------\n",
      "------ 107 -------\n",
      "------ 108 -------\n",
      "------ 109 -------\n",
      "------ 110 -------\n",
      "------ 111 -------\n"
     ]
    }
   ],
   "source": [
    "# ask_date_dfloader = []\n",
    "ask_date_dfloader_wont = []\n",
    "# ask_date_json = []\n",
    "ask_date_json_wont = []\n",
    "ask_date_tabsep = []\n",
    "ask_date_commasep = []\n",
    "ask_date_totext = []\n",
    "ask_date_totextvisited = []\n",
    "\n",
    "system_prompt = 'You only answer in the following format: year-month-day. Don\\'t answer in a sentence.'\n",
    "\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('------', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_lookup/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # dates_to_reply = str(dates_ans[i])\n",
    "\n",
    "    user_prompt = 'When is the date when the person visited ' + str(the_places[i]) + '? If you have several days, answer only one date.'\n",
    "\n",
    "    \n",
    "    # print('format 1')\n",
    "    # user_log_str = user_log.to_string()\n",
    "    # user_log_form1 = 'index' + re.sub('  +', ',', user_log_str)\n",
    "    # user_log_form1 = re.sub('date hour', 'date,hour', user_log_form1)\n",
    "    # output, tok = gpt_api(system_prompt, user_prompt, dfloader(user_log))\n",
    "    # ask_date_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    # form2_df = user_log[['place_name', 'place_category', 'place_address', 'date', 'hour']]\n",
    "    # form2_df = form2_df.sort_values('place').reset_index(drop=True)\n",
    "    # user_log_form2_str = form2_df.to_string()\n",
    "    # user_log_form2 = 'index' + re.sub('  +', ',', user_log_form2_str)\n",
    "    # user_log_form2 = re.sub('date hour', 'date,hour', user_log_form2)\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, dfloader_wont(user_log))\n",
    "    ask_date_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # user_log.to_json(f'./data/subtasks_lookup/user_log/user_log_{i}_json_temp.json', orient = 'index')\n",
    "    # with open(f'./data/subtasks_lookup/user_log/user_log_{i}_json_temp.json') as f:\n",
    "    #     user_log_form3 = json.load(f)\n",
    "    # output, tok = gpt_api(system_prompt, user_prompt_q, user_prompt_a, json(user_log))\n",
    "    # ask_date_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    # form2_df.to_json(f'./data/subtasks_lookup/user_log/user_log_{i}_json_space.json', orient = 'index')\n",
    "    # with open(f'./data/subtasks_lookup/user_log/user_log_{i}_json_space.json') as f:\n",
    "    #     user_log_form4 = json.load(f)\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, json_wont(user_log))\n",
    "    ask_date_json_wont.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, tabsep(user_log))\n",
    "    ask_date_tabsep.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, commasep(user_log))\n",
    "    ask_date_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totext(user_log))\n",
    "    ask_date_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totextvisited(user_log))\n",
    "    ask_date_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7751a130-4ae3-48f3-b643-08fdcee4633b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['2017-12-31'] 2017-12-18\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] 2017-12-25\n",
      "['2017-12-28', '2018-01-02', '2018-01-04', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29', '2017-12-29'] 2017-12-28\n",
      "['2017-12-25', '2018-01-01'] 2018-01-03\n",
      "['2018-01-02'] 2017-12-26\n",
      "['2017-12-29'] 2017-12-27\n",
      "['2017-12-31'] 2018-01-04\n",
      "['2017-12-22'] 2017-12-21\n",
      "['2018-01-02'] 2017-12-29\n",
      "['2018-01-03'] 2017-12-26\n",
      "['2017-12-22', '2017-12-22'] 2017-12-29\n",
      "['2017-12-10', '2018-01-05'] 2017-12-09\n",
      "['2018-01-04'] 2018-01-05\n",
      "['2018-01-04'] 2018-01-05\n",
      "['2017-12-28', '2017-12-28'] 2017-12-26\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] 2017-12-26\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2017-12-21'] 2017-12-08\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] 2018-01-04\n",
      "['2018-01-01'] 2017-12-29\n",
      "['2018-01-03'] 2018-01-02\n",
      "['2017-12-18'] 2017-12-11\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] 2017-12-19\n",
      "['2017-12-29', '2018-01-04'] 2017-12-26\n",
      "['2017-12-27'] 2017-12-28\n",
      "['2017-12-28'] 2017-12-29\n",
      "['2018-01-01'] 2018-01-02\n",
      "['2017-12-31', '2017-12-31'] 2017-12-28\n",
      "['2017-12-27'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-31\n",
      "['2017-12-28'] 2017-12-25\n",
      "['2017-12-16'] 2017-12-15\n",
      "['2017-12-15', '2017-12-15'] 2017-12-10\n",
      "['2018-01-01'] 2017-12-30\n",
      "['2017-12-14'] 2017-12-13\n",
      "['2017-12-17'] 2017-12-12\n",
      "['2018-01-05'] 2017-12-17\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] 2017-12-11\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] 2018-01-02\n",
      "['2017-12-31'] 2017-12-30\n",
      "['2017-12-23'] 2017-12-22\n",
      "json_wont\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-27'] 2017-12-28\n",
      "['2018-01-04'] 2018-01-05\n",
      "['2018-01-01'] 2018-01-02\n",
      "['2018-01-01'] 2018-01-02\n",
      "['2017-12-13'] 2017-12-18\n",
      "tabsep\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-27'] 2017-12-28\n",
      "['2018-01-01'] 2018-01-02\n",
      "['2018-01-01'] 2018-01-02\n",
      "commasep\n",
      "['2018-01-02'] 2017-12-27\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-27'] 2017-12-28\n",
      "['2018-01-01'] 2017-12-10\n",
      "['2018-01-01'] 2018-01-02\n",
      "['2017-12-17'] 2017-12-28\n",
      "totext\n",
      "['2018-01-02'] 2018-01-05\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-15'] 2017-12-28\n",
      "totextvisited\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-15', '2017-12-18', '2018-01-04'] 2017-12-13\n"
     ]
    }
   ],
   "source": [
    "# ask_date_dfloader_score = []\n",
    "ask_date_dfloader_wont_score = []\n",
    "# ask_date_json_score = []\n",
    "ask_date_json_wont_score = []\n",
    "ask_date_tabsep_score = []\n",
    "ask_date_commasep_score = []\n",
    "ask_date_totext_score = []\n",
    "ask_date_totextvisited_score = []\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(possible_dates_ans, ask_date_dfloader):\n",
    "#     cot_ask_date_dfloader_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(possible_dates_ans, ask_date_dfloader_wont):\n",
    "    ask_date_dfloader_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(possible_dates_ans, cot_ask_date_json):\n",
    "#     cot_ask_date_json_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(possible_dates_ans, ask_date_json_wont):\n",
    "    ask_date_json_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(possible_dates_ans, ask_date_tabsep):\n",
    "    ask_date_tabsep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(possible_dates_ans, ask_date_commasep):\n",
    "    ask_date_commasep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(possible_dates_ans, ask_date_totext):\n",
    "    ask_date_totext_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(possible_dates_ans, ask_date_totextvisited):\n",
    "    ask_date_totextvisited_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58a2e0a4-b60d-4e9b-b41a-fc5856bba130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n",
      "0.9464285714285714\n",
      "0.9642857142857143\n",
      "0.9464285714285714\n",
      "0.9732142857142857\n",
      "0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "# print(sum(ask_date_dfloader_score)/user_number)\n",
    "print(sum(ask_date_dfloader_wont_score)/user_number)\n",
    "# print(sum(ask_date_json_score)/user_number)\n",
    "print(sum(ask_date_json_wont_score)/user_number)\n",
    "print(sum(ask_date_tabsep_score)/user_number)\n",
    "print(sum(ask_date_commasep_score)/user_number)\n",
    "print(sum(ask_date_totext_score)/user_number)\n",
    "print(sum(ask_date_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cecd7090-b339-4d58-8b12-469cd7004e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 -------\n",
      "------ 1 -------\n",
      "------ 2 -------\n",
      "------ 3 -------\n",
      "------ 4 -------\n",
      "------ 5 -------\n",
      "------ 6 -------\n",
      "------ 7 -------\n",
      "------ 8 -------\n",
      "------ 9 -------\n",
      "------ 10 -------\n",
      "------ 11 -------\n",
      "------ 12 -------\n",
      "------ 13 -------\n",
      "------ 14 -------\n",
      "------ 15 -------\n",
      "------ 16 -------\n",
      "------ 17 -------\n",
      "------ 18 -------\n",
      "------ 19 -------\n",
      "------ 20 -------\n",
      "------ 21 -------\n",
      "------ 22 -------\n",
      "------ 23 -------\n",
      "------ 24 -------\n",
      "------ 25 -------\n",
      "------ 26 -------\n",
      "------ 27 -------\n",
      "------ 28 -------\n",
      "------ 29 -------\n",
      "------ 30 -------\n",
      "------ 31 -------\n",
      "------ 32 -------\n",
      "------ 33 -------\n",
      "------ 34 -------\n",
      "------ 35 -------\n",
      "------ 36 -------\n",
      "------ 37 -------\n",
      "------ 38 -------\n",
      "------ 39 -------\n",
      "------ 40 -------\n",
      "------ 41 -------\n",
      "------ 42 -------\n",
      "------ 43 -------\n",
      "------ 44 -------\n",
      "------ 45 -------\n",
      "------ 46 -------\n",
      "------ 47 -------\n",
      "------ 48 -------\n",
      "------ 49 -------\n",
      "------ 50 -------\n",
      "------ 51 -------\n",
      "------ 52 -------\n",
      "------ 53 -------\n",
      "------ 54 -------\n",
      "------ 55 -------\n",
      "------ 56 -------\n",
      "------ 57 -------\n",
      "------ 58 -------\n",
      "------ 59 -------\n",
      "------ 60 -------\n",
      "------ 61 -------\n",
      "------ 62 -------\n",
      "------ 63 -------\n",
      "------ 64 -------\n",
      "------ 65 -------\n",
      "------ 66 -------\n",
      "------ 67 -------\n",
      "------ 68 -------\n",
      "------ 69 -------\n",
      "------ 70 -------\n",
      "------ 71 -------\n",
      "------ 72 -------\n",
      "------ 73 -------\n",
      "------ 74 -------\n",
      "------ 75 -------\n",
      "------ 76 -------\n",
      "------ 77 -------\n",
      "------ 78 -------\n",
      "------ 79 -------\n",
      "------ 80 -------\n",
      "------ 81 -------\n",
      "------ 82 -------\n",
      "------ 83 -------\n",
      "------ 84 -------\n",
      "------ 85 -------\n",
      "------ 86 -------\n",
      "------ 87 -------\n",
      "------ 88 -------\n",
      "------ 89 -------\n",
      "------ 90 -------\n",
      "------ 91 -------\n",
      "------ 92 -------\n",
      "------ 93 -------\n",
      "------ 94 -------\n",
      "------ 95 -------\n",
      "------ 96 -------\n",
      "------ 97 -------\n",
      "------ 98 -------\n",
      "------ 99 -------\n",
      "------ 100 -------\n",
      "------ 101 -------\n",
      "------ 102 -------\n",
      "------ 103 -------\n",
      "------ 104 -------\n",
      "------ 105 -------\n",
      "------ 106 -------\n",
      "------ 107 -------\n",
      "------ 108 -------\n",
      "------ 109 -------\n",
      "------ 110 -------\n",
      "------ 111 -------\n"
     ]
    }
   ],
   "source": [
    "# cot_ask_place_dfloader = []\n",
    "ask_place_dfloader_wont = []\n",
    "# cot_ask_place_json = []\n",
    "ask_place_json_wont = []\n",
    "ask_place_tabsep = []\n",
    "ask_place_commasep = []\n",
    "ask_place_totext = []\n",
    "ask_place_totextvisited = []\n",
    "\n",
    "system_prompt = 'You only answer in the following format: placename. Don\\'t answer in a sentence.'\n",
    "\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('------', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_lookup/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # dates_to_reply = str(dates_ans[i])\n",
    "\n",
    "    user_prompt = 'Where did the person visited on ' + str(the_dates[i]) + '? If you have several places, answer only one place.'\n",
    "    \n",
    "    # print('format 1')\n",
    "    # user_log_str = user_log.to_string()\n",
    "    # user_log_form1 = 'index' + re.sub('  +', ',', user_log_str)\n",
    "    # user_log_form1 = re.sub('date hour', 'date,hour', user_log_form1)\n",
    "    # output, tok = cot_api(system_prompt, user_prompt_q, user_prompt_a, dfloader(user_log))\n",
    "    # cot_ask_place_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    # form2_df = user_log[['place', 'category', 'address', 'date', 'hour']]\n",
    "    # form2_df = form2_df.sort_values('place').reset_index(drop=True)\n",
    "    # user_log_form2_str = form2_df.to_string()\n",
    "    # user_log_form2 = 'index' + re.sub('  +', ',', user_log_form2_str)\n",
    "    # user_log_form2 = re.sub('date hour', 'date,hour', user_log_form2)\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, dfloader_wont(user_log))\n",
    "    ask_place_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # user_log.to_json(f'./data/subtasks_lookup/user_log/user_log_{i}_json_temp.json', orient = 'index')\n",
    "    # with open(f'./data/subtasks_lookup/user_log/user_log_{i}_json_temp.json') as f:\n",
    "    #     user_log_form3 = json.load(f)\n",
    "    # output, tok = cot_api(system_prompt, user_prompt_q, user_prompt_a, json(user_log))\n",
    "    # cot_ask_place_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    # form2_df.to_json(f'./data/subtasks_lookup/user_log/user_log_{i}_json_space.json', orient = 'index')\n",
    "    # with open(f'./data/subtasks_lookup/user_log/user_log_{i}_json_space.json') as f:\n",
    "    #     user_log_form4 = json.load(f)\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, json_wont(user_log))\n",
    "    ask_place_json_wont.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, tabsep(user_log))\n",
    "    ask_place_tabsep.append(output)\n",
    "    \n",
    "    output, tok = gpt_api(system_prompt, user_prompt, commasep(user_log))\n",
    "    ask_place_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totext(user_log))\n",
    "    ask_place_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totextvisited(user_log))\n",
    "    ask_place_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16db575d-e4ab-4aa2-9088-dfff18a8fc4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 4-3', '서울5호선 왕십리역 방화행 6-4', '서울7호선 장승배기역 부평구청 방면 2-2', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 351420', '서울7호선 고속터미널역 장암 방면 4-4'] 서울5호선 마장역 방화행 2-2\n",
      "['미소식품가정식백반', 'TKS CAFE'] 서울4호선 충무로역 오이도방면 7-1\n",
      "['마돈나노래연습장', 'GS25 문래시티점'] 스타벅스 하이테크시티점\n",
      "['미니스톱 신천역점', '미니스톱 신천역점', '허수아비돈까스쌀국수 대학동점'] 투썸플레이스 서울대역중앙점\n",
      "['스타벅스 잠실점', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너'] 한사랑의원 내과.소아과.이비인후과.피부과\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['강남성결교회 /사무실', 'GS25 논현진실점', '강남성결교회 /사무실', 'GS25 논현진실점', '서울8호선 잠실역 암사방면 2-2'] 스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바\n",
      "['미자식당', '미자식당', '일신부동산', '크린업24 송파점', '뚜레쥬르 배명사거리점', '이디야 송파하비오점', 'Watsons 파크하비오점'] 스타벅스 송파아이파크점\n",
      "['강가 역삼점'] HANS 반포점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울9호선 동작역 종합운동장행 1-1\n",
      "['분당선 351939'] 스타칼리휘트니스\n",
      "['현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점'] 3POP PC #116055#서울#강남구#대치동\n",
      "['미소야 서초점'] 서울2호선 종합운동장역 내선 3-1\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 서울2호선 선릉역 외선 7-1\n",
      "['서울2호선 신당역 내선 5-1', '올리브영 강변역점'] 서울5호선 을지로4가역 방화행 7-4 / 상일동 마천행 2-1\n",
      "['서울4호선 신용산역 당고개방면 9-1', '서울4호선 숙대입구역 당고개방면 9-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4'] 현대백화점 무역센터점 /영캐주얼\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점/딥티크 코엑스몰점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['MAD COFFEE', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울4호선 총신대입구(이수)역 오이도행 3-1', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4'] GS25 대치삼성점\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 분당선 강남구청역 왕십리방면 6-4\n",
      "['이디야 서울고교점'] 서울2호선 삼성역 내선 5-1 / 외선 6-4\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /원더브라/쥬스스타', '스타필드 코엑스몰점/맥도날드 코엑스점', \"스타필드 코엑스몰점/IT'S SKIN 코엑스점\", '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이'] 파리바게뜨 카페강남중앙점\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타필드 코엑스몰점 /가가홈&차일드/안동찜닭&해물떡집/반하는보쌈\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 서울1호선 영등포역 동인천 천안급행 2-4\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['GS25 방화샤르망점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/THE BODY SHOP 롯데백화점김포공항점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '서울5호선 김포공항역 방화행 2-2', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /토이저러스 외'] 맥도날드 염창DT점\n",
      "['동명공인중개사', 'CU 역삼포스틸점', '파리바게뜨 역삼특허청점', '서울2호선 강남역 내선 5-1', 'KEEP YOUR FORK /푸드코트', '스타벅스 포도몰점', '포도몰 /남성의류', '이불나라'] IFC몰/부츠\n",
      "['서울5호선 아차산역 방화행 6-4', '서울7호선 먹골역 장암 방면 6-4', '롯데리아 먹골역점', '서울6호선 태릉입구역 응암순환행 4-4', '서울1호선 대방역 인천 신창행 5-1 / 용산급행 6-4', '서울6호선 동묘앞역 봉화산행 8-3 / 응암순환행 1-2', '서울4호선 삼각지역 오이도방면 9-1', '서울6호선 한강진역 응암순환행 4-4', '분당선 강남구청역 수원방면 5-3'] 서울8호선 가락시장역 모란방면 2-2\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울6호선 월드컵경기장역 봉화산행 2-2\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/에잇세컨즈 IFC몰점\n",
      "['세븐일레븐 도곡2호점', '세븐일레븐 도곡스타점'] 세븐일레븐 암사희망점\n",
      "['서울8호선 복정역 /암사방면2-2', '롯데월드몰/8seconds 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '롯데월드몰/UNIQLO 롯데월드몰점', '스타필드 코엑스몰점 /자라/아르마니진', '스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트'] 서울2호선 잠실역 외선 3-1\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 스타필드 코엑스몰점\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 롯데마트 잠실점 /비식품코너\n",
      "['베테랑 센트럴지점', '이마트 자양점 /식품/비식품/푸드코트', '이마트 자양점/몰리스펫샵 이마트자양점'] 서울7호선 고속터미널역 장암 방면 6-4\n",
      "['GS25 S강남역1호점', 'REFESH COFFEE&JUICE'] Cafe Queen's Amore\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 서울 중구 을지로2가 199-74\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 뉴코아아울렛 강남점 2관/Cafe Lugo 반포점\n",
      "['분당선 351132', 'bm1001 아현역점', '서울2호선 동대문역사문화공원역 외선 9-1', '분당선 351132', '미니스톱 M아현역점', '분당선 351232', '경의중앙선 왕십리역 문산방면 8-3/지평방면 1-2', 'bm1001 아현역점', '보루네오 북아현점', '동양사무용가구', '리자가구', '보르네오 아현전시점', '동양사무용가구', '롯데리아 아현점', '보루네오 북아현점', '아현역 공인중개사', '서울2호선 신촌역 외선 7-1', '서울2호선 신촌역 내선 9-1', '서울2호선 신촌역 외선 5-1', '던킨도너츠 나라키움점'] 분당선 351424\n",
      "['예스자이엘라부동산'] 다이소 대방남부점\n",
      "['쟝블랑제리', '버거킹 낙성대역점'] 파르나스몰/18번완당명가\n",
      "['롯데리아 월드점', '투썸플레이스 잠실롯데점', '공항철도 2220', '롯데리아 월드점', '자연별곡 잠실웰빙점'] 스타필드 코엑스몰점\n",
      "['MINI GOLD 돈암점'] 스타벅스 성신여대정문점\n",
      "['서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 서울역발 문산행 2-2'] 서울 강남구 삼성동 152-27\n",
      "['바르미샤브샤브 삼성역점', 'Park et Table', 'GS25 대치그린점'] 스타필드 코엑스몰점/스위트스페이스 코엑스몰점\n",
      "['IFC몰/유니클로 IFC몰점', 'IFC몰/스타벅스 여의도IFC몰(B3)점', 'IFC몰/MANGO 여의도IFC몰점', 'IFC몰/Aesop IFC서울점', '서울9호선 여의도역 개화 방면 1-1', '서울2호선 당산역 내선 3-1', '메이퓨어의원 /피부과', '서울2호선 2795', '서울7호선 대림역 장암 방면 4-4'] cafe MAMAS 청계천점\n",
      "['스타벅스 송파구청점', '참숯구이 황토골', '챈서리', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', 'CGV 중계점', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', '투썸플레이스 중계CGV스윗바점'] 현대시티아울렛 동대문점\n",
      "['서울8호선 암사역 모란방면 2-2', '서울2호선 종합운동장역 내선 9-1', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 안국점', '서울3호선 안국역 대화행 7-1 / 오금행 4-4', 'YES 당구장 /당구장', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 마로니에공원점', 'GS25 암사역점', '서울8호선 천호역 암사방면 2-2'] 스타필드 코엑스몰점/CJ푸드월드 코엑스몰점/방콕9/비비고/차이나팩토리/제일제면소/투썸플레이스\n",
      "['서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1'] 서울 중구 을지로7가 133\n",
      "['서울4호선 이촌역 오이도방면 3-1', '서울2호선 사당역 외선 7-1', 'Art Billiard Club', '깐부치킨 서초삼성타운점'] 스타필드 코엑스몰점/메가박스 코엑스몰점/매표소\n",
      "['서울9호선 노들역 종합운동장 방면 1-1', '엔제리너스 사당역점'] 파리바게뜨 신도림역점\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['스타벅스 대한극장점', '스타벅스 대한극장점'] KOPITIAM\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] 서울2호선 선릉역 외선 5-1\n",
      "['서울1호선 창동역 인천 신창행 9-1', '뉴욕화이트치과의원 치과', 'ARISTA COFFEE 선릉2호점', '장수가 선릉점'] 롯데백화점 잠실점 식품/푸드에비뉴\n",
      "['서울5호선 군자역 방화행 2-4 / 상일동 마천행 6-4', '투썸플레이스 여의도점', '서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3', '서울5호선 길동역 상일동행 6-4', '서울5호선 5549'] 서울9호선 고속터미널역 종합운동장 방면 2-4\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] 던킨도너츠 시청역점\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점/STUDIO TOMBOY', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 종합운동장역 외선 7-1'] 서울4호선 노원역 오이도방면 3-1\n",
      "['파리바게뜨 서울적십자병원점', 'CU 강북삼성병원 2호점', 'SHILLA MYUNGGUA 신관/강북삼성병원점'] 서울4호선 회현역 당고개방면 3-1/오이도방면 8-4\n",
      "['분당선 351342', '분당선 강남구청역 수원방면 3-4'] 분당선 351441\n",
      "['햇빛병원 /내과'] 스타벅스 미아점\n",
      "['CAFÉ des VERTS 선릉점', '아비꼬카레 신천점'] SUPER COFFEE 선릉로점\n",
      "['스타벅스 청담영동대로점'] 서울2호선 역삼역 외선 9-1\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점 /ZARA/A\n",
      "['주민약국'] 스타필드 코엑스몰점/BUTTER 코엑스점\n",
      "['제일제면소 서울역사점', '롯데마트 서울역점 /식품', '롯데마트 서울역점 /비식품'] 신촌세브란스병원 영상의학과\n",
      "['서울3호선 남부터미널역 대화방면 9-1', '행복한수약국', '수약국', 'NIKE 강남점', 'NIKE 강남점', 'NIKE 강남점', 'NIKE 강남점'] 서울2호선 교대역 내선 3-1\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 코스트코 양평점 / 야채코너\n",
      "['서울8호선 잠실역 암사방면 4-4', 'KB국민은행 방이동지점', 'KB국민은행 방이동지점', 'GS25 잠실2점', '세븐일레븐 방이한양점', 'GS25 방배효령점', '미니스톱 방배본점'] 롯데월드몰/BLACK\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점 /식품\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 스타벅스 센트럴시티점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2', '소래포구 성수점', '서울2호선 종합운동장역 외선 9-1', '소래포구 성수점', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/카카오프렌즈 스타필드코엑스몰점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/18번완당명가', '서울2호선 신림역 내선 2-3 / 외선 9-2'] NATURE REPUBLIC 강남지하상가점\n",
      "['파르나스몰/GS25 파르나스타워점', '서울6호선 보문역 봉화산행 4-3 / 응암순환행 5-1', '서울4호선 창동역 오이도방면 9-1', '우이신설선 성신여대입구역 신설동방면 1-1', '서울2호선 한양대역 내선 7-1'] 서울2호선 신설동역 지선 성수행 2-1\n",
      "['덕수궁피자', '할리스커피 광화문LG점', '아이파크몰 /디지털소형가전/토이하비/디지털관', '여로집 영등포본관/오징어볶음', '서울1호선 용산역 / 경의중앙선 용산역 동인천 천안급행 2-1 / 문산행 8-4'] 서울5호선 서대문역 방화행 4-4 / 상일동 마천행 4-4\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타벅스 종로구청점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] ROK'S PLATE\n",
      "json_wont\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 서울2호선 잠실나루역 외선 3-1\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울4호선 사당역 당고개방면 7-1/오이도방면 4-4\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 서울2호선 선릉역 외선 7-1\n",
      "['서울4호선 신용산역 당고개방면 9-1', '서울4호선 숙대입구역 당고개방면 9-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4'] 서울4호선 사당역 당고개방면 9-1\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점/딥티크 코엑스몰점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 분당선 강남구청역 왕십리방면 6-4\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울 구로구 구로동 182-13\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 서울1호선 가산디지털단지역 신창방면 7-1\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 스타필드 코엑스몰점\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 서울3호선 구파발역 대화행 8-4 / 오금행 3-1\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 스타벅스 센트럴시티점\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타벅스 종로구청점\n",
      "tabsep\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점'] 스타필드 코엑스몰점\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 서울 강서구 등촌동 477-1\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2', '소래포구 성수점', '서울2호선 종합운동장역 외선 9-1', '소래포구 성수점', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/카카오프렌즈 스타필드코엑스몰점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/18번완당명가', '서울2호선 신림역 내선 2-3 / 외선 9-2'] 스타필드 코엑스몰점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "commasep\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /서비스 라운지\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울4호선 사당역 당고개방면 7-1/오이도방면 4-4\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점/딥티크 코엑스몰점\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 서울 강남구 논현동 279-92\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['동명공인중개사', 'CU 역삼포스틸점', '파리바게뜨 역삼특허청점', '서울2호선 강남역 내선 5-1', 'KEEP YOUR FORK /푸드코트', '스타벅스 포도몰점', '포도몰 /남성의류', '이불나라'] 서울 강남구 역삼동 825-25\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울 구로구 구로동 182-13\n",
      "['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점'] 스타필드 코엑스몰점\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 서울1호선 가산디지털단지역 신창방면 7-1\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 스타필드 코엑스몰점\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 서울3호선 구파발역 대화행 8-4 / 오금행 3-1\n",
      "['MINI GOLD 돈암점'] 스타벅스 성신여대점\n",
      "['서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1'] 서울4호선 동대문역사문화공원역\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['스타벅스 대한극장점', '스타벅스 대한극장점'] KOPITIAM\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] 서울 강동구 성내동 396-19\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 서울 강서구 등촌동 477-1\n",
      "['스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/cafe imt 코엑스몰점', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/예가낙지마을', '오징어세상 삼성점', '스타필드 코엑스몰점 /반하는보쌈/ABC-mart/래핑차일드', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /OYSHO/BUTTER', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /럭키슈에뜨/아메리칸이글/별마당도서관', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '오징어세상 삼성점', '서울야시장', '오징어세상 삼성점', '서울야시장', '서울야시장'] 스타필드 코엑스몰점\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 서울 서초구 반포동 19-3\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2', '소래포구 성수점', '서울2호선 종합운동장역 외선 9-1', '소래포구 성수점', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/카카오프렌즈 스타필드코엑스몰점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/18번완당명가', '서울2호선 신림역 내선 2-3 / 외선 9-2'] 스타필드 코엑스몰점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "totext\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 강남삼성라마르성형외과\n",
      "['분당선 351939'] 현대백화점 무역센터점 /남성패션\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 서울2호선 선릉역 외선 7-1\n",
      "['서울2호선 신당역 내선 5-1', '올리브영 강변역점'] 서울2호선 종합운동장역 외선 3-1\n",
      "['서울5호선 5756', '서울5호선 5152'] 배스킨라빈스 사당역1호점\n",
      "['서울3호선 일원역 대화방면 3-1', '서울3호선 일원역 대화방면 5-1', '서울3호선 양재역 대화방면 7-1', '애니벅스 애니학원 강남본점', '에스프레소 퍼블릭', '애니벅스 애니학원 강남본점', '서울3호선 양재역 오금방면 5-1'] 서울 강남구 역삼동 618-15\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 서울 강남구 논현동 279-92\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 서울 관악구 신림동 1467-10\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 서울2호선 삼성역 내선 3-1 / 외선 8-4\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울 구로구 구로동 182-13\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 서울3호선 구파발역 대화행 8-4 / 오금행 3-1\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 뉴코아아울렛 강남점 2관/Cafe Lugo 반포점\n",
      "['쟝블랑제리', '버거킹 낙성대역점'] 파리바게뜨 역삼스타점\n",
      "['롯데슈퍼 성내점', 'GS25 S6안암역점', '고려대학교 안암병원 척추센테/통증센테', '고려대학교 안암병원 진단검사의학과', '고려대학교 안암병원 척추센테/통증센테', '고려대학교 안암병원 이비인후과/두경부암센타', '고려대학교 안암병원 척추센테/통증센테'] 스타벅스 잠실대교남단점\n",
      "['서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 서울역발 문산행 2-2'] 서울 은평구 수색동 81\n",
      "['서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1'] 서울 마포구 도화동 25-13\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['스타벅스 청담영동대로점'] 서울 강남구 청담동 132-1\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 서울5호선 영등포시장역\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 서울 강서구 등촌동 477-1\n",
      "['서울8호선 잠실역 암사방면 4-4', 'KB국민은행 방이동지점', 'KB국민은행 방이동지점', 'GS25 잠실2점', '세븐일레븐 방이한양점', 'GS25 방배효령점', '미니스톱 방배본점'] 서울 송파구 신천동 27\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타벅스 종로구청점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "totextvisited\n",
      "['경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 4-3', '서울5호선 왕십리역 방화행 6-4', '서울7호선 장승배기역 부평구청 방면 2-2', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 351420', '서울7호선 고속터미널역 장암 방면 4-4'] 서울5호선 왕십리역 상일동 마천행 2-2\n",
      "['요거프레소 동덕여대점', '요거프레소 동덕여대점', '요거프레소 동덕여대점', '요거프레소 동덕여대점', '요거프레소 동덕여대점'] 파르나스몰 /마리메꼬/곤트란쉐리에\n",
      "['미소식품가정식백반', 'TKS CAFE'] 서울4호선 충무로역 오이도방면 7-1\n",
      "['스타벅스 잠실점', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너'] 한사랑의원 내과.소아과.이비인후과.피부과\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['커피빈 대치한티점', '분당선 복정역 수원방면 6-4', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '올바른영어 학원', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '이디야 한티역점'] 1357철판삼겹\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['강남성결교회 /사무실', 'GS25 논현진실점', '강남성결교회 /사무실', 'GS25 논현진실점', '서울8호선 잠실역 암사방면 2-2'] 서울 강남구 삼성동 159\n",
      "['강가 역삼점'] 맥도날드 양재점\n",
      "['분당선 351939'] 현대백화점 무역센터점 /남성패션\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 서울2호선 선릉역 외선 7-1\n",
      "['서울2호선 신당역 내선 5-1', '올리브영 강변역점'] 서울 중구 신당동 99\n",
      "['서울4호선 신용산역 당고개방면 9-1', '서울4호선 숙대입구역 당고개방면 9-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4'] 서울역\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점/딥티크 코엑스몰점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 분당선 강남구청역 왕십리방면 6-4\n",
      "['이디야 서울고교점'] 서울3호선 충무로역 오금방면 5-1\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 서울9호선 노량진역 종합운동장 방면 2-4\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['GS25 방화샤르망점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/THE BODY SHOP 롯데백화점김포공항점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '서울5호선 김포공항역 방화행 2-2', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /토이저러스 외'] 맥도날드 염창DT점\n",
      "['동명공인중개사', 'CU 역삼포스틸점', '파리바게뜨 역삼특허청점', '서울2호선 강남역 내선 5-1', 'KEEP YOUR FORK /푸드코트', '스타벅스 포도몰점', '포도몰 /남성의류', '이불나라'] IFC몰/부츠\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울9호선 신논현역 개화 방면 1-1\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/DESIGN SKIN IFC몰점\n",
      "['서울8호선 복정역 /암사방면2-2', '롯데월드몰/8seconds 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '롯데월드몰/UNIQLO 롯데월드몰점', '스타필드 코엑스몰점 /자라/아르마니진', '스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트'] 서울2호선 잠실역 외선 3-1\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 서울1호선 가산디지털단지역 신창방면 7-1\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 서울 중구 을지로2가 199-74\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 뉴코아아울렛 강남점 2관/Cafe Lugo 반포점\n",
      "['쟝블랑제리', '버거킹 낙성대역점'] 파리바게뜨 역삼스타점\n",
      "['서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 서울역발 문산행 2-2'] 미성양꼬치 삼성점\n",
      "['스타벅스 송파구청점', '참숯구이 황토골', '챈서리', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', 'CGV 중계점', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', '투썸플레이스 중계CGV스윗바점'] 현대시티아울렛 동대문점\n",
      "['서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1'] 서울 마포구 도화동 25-13\n",
      "['서울4호선 이촌역 오이도방면 3-1', '서울2호선 사당역 외선 7-1', 'Art Billiard Club', '깐부치킨 서초삼성타운점'] GS25 LG유플러스 용산사옥점\n",
      "['서울9호선 노들역 종합운동장 방면 1-1', '엔제리너스 사당역점'] 서울 동작구 본동 126-6\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['스타벅스 대한극장점', '스타벅스 대한극장점'] KOPITIAM\n",
      "['서울1호선 창동역 인천 신창행 9-1', '뉴욕화이트치과의원 치과', 'ARISTA COFFEE 선릉2호점', '장수가 선릉점'] 롯데백화점 잠실점 식품/푸드에비뉴\n",
      "['스타벅스 선정릉역점', '서울9호선 선정릉역 개화 방면 1-1'] 서울9호선 선정릉역 종합운동장 방면 2-4\n",
      "['KEB하나은행 서압구정지점', '스타필드 코엑스몰점/TWORLD', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '마리아홀리기프트 /책cd'] 천주교잠원동성당\n",
      "['스타벅스 청담영동대로점'] 서울2호선 강남역 외선 9-1\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 서울 강서구 등촌동 477-1\n",
      "['스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/cafe imt 코엑스몰점', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/예가낙지마을', '오징어세상 삼성점', '스타필드 코엑스몰점 /반하는보쌈/ABC-mart/래핑차일드', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /OYSHO/BUTTER', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /럭키슈에뜨/아메리칸이글/별마당도서관', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '오징어세상 삼성점', '서울야시장', '오징어세상 삼성점', '서울야시장', '서울야시장'] 스타필드 코엑스몰점\n",
      "['퍼스트약국', '퍼스트약국', '하나로마트 대치점', '롯데백화점 강남점 본관 /식품/식당가'] 롯데백화점 강남점 /식품/식당가\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 서울 종로구 체부동 188-1\n"
     ]
    }
   ],
   "source": [
    "# ask_place_dfloader_score = []\n",
    "ask_place_dfloader_wont_score = []\n",
    "# ask_place_json_score = []\n",
    "ask_place_json_wont_score = []\n",
    "ask_place_tabsep_score = []\n",
    "ask_place_commasep_score = []\n",
    "ask_place_totext_score = []\n",
    "ask_place_totextvisited_score = []\n",
    "\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(possible_places_ans, cot_ask_place_dfloader):\n",
    "#     cot_ask_place_dfloader_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(possible_places_ans, ask_place_dfloader_wont):\n",
    "    ask_place_dfloader_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(possible_places_ans, cot_ask_place_json):\n",
    "#     cot_ask_place_json_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(possible_places_ans, ask_place_json_wont):\n",
    "    ask_place_json_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(possible_places_ans, ask_place_tabsep):\n",
    "    ask_place_tabsep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(possible_places_ans, ask_place_commasep):\n",
    "    ask_place_commasep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(possible_places_ans, ask_place_totext):\n",
    "    ask_place_totext_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(possible_places_ans, ask_place_totextvisited):\n",
    "    ask_place_totextvisited_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ded00d85-26c9-4db9-bfdb-45f0b9646a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30357142857142855\n",
      "0.8303571428571429\n",
      "0.9017857142857143\n",
      "0.7946428571428571\n",
      "0.7678571428571429\n",
      "0.5892857142857143\n"
     ]
    }
   ],
   "source": [
    "# print(sum(ask_place_dfloader_score)/user_number)\n",
    "print(sum(ask_place_dfloader_wont_score)/user_number)\n",
    "# print(sum(ask_place_json_score)/user_number)\n",
    "print(sum(ask_place_json_wont_score)/user_number)\n",
    "print(sum(ask_place_tabsep_score)/user_number)\n",
    "print(sum(ask_place_commasep_score)/user_number)\n",
    "print(sum(ask_place_totext_score)/user_number)\n",
    "print(sum(ask_place_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5613bff8-81a8-4dd7-9af1-a2ff20a68eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 -------\n",
      "------ 1 -------\n",
      "------ 2 -------\n",
      "------ 3 -------\n",
      "------ 4 -------\n",
      "------ 5 -------\n",
      "------ 6 -------\n",
      "------ 7 -------\n",
      "------ 8 -------\n",
      "------ 9 -------\n",
      "------ 10 -------\n",
      "------ 11 -------\n",
      "------ 12 -------\n",
      "------ 13 -------\n",
      "------ 14 -------\n",
      "------ 15 -------\n",
      "------ 16 -------\n",
      "------ 17 -------\n",
      "------ 18 -------\n",
      "------ 19 -------\n",
      "------ 20 -------\n",
      "------ 21 -------\n",
      "------ 22 -------\n",
      "------ 23 -------\n",
      "------ 24 -------\n",
      "------ 25 -------\n",
      "------ 26 -------\n",
      "------ 27 -------\n",
      "------ 28 -------\n",
      "------ 29 -------\n",
      "------ 30 -------\n",
      "------ 31 -------\n",
      "------ 32 -------\n",
      "------ 33 -------\n",
      "------ 34 -------\n",
      "------ 35 -------\n",
      "------ 36 -------\n",
      "------ 37 -------\n",
      "------ 38 -------\n",
      "------ 39 -------\n",
      "------ 40 -------\n",
      "------ 41 -------\n",
      "------ 42 -------\n",
      "------ 43 -------\n",
      "------ 44 -------\n",
      "------ 45 -------\n",
      "------ 46 -------\n",
      "------ 47 -------\n",
      "------ 48 -------\n",
      "------ 49 -------\n",
      "------ 50 -------\n",
      "------ 51 -------\n",
      "------ 52 -------\n",
      "------ 53 -------\n",
      "------ 54 -------\n",
      "------ 55 -------\n",
      "------ 56 -------\n",
      "------ 57 -------\n",
      "------ 58 -------\n",
      "------ 59 -------\n",
      "------ 60 -------\n",
      "------ 61 -------\n",
      "------ 62 -------\n",
      "------ 63 -------\n",
      "------ 64 -------\n",
      "------ 65 -------\n",
      "------ 66 -------\n",
      "------ 67 -------\n",
      "------ 68 -------\n",
      "------ 69 -------\n",
      "------ 70 -------\n",
      "------ 71 -------\n",
      "------ 72 -------\n",
      "------ 73 -------\n",
      "------ 74 -------\n",
      "------ 75 -------\n",
      "------ 76 -------\n",
      "------ 77 -------\n",
      "------ 78 -------\n",
      "------ 79 -------\n",
      "------ 80 -------\n",
      "------ 81 -------\n",
      "------ 82 -------\n",
      "------ 83 -------\n",
      "------ 84 -------\n",
      "------ 85 -------\n",
      "------ 86 -------\n",
      "------ 87 -------\n",
      "------ 88 -------\n",
      "------ 89 -------\n",
      "------ 90 -------\n",
      "------ 91 -------\n",
      "------ 92 -------\n",
      "------ 93 -------\n",
      "------ 94 -------\n",
      "------ 95 -------\n",
      "------ 96 -------\n",
      "------ 97 -------\n",
      "------ 98 -------\n",
      "------ 99 -------\n",
      "------ 100 -------\n",
      "------ 101 -------\n",
      "------ 102 -------\n",
      "------ 103 -------\n",
      "------ 104 -------\n",
      "------ 105 -------\n",
      "------ 106 -------\n",
      "------ 107 -------\n",
      "------ 108 -------\n",
      "------ 109 -------\n",
      "------ 110 -------\n",
      "------ 111 -------\n"
     ]
    }
   ],
   "source": [
    "# most_visited_date_pred_dfloader = []\n",
    "most_visited_date_pred_dfloader_wont = []\n",
    "# cot_most_visited_date_pred_json = []\n",
    "most_visited_date_pred_json_wont = []\n",
    "most_visited_date_pred_tabsep = []\n",
    "most_visited_date_pred_commasep = []\n",
    "most_visited_date_pred_totext = []\n",
    "most_visited_date_pred_totextvisited = []\n",
    "\n",
    "system_prompt = 'You only answer in the following format: year-month-day. Don\\'t answer in a sentence.'\n",
    "user_prompt = 'When is the date with the most visits? If you have several days, answer only one date.'\n",
    "\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('------', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_temporal/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # print('format 1')\n",
    "    # output, tok = cot_api(system_prompt, user_prompt_q, user_prompt_a, dfloader(user_log))\n",
    "    # most_visited_date_pred_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, dfloader_wont(user_log))\n",
    "    most_visited_date_pred_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # output, tok = cot_api(system_prompt, user_prompt_q, user_prompt_a, json(user_log))\n",
    "    # cot_most_visited_date_pred_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, json_wont(user_log))\n",
    "    most_visited_date_pred_json_wont.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, tabsep(user_log))\n",
    "    most_visited_date_pred_tabsep.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, commasep(user_log))\n",
    "    most_visited_date_pred_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totext(user_log))\n",
    "    most_visited_date_pred_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totextvisited(user_log))\n",
    "    most_visited_date_pred_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92fcdab2-c52d-43cd-a74c-d1edd0957b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-28'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-12\n",
      "['2018-01-03'] 2017-12-29\n",
      "['2018-01-05'] 2017-12-16\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2018-01-02'] 2017-12-24\n",
      "['2018-01-03'] 2017-12-09\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2018-01-05'] 2017-12-31\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2018-01-04'] 2017-12-31\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-29'] 2017-12-26\n",
      "['2017-12-28'] 2017-12-18\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2018-01-01'] 2017-12-31\n",
      "['2018-01-03', '2018-01-05'] 2017-12-15\n",
      "['2018-01-03', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2018-01-02'] 2017-12-31\n",
      "['2017-12-15'] 2017-12-14\n",
      "['2018-01-04', '2017-12-29'] 2017-12-14\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-20\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2018-01-02'] 2017-12-12\n",
      "['2017-12-20', '2018-01-03'] 2017-12-16\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2017-12-31'] 2017-12-27\n",
      "json_wont\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-28'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-21\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-29\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-09\n",
      "['2018-01-05'] 2017-12-16\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2018-01-02'] 2017-12-24\n",
      "['2018-01-03'] 2017-12-09\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2018-01-05'] 2017-12-31\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] 2017-12-23\n",
      "['2018-01-04'] 2017-12-28\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-29'] 2017-12-26\n",
      "['2017-12-25'] 2017-12-23\n",
      "['2017-12-28'] 2017-12-15\n",
      "['2017-12-25'] 2017-12-18\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] 2017-12-22\n",
      "['2018-01-01'] 2017-12-30\n",
      "['2018-01-03', '2018-01-05'] 2017-12-15\n",
      "['2018-01-03', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-26\n",
      "['2018-01-02'] 2017-12-26\n",
      "['2017-12-15'] 2017-12-14\n",
      "['2018-01-04', '2017-12-29'] 2017-12-14\n",
      "['2017-12-29'] 2017-12-14\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-19\n",
      "['2017-12-30'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2018-01-02'] 2017-12-12\n",
      "['2017-12-20', '2018-01-03'] 2017-12-16\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-16\n",
      "tabsep\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-28'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-29\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-20\n",
      "['2018-01-05'] 2017-12-16\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2018-01-02'] 2017-12-24\n",
      "['2018-01-03'] 2017-12-12\n",
      "['2018-01-05'] 2017-12-30\n",
      "['2018-01-05'] 2017-12-31\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] 2017-12-23\n",
      "['2018-01-04'] 2017-12-31\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-29'] 2017-12-26\n",
      "['2017-12-28'] 2017-12-18\n",
      "['2017-12-25'] 2017-12-18\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] 2017-12-22\n",
      "['2018-01-01'] 2017-12-31\n",
      "['2018-01-03', '2018-01-05'] 2017-12-15\n",
      "['2018-01-03', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-26\n",
      "['2018-01-02'] 2017-12-26\n",
      "['2018-01-04', '2017-12-29'] 2017-12-13\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-17\n",
      "['2017-12-30'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2018-01-02'] 2017-12-12\n",
      "['2017-12-20', '2018-01-03'] 2017-12-16\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2017-12-31'] 2017-12-27\n",
      "commasep\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-28'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-21\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-29\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-09\n",
      "['2018-01-05'] 2017-12-16\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2018-01-02'] 2017-12-24\n",
      "['2018-01-03'] 2017-12-12\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2018-01-05'] 2017-12-31\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] 2017-12-23\n",
      "['2018-01-04'] 2017-12-28\n",
      "['2017-12-31', '2018-01-02', '2018-01-05'] 2017-12-29\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-29'] 2017-12-26\n",
      "['2017-12-29'] 2017-12-25\n",
      "['2017-12-28'] 2017-12-18\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] 2017-12-22\n",
      "['2018-01-01'] 2017-12-30\n",
      "['2018-01-03', '2018-01-05'] 2017-12-15\n",
      "['2018-01-03', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-26\n",
      "['2018-01-02'] 2017-12-26\n",
      "['2017-12-15'] 2017-12-14\n",
      "['2018-01-04', '2017-12-29'] 2017-12-13\n",
      "['2017-12-29'] 2017-12-14\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-17\n",
      "['2017-12-30'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2018-01-02'] 2017-12-12\n",
      "['2017-12-20', '2018-01-03'] 2017-12-16\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-16\n",
      "totext\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2017-12-28'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-20\n",
      "['2017-12-29'] 2017-12-21\n",
      "['2018-01-05'] 2017-12-16\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2018-01-02'] 2017-12-24\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] 2017-12-13\n",
      "['2018-01-03'] 2017-12-12\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2018-01-04'] 2017-12-31\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-29'] 2017-12-26\n",
      "['2017-12-25'] 2017-12-23\n",
      "['2017-12-28'] 2017-12-15\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] 2017-12-22\n",
      "['2018-01-01'] 2017-12-31\n",
      "['2018-01-03', '2018-01-05'] 2017-12-15\n",
      "['2018-01-03', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2018-01-02'] 2017-12-26\n",
      "['2017-12-16'] 2017-12-21\n",
      "['2017-12-15'] 2017-12-14\n",
      "['2018-01-04', '2017-12-29'] 2017-12-14\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-20\n",
      "['2017-12-30'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2018-01-02'] 2017-12-18\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2017-12-31'] 2017-12-27\n",
      "totextvisited\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-21\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-22'] 2017-12-08\n",
      "['2018-01-05'] 2017-12-16\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2017-12-18', '2018-01-05'] 2017-12-12\n",
      "['2017-12-10'] 2017-12-07\n",
      "['2017-12-21'] 2017-12-18\n",
      "['2018-01-02'] 2017-12-24\n",
      "['2018-01-03'] 2017-12-12\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2018-01-05'] 2017-12-31\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-22'] 2018-01-04\n",
      "['2018-01-04'] 2017-12-31\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2017-12-28'] 2017-12-18\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] 2017-12-22\n",
      "['2018-01-01'] 2017-12-31\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-29'] 2017-12-23\n",
      "['2018-01-03'] 2017-12-28\n",
      "['2018-01-02'] 2017-12-26\n",
      "['2017-12-16'] 2017-12-25\n",
      "['2017-12-25'] 2017-12-17\n",
      "['2017-12-15'] 2017-12-14\n",
      "['2018-01-04', '2017-12-29'] 2017-12-17\n",
      "['2017-12-30'] 2017-12-23\n",
      "['2017-12-30'] 2017-12-28\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-02'] 2017-12-18\n",
      "['2018-01-05'] 2017-12-29\n",
      "['2017-12-31'] 2017-12-27\n"
     ]
    }
   ],
   "source": [
    "# most_visited_date_pred_dfloader_score = []\n",
    "most_visited_date_pred_dfloader_wont_score = []\n",
    "# most_visited_date_pred_json_score = []\n",
    "most_visited_date_pred_json_wont_score = []\n",
    "most_visited_date_pred_tabsep_score = []\n",
    "most_visited_date_pred_commasep_score = []\n",
    "most_visited_date_pred_totext_score = []\n",
    "most_visited_date_pred_totextvisited_score = []\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(most_visited_date_ans, cot_most_visited_date_pred_dfloader):\n",
    "#     cot_most_visited_date_pred_dfloader_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "        \n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(most_visited_date_ans, most_visited_date_pred_dfloader_wont):\n",
    "    most_visited_date_pred_dfloader_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(most_visited_date_ans, cot_most_visited_date_pred_json):\n",
    "#     cot_most_visited_date_pred_json_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(most_visited_date_ans, most_visited_date_pred_json_wont):\n",
    "    most_visited_date_pred_json_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(most_visited_date_ans, most_visited_date_pred_tabsep):\n",
    "    most_visited_date_pred_tabsep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(most_visited_date_ans, most_visited_date_pred_commasep):\n",
    "    most_visited_date_pred_commasep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(most_visited_date_ans, most_visited_date_pred_totext):\n",
    "    most_visited_date_pred_totext_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(most_visited_date_ans, most_visited_date_pred_totextvisited):\n",
    "    most_visited_date_pred_totextvisited_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf7f914e-e76a-455b-b99e-f469be44dd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696428571428571\n",
      "0.5803571428571429\n",
      "0.625\n",
      "0.5714285714285714\n",
      "0.6339285714285714\n",
      "0.6696428571428571\n"
     ]
    }
   ],
   "source": [
    "# print(sum(cot_most_visited_date_pred_dfloader_score)/user_number)\n",
    "print(sum(most_visited_date_pred_dfloader_wont_score)/user_number)\n",
    "# print(sum(cot_most_visited_date_pred_json_score)/user_number)\n",
    "print(sum(most_visited_date_pred_json_wont_score)/user_number)\n",
    "print(sum(most_visited_date_pred_tabsep_score)/user_number)\n",
    "print(sum(most_visited_date_pred_commasep_score)/user_number)\n",
    "print(sum(most_visited_date_pred_totext_score)/user_number)\n",
    "print(sum(most_visited_date_pred_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "128d6ab3-3bad-4412-9471-afe4cc53f95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0 -------\n",
      "----- 1 -------\n",
      "----- 2 -------\n",
      "----- 3 -------\n",
      "----- 4 -------\n",
      "----- 5 -------\n",
      "----- 6 -------\n",
      "----- 7 -------\n",
      "----- 8 -------\n",
      "----- 9 -------\n",
      "----- 10 -------\n",
      "----- 11 -------\n",
      "----- 12 -------\n",
      "----- 13 -------\n",
      "----- 14 -------\n",
      "----- 15 -------\n",
      "----- 16 -------\n",
      "----- 17 -------\n",
      "----- 18 -------\n",
      "----- 19 -------\n",
      "----- 20 -------\n",
      "----- 21 -------\n",
      "----- 22 -------\n",
      "----- 23 -------\n",
      "----- 24 -------\n",
      "----- 25 -------\n",
      "----- 26 -------\n",
      "----- 27 -------\n",
      "----- 28 -------\n",
      "----- 29 -------\n",
      "----- 30 -------\n",
      "----- 31 -------\n",
      "----- 32 -------\n",
      "----- 33 -------\n",
      "----- 34 -------\n",
      "----- 35 -------\n",
      "----- 36 -------\n",
      "----- 37 -------\n",
      "----- 38 -------\n",
      "----- 39 -------\n",
      "----- 40 -------\n",
      "----- 41 -------\n",
      "----- 42 -------\n",
      "----- 43 -------\n",
      "----- 44 -------\n",
      "----- 45 -------\n",
      "----- 46 -------\n",
      "----- 47 -------\n",
      "----- 48 -------\n",
      "----- 49 -------\n",
      "----- 50 -------\n",
      "----- 51 -------\n",
      "----- 52 -------\n",
      "----- 53 -------\n",
      "----- 54 -------\n",
      "----- 55 -------\n",
      "----- 56 -------\n",
      "----- 57 -------\n",
      "----- 58 -------\n",
      "----- 59 -------\n",
      "----- 60 -------\n",
      "----- 61 -------\n",
      "----- 62 -------\n",
      "----- 63 -------\n",
      "----- 64 -------\n",
      "----- 65 -------\n",
      "----- 66 -------\n",
      "----- 67 -------\n",
      "----- 68 -------\n",
      "----- 69 -------\n",
      "----- 70 -------\n",
      "----- 71 -------\n",
      "----- 72 -------\n",
      "----- 73 -------\n",
      "----- 74 -------\n",
      "----- 75 -------\n",
      "----- 76 -------\n",
      "----- 77 -------\n",
      "----- 78 -------\n",
      "----- 79 -------\n",
      "----- 80 -------\n",
      "----- 81 -------\n",
      "----- 82 -------\n",
      "----- 83 -------\n",
      "----- 84 -------\n",
      "----- 85 -------\n",
      "----- 86 -------\n",
      "----- 87 -------\n",
      "----- 88 -------\n",
      "----- 89 -------\n",
      "----- 90 -------\n",
      "----- 91 -------\n",
      "----- 92 -------\n",
      "----- 93 -------\n",
      "----- 94 -------\n",
      "----- 95 -------\n",
      "----- 96 -------\n",
      "----- 97 -------\n",
      "----- 98 -------\n",
      "----- 99 -------\n",
      "----- 100 -------\n",
      "----- 101 -------\n",
      "----- 102 -------\n",
      "----- 103 -------\n",
      "----- 104 -------\n",
      "----- 105 -------\n",
      "----- 106 -------\n",
      "----- 107 -------\n",
      "----- 108 -------\n",
      "----- 109 -------\n",
      "----- 110 -------\n",
      "----- 111 -------\n"
     ]
    }
   ],
   "source": [
    "# cot_most_visited_cat_pred_dfloader = []\n",
    "most_visited_cat_pred_dfloader_wont = []\n",
    "# cot_most_visited_cat_pred_json = []\n",
    "most_visited_cat_pred_json_wont = []\n",
    "most_visited_cat_pred_tabsep = []\n",
    "most_visited_cat_pred_commasep = []\n",
    "most_visited_cat_pred_totext = []\n",
    "most_visited_cat_pred_totextvisited = []\n",
    "\n",
    "\n",
    "system_prompt = 'You only answer in the following format: category. Don\\'t answer in a sentence.'\n",
    "user_prompt = 'What is the most visited category? If you have several categories, answer only one category.' \n",
    "\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('-----', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_temporal/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # print('format 1')\n",
    "    # output, tok = cot_api(system_prompt, user_prompt_q, user_prompt_a, dfloader(user_log))\n",
    "    # cot_most_visited_cat_pred_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, dfloader_wont(user_log))\n",
    "    most_visited_cat_pred_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # output, tok = cot_api(system_prompt, user_prompt_q, user_prompt_a, json(user_log))\n",
    "    # cot_most_visited_cat_pred_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, json_wont(user_log))\n",
    "    most_visited_cat_pred_json_wont.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, tabsep(user_log))\n",
    "    most_visited_cat_pred_tabsep.append(output)\n",
    "\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, commasep(user_log))\n",
    "    most_visited_cat_pred_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totext(user_log))\n",
    "    most_visited_cat_pred_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = gpt_api(system_prompt, user_prompt, totextvisited(user_log))\n",
    "    most_visited_cat_pred_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e18660c-82f8-481b-9396-69be83e73c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['internal medicine clinic'] korean food restaurants\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] department store\n",
      "['pc cafe'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['outlet/ shopping mall'] korean food restaurants\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station', 'outlet/ shopping mall'] coffee shop\n",
      "['subway station'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] furniture shop\n",
      "['convenience store'] others(restaurants)\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] bookstore\n",
      "['convenience store'] burger/sandwich\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] discount department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['pharmacy'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] convenience store\n",
      "['subway station'] coffee shop\n",
      "json_wont\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['outlet/ shopping mall'] bookstore\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['subway station'] coffee shop\n",
      "['convenience store'] subway station\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] discount department store\n",
      "['convenience store'] clothing store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['others(restaurants)', 'discount department store'] izakaya\n",
      "tabsep\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['outlet/ shopping mall'] bookstore\n",
      "['clothing store'] convenience store\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] subway train\n",
      "['convenience store'] outlet/ shopping mall\n",
      "['subway train'] subway station\n",
      "['subway station'] bookstore\n",
      "['convenience store'] subway station\n",
      "['subway station'] discount department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['others(restaurants)', 'discount department store'] convenience store\n",
      "commasep\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['outlet/ shopping mall'] bookstore\n",
      "['outlet/ shopping mall'] cosmetics shop\n",
      "['clothing store'] convenience store\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] subway train\n",
      "['subway station'] bookstore\n",
      "['subway station'] discount department store\n",
      "['subway station'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['others(restaurants)', 'discount department store'] convenience store\n",
      "totext\n",
      "['subway station'] korean food restaurants.\n",
      "['subway station'] subway station.\n",
      "['icecream shop'] ice cream shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] department store\n",
      "['subway station'] clothing store\n",
      "['korean food restaurants'] pizza\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['outlet/ shopping mall'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway station.\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['karaoke'] akaraokelocated\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] furniture shop\n",
      "['subway station'] korean food restaurants\n",
      "['convenience store'] outlet/ shopping mall\n",
      "['korean food restaurants'] coffee shop\n",
      "['subway train'] outlet/ shopping mall\n",
      "['subway station'] restaurants\n",
      "['subway station'] convenience store\n",
      "['subway station'] subway station.\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway station.\n",
      "['subway train'] subway station\n",
      "['subway station'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/shopping mall\n",
      "['general hospital'] supermarket\n",
      "['subway station'] subway station.\n",
      "['subway station'] discount department store\n",
      "['discount department store'] 이마트 양재점 /식품\n",
      "['subway station'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] convenience store\n",
      "['subway station'] coffee shop\n",
      "['others(restaurants)', 'discount department store'] convenience store\n",
      "totextvisited\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] subway station visits.\n",
      "['icecream shop'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['physical fitness facility', 'discount department store'] others(hospital)\n",
      "['subway station'] subway station.\n",
      "['internal medicine clinic'] korean food restaurants.\n",
      "['subway station'] subway station.\n",
      "['subway station'] clothing store\n",
      "['protestant church'] movie theater\n",
      "['korean food restaurants'] outlet/ shopping mall\n",
      "['subway station'] subway station.\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway stations\n",
      "['subway station'] 서울5호선\n",
      "['subway station'] subway station.\n",
      "['subway station'] subway station.\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway station visits\n",
      "['coffee shop'] convenience store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['karaoke'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station', 'cosmetics shop'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] subway station.\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] subway station.\n",
      "['subway station'] korean food restaurants\n",
      "['real estate agency'] movie theater\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] 서울5호선 (subway line 5)\n",
      "['subway station'] subway station.\n",
      "['subway train'] subway train.\n",
      "['coffee shop'] subway station\n",
      "['subway station'] restaurants\n",
      "['subway station'] subway stations.\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway stations\n",
      "['subway station'] subway station.\n",
      "['subway train'] subway stations\n",
      "['catholic church'] catholic church.\n",
      "['subway station'] subway\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] bakery\n",
      "['discount department store'] 이마트 양재점 /식품\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['pharmacy'] department store\n",
      "['subway station'] korean food restaurants.\n",
      "['subway station'] subway stations\n",
      "['subway station'] cosmetics shop\n",
      "['others(restaurants)', 'discount department store'] convenience store\n"
     ]
    }
   ],
   "source": [
    "# cot_most_visited_cat_pred_dfloader_score = []\n",
    "most_visited_cat_pred_dfloader_wont_score = []\n",
    "# cot_most_visited_cat_pred_json_score = []\n",
    "most_visited_cat_pred_json_wont_score = []\n",
    "most_visited_cat_pred_tabsep_score = []\n",
    "most_visited_cat_pred_commasep_score = []\n",
    "most_visited_cat_pred_totext_score = []\n",
    "most_visited_cat_pred_totextvisited_score = []\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(most_visited_cat_ans, cot_most_visited_cat_pred_dfloader):\n",
    "#     cot_most_visited_cat_pred_dfloader_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "#     if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(most_visited_cat_ans, most_visited_cat_pred_dfloader_wont):\n",
    "    most_visited_cat_pred_dfloader_wont_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(most_visited_cat_ans, cot_most_visited_cat_pred_json):\n",
    "#     cot_most_visited_cat_pred_json_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "#     if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(most_visited_cat_ans, most_visited_cat_pred_json_wont):\n",
    "    most_visited_cat_pred_json_wont_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(most_visited_cat_ans, most_visited_cat_pred_tabsep):\n",
    "    most_visited_cat_pred_tabsep_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(most_visited_cat_ans, most_visited_cat_pred_commasep):\n",
    "    most_visited_cat_pred_commasep_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(most_visited_cat_ans, most_visited_cat_pred_totext):\n",
    "    most_visited_cat_pred_totext_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(most_visited_cat_ans, most_visited_cat_pred_totextvisited):\n",
    "    most_visited_cat_pred_totextvisited_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86ce3b2b-0213-4cac-95c2-45c4792cf41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785714285714286\n",
      "0.7589285714285714\n",
      "0.7589285714285714\n",
      "0.7857142857142857\n",
      "0.5178571428571429\n",
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# print(sum(cot_most_visited_cat_pred_dfloader_score)/user_number)\n",
    "print(sum(most_visited_cat_pred_dfloader_wont_score)/user_number)\n",
    "# print(sum(cot_most_visited_cat_pred_json_score)/user_number)\n",
    "print(sum(most_visited_cat_pred_json_wont_score)/user_number)\n",
    "print(sum(most_visited_cat_pred_tabsep_score)/user_number)\n",
    "print(sum(most_visited_cat_pred_commasep_score)/user_number)\n",
    "print(sum(most_visited_cat_pred_totext_score)/user_number)\n",
    "print(sum(most_visited_cat_pred_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec51539-fc88-4822-91e3-1d1c25444f1d",
   "metadata": {},
   "source": [
    "<font size=\"5\">Our Instruction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3d63c65-f5d8-468f-9746-3fd7963cce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oi_api(system_prompt, user_prompt, user_log, model=\"gpt-3.5-turbo-0613\", verbose=False):\n",
    "\n",
    "    user_prompt += '\\n' + '```' + '\\n' + user_log + '\\n' + '```'\n",
    "    \n",
    "    if verbose:\n",
    "      print(user_prompt)\n",
    "\n",
    "    messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt}, \n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "    token = response.usage.total_tokens\n",
    "    \n",
    "    # print('answer : ', output)\n",
    "    # print('token : ', token)\n",
    "\n",
    "    return output, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aaa6fd07-5fe4-458c-8195-d6e69be5005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 -------\n",
      "------ 1 -------\n",
      "------ 2 -------\n",
      "------ 3 -------\n",
      "------ 4 -------\n",
      "------ 5 -------\n",
      "------ 6 -------\n",
      "------ 7 -------\n",
      "------ 8 -------\n",
      "------ 9 -------\n",
      "------ 10 -------\n",
      "------ 11 -------\n",
      "------ 12 -------\n",
      "------ 13 -------\n",
      "------ 14 -------\n",
      "------ 15 -------\n",
      "------ 16 -------\n",
      "------ 17 -------\n",
      "------ 18 -------\n",
      "------ 19 -------\n",
      "------ 20 -------\n",
      "------ 21 -------\n",
      "------ 22 -------\n",
      "------ 23 -------\n",
      "------ 24 -------\n",
      "------ 25 -------\n",
      "------ 26 -------\n",
      "------ 27 -------\n",
      "------ 28 -------\n",
      "------ 29 -------\n",
      "------ 30 -------\n",
      "------ 31 -------\n",
      "------ 32 -------\n",
      "------ 33 -------\n",
      "------ 34 -------\n",
      "------ 35 -------\n",
      "------ 36 -------\n",
      "------ 37 -------\n",
      "------ 38 -------\n",
      "------ 39 -------\n",
      "------ 40 -------\n",
      "------ 41 -------\n",
      "------ 42 -------\n",
      "------ 43 -------\n",
      "------ 44 -------\n",
      "------ 45 -------\n",
      "------ 46 -------\n",
      "------ 47 -------\n",
      "------ 48 -------\n",
      "------ 49 -------\n",
      "------ 50 -------\n",
      "------ 51 -------\n",
      "------ 52 -------\n",
      "------ 53 -------\n",
      "------ 54 -------\n",
      "------ 55 -------\n",
      "------ 56 -------\n",
      "------ 57 -------\n",
      "------ 58 -------\n",
      "------ 59 -------\n",
      "------ 60 -------\n",
      "------ 61 -------\n",
      "------ 62 -------\n",
      "------ 63 -------\n",
      "------ 64 -------\n",
      "------ 65 -------\n",
      "------ 66 -------\n",
      "------ 67 -------\n",
      "------ 68 -------\n",
      "------ 69 -------\n",
      "------ 70 -------\n",
      "------ 71 -------\n",
      "------ 72 -------\n",
      "------ 73 -------\n",
      "------ 74 -------\n",
      "------ 75 -------\n",
      "------ 76 -------\n",
      "------ 77 -------\n",
      "------ 78 -------\n",
      "------ 79 -------\n",
      "------ 80 -------\n",
      "------ 81 -------\n",
      "------ 82 -------\n",
      "------ 83 -------\n",
      "------ 84 -------\n",
      "------ 85 -------\n",
      "------ 86 -------\n",
      "------ 87 -------\n",
      "------ 88 -------\n",
      "------ 89 -------\n",
      "------ 90 -------\n",
      "------ 91 -------\n",
      "------ 92 -------\n",
      "------ 93 -------\n",
      "------ 94 -------\n",
      "------ 95 -------\n",
      "------ 96 -------\n",
      "------ 97 -------\n",
      "------ 98 -------\n",
      "------ 99 -------\n",
      "------ 100 -------\n",
      "------ 101 -------\n",
      "------ 102 -------\n",
      "------ 103 -------\n",
      "------ 104 -------\n",
      "------ 105 -------\n",
      "------ 106 -------\n",
      "------ 107 -------\n",
      "------ 108 -------\n",
      "------ 109 -------\n",
      "------ 110 -------\n",
      "------ 111 -------\n"
     ]
    }
   ],
   "source": [
    "# oi_ask_date_dfloader = []\n",
    "oi_ask_date_dfloader_wont = []\n",
    "# oi_ask_date_json = []\n",
    "oi_ask_date_json_wont = []\n",
    "oi_ask_date_tabsep = []\n",
    "oi_ask_date_commasep = []\n",
    "oi_ask_date_totext = []\n",
    "oi_ask_date_totextvisited = []\n",
    "\n",
    "system_prompt = 'You only answer in the following format: year-month-day. Don\\'t answer in a sentence.'\n",
    "\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('------', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_lookup/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # dates_to_reply = str(dates_ans[i])\n",
    "\n",
    "    user_prompt = 'The user\\'s visit history below is delimited by three backticks. Your goal is to answer the question \\'When is the date when the person visited ' + str(the_places[i]) + '?\\' If you have several days, answer only one date. Look into the features of the user\\'s visit history and put emphasis on key features of the data that could be useful in answering the question.'\n",
    "\n",
    "    \n",
    "    system_prompt_dfloader = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "    1. The visit history is in the format of pandas dataframe loader.\n",
    "    2. Each column name(index, date, hour, place_name, place_category, and place_address) is indicated before each colon and values are represented in a list format after each colon.\n",
    "    3. The order of values in each list is kept the same, meaning that nth value in one list and nth value in another list are both included in the person’s one specific visit log information.\n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_json = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "    1. The visit history is in the format of JSON.\n",
    "    2. The number before each colon before each dictionary format indicates the index number of the visit log and the dictionary format data after each colon includes each column name( index, date, hour, place_name, place_category, and place_address) and the value corresponding to the column. \n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_tabsep = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "    1. Each line contains one log of the visit history.\n",
    "    2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "    3. Each item that corresponds to each feature is separated by a tab.\n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_commasep = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "    1. Each line contains one log of the visit history.\n",
    "    2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "    3. Each item that corresponds to each feature is separated by a comma.\n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_totext = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "    1. The visit history is in the text(sentence) format.\n",
    "    2. In the sentence, each visit log is included in order of time. \n",
    "    3. Each visit log includes date, hour, place_name, place_category, and place_address. \n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_totextvisited = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "    1. The visit history is in the text(sentence) format.\n",
    "    2. In the sentence, for each place, its place_name, place_category, and place_address are followed by all visited dates and hours to the place. \n",
    "    ''' + system_prompt\n",
    "    \n",
    "    # # print('format 1')\n",
    "    # output, tok = gpt_api(system_prompt_dfloader, user_prompt, dfloader(user_log))\n",
    "    # oi_ask_date_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    output, tok = oi_api(system_prompt_dfloader, user_prompt, dfloader_wont(user_log))\n",
    "    oi_ask_date_dfloader_wont.append(output)\n",
    "    \n",
    "    # # print('format 3')\n",
    "    # output, tok = gpt_api(system_prompt_json, user_prompt, json(user_log))\n",
    "    # oi_ask_date_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    output, tok = oi_api(system_prompt_json, user_prompt, json_wont(user_log))\n",
    "    oi_ask_date_json_wont.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_tabsep, user_prompt, tabsep(user_log))\n",
    "    oi_ask_date_tabsep.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_commasep, user_prompt, commasep(user_log))\n",
    "    oi_ask_date_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = oi_api(system_prompt_totext, user_prompt, totext(user_log))\n",
    "    oi_ask_date_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = oi_api(system_prompt_totextvisited, user_prompt, totextvisited(user_log))\n",
    "    oi_ask_date_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ad504a2d-9345-414c-871e-84d878345696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 이찌마이 is 2017-12-30.\n",
      "['2017-12-31'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"서울5호선 왕십리역 방화행 6-4\".\n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the specific value \"서울5호선 왕십리역 방화행 6-4\".\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited TKS CAFE is '2017-12-26'.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited \"미니스톱 신천역점\" is 2017-12-28.\n",
      "['2017-12-25', '2018-01-01'] The date when the person visited \"풀잎채 두부사랑점\" can be found by looking at the \"place_name\" column in the visit history dataframe. We need to find the date(s) where the value in the \"place_name\" column is \"풀잎채 두부사랑점\".\n",
      "['2018-01-02'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"place_address\" columns. We need to find the date when the person visited \"서울2호선 잠실역 내선 3-1\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" and \"place_address\" columns. We need to find the row where the \"place_name\" is \"서울2호선 잠실역 내선 3-1\". \n",
      "\n",
      "Let's filter the dataframe and find the date when the person visited \"서울2호선 잠실역 내선 3-1\".\n",
      "['2017-12-16', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'] The date when the person visited \"위담한방병원 내과\" is 2017-12-16.\n",
      "['2017-12-29'] The key features of the data that could be useful in answering the question are the \"date\" column and the \"place_name\" column. We need to find the date when the person visited \"서울7호선 강남구청역 부평구청 방면 2-2\".\n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the specific value \"서울7호선 강남구청역 부평구청 방면 2-2\".\n",
      "['2017-12-23'] The key features of the data that could be useful in answering the question are the \"date\" column and the \"place_name\" column. We need to find the date when the person visited the specific places mentioned in the question.\n",
      "\n",
      "To find the date when the person visited \"스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수\", we can filter the dataframe based on the \"place_name\" column and check for the specific places mentioned.\n",
      "\n",
      "Here is the code to find the date when the person visited the specific places:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [13, 18, 19, 18, 20, 18, 18, 13, 18, 18, 18, 20, 18, 18, 16, 16, 16, 17, 17, 18, 18, 19, 15, 15, 16, 18, 19, 20, 20, 15, 13, 9, 18, 19, 10, 11, 19, 18, 18, 20],\n",
      "    'place_name': ['달콤커피 삼성점', '진부령황태명가', '삼성한방삼계탕', '진부령황태명가', '인어스휘트니스', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '이디야 강남역지하상가점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점/D.QUEENS 코엑스몰점', '진부령황태명가', '진부령황태명가', '인어스휘트니스', '진부령황태명가', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', '스타필드 코엑스몰점/KFC 코엑스몰점', '스타필드 코엑스몰점 /코나이비인후과/헌혈의집', '파리바게뜨 삼성풍림점', '진부령황태명가', '삼성한방삼계탕', '삼성한방삼계탕', '서울2호선 2521', '서울9호선 봉은사역 종합운동장 방면 2-4', '최미삼순대국', '진부령황태명가', '진부령황태명가', '진부령황태명가', '삼성한방삼계탕', 'NATURE REPUBLIC 청담역점', '파리바게뜨 삼성풍림점', '아셈내과의원', '인어스휘트니스', '삼성한방삼계탕', '박병익내과의원 내과', '스타벅스 삼성도심공항점', '진부령황태명가', '삼성한방삼계탕', '진부령황태명가', '삼성한방삼계탕'],\n",
      "    'place_category': ['Coffee Shop', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Physical Fitness Facility', 'Movie Theater', 'Outlet/ Shopping Mall', 'Coffee Shop', 'Outlet/ Shopping Mall', 'Western Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Physical Fitness Facility', 'Korean Food Restaurants', 'Outlet/ Shopping Mall', 'Others(Restaurants)', 'Burger/Sandwich', 'Outlet/ Shopping Mall', 'Bakery', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Subway Train', 'Subway Station', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Cosmetics Shop', 'Bakery', 'Internal Medicine Clinic', 'Physical Fitness Facility', 'Korean Food Restaurants', 'Internal Medicine Clinic', 'Coffee Shop', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants'],\n",
      "    'place_address': ['서울 강남구 삼성동 168-16', '서울\n",
      "['2017-12-31'] 2018-01-03\n",
      "['2017-12-22'] 2017-12-21\n",
      "['2017-12-31'] 2018-01-05\n",
      "['2017-12-27'] The key features of the data that could be useful in answering the question are the \"date\" column and the \"place_name\" column. We need to find the date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the specific value \"서울5호선 목동역 상일동 마천행 6-4\". Then, we can retrieve the corresponding date from the \"date\" column.\n",
      "\n",
      "Here is the code to find the date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\":\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Given dataframe\n",
      "df = pd.DataFrame({date : ['2017-12-22', '2017-12-23', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],hour : [15, 5, 14, 5, 16, 9, 18, 18, 14, 18, 20, 21, 12, 13, 13, 14, 14, 5, 5, 14, 14, 14, 5, 14, 15, 11, 12, 13, 13, 16, 17, 17, 18, 19, 5, 15, 16, 15, 17, 17],place_name : ['서울5호선 5033', '서울5호선 5127', '하나로마트 서대문점', '서울5호선 충정로역 방화행 2-4 / 상일동 마천행 6-4', '스타벅스 문화일보점', '서울5호선 5317', '서울5호선 목동역 상일동 마천행 6-4', '서울5호선 5276', 'KT 목동네거리점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀', '서울3호선 고속터미널역 대화방면 9-1', '서울3호선 잠원역 대화방면 5-1', '박종근과자점', '현대백화점 신촌점 /영플라자/대행사장', '현대백화점 신촌점 /문화센터', '현대백화점 신촌점 /식품', 'IBK기업은행 신촌지점', '서울5호선 5229', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '현대백화점 신촌점 /문화센터', 'GS25 종로행촌점', '올리브영 홍대입구역점', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '올리브영 목동역점', '서울5호선 5708', 'Paul Bassett 동부이촌점', '아이파크몰/아이파크백화점 /여성복/패션관', '이마트 용산점 /비식품', '아이파크몰/올리브영 아이파크몰점', '아이파크몰/EYE AVENUE 용산아이파크점/동관', '서울1호선 서울역 소요산행 9-1 / 인천 신창행 3-1', '서울1호선 용산역 소요산행 9-1', '커피베이 종로광화문점', '파리바게뜨 광화문점', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '스타벅스 목동오목로점', '서울5호선 여의나루역 방화방면 6-4', 'Paul Bassett 코리아나호텔점', '빚은 정동점', '세븐일레븐 종로사직점'],place_category : ['Subway Train', 'Subway Train', 'Supermarket', 'Subway Station', 'Coffee Shop', 'Subway Train', 'Subway Station', 'Subway Train', 'Mobile Phone Shop', 'Department Store', 'Subway Station', 'Subway Station', 'Bakery\n",
      "['2018-01-02'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"분당선 351939\".\n",
      "['2017-12-22', '2017-12-29', '2018-01-05'] The date when the person visited \"미소야 서초점\" is 2017-12-22.\n",
      "['2018-01-03'] The key features of the data that could be useful in answering the question are the 'date' and 'place_name' columns. We need to find the date when the person visited '서울4호선 숙대입구역 당고개방면 9-1'.\n",
      "\n",
      "To find the date, we can filter the dataframe based on the 'place_name' column where the value is '서울4호선 숙대입구역 당고개방면 9-1' and then retrieve the corresponding 'date' value.\n",
      "\n",
      "The date when the person visited '서울4호선 숙대입구역 당고개방면 9-1' is '2018-01-03'.\n",
      "['2017-12-18'] The date when the person visited 곰돌이스타약국 is '2017-12-18'.\n",
      "['2017-12-11'] The date when the person visited \"서울5호선 5756\" is 2017-12-11.\n",
      "['2017-12-23', '2017-12-26', '2017-12-26', '2017-12-29', '2017-12-30'] The date when the person visited \"애니벅스 애니학원 강남본점\" is 2017-12-23.\n",
      "['2017-12-08'] The date when the person visited \"서울2호선 서초역 외선 5-1\" is 2017-12-08.\n",
      "['2017-12-27'] The date when the person visited 이디야 서울고교점 is '2017-12-30'.\n",
      "['2017-12-22', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'] The date when the person visited \"스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이\" can be found by filtering the dataframe for the corresponding place_name.\n",
      "['2017-12-22', '2017-12-22'] The date when the person visited 버거킹 시청역점 is '2017-12-22'.\n",
      "['2017-12-10', '2018-01-05'] The key features of the data that could be useful in answering the question are the 'date' and 'place_name' columns. We need to find the date when the person visited '서울2호선 신림역 내선 2-3 / 외선 9-2'.\n",
      "\n",
      "To find the date, we can filter the dataframe based on the 'place_name' column where the value is '서울2호선 신림역 내선 2-3 / 외선 9-2' and then retrieve the corresponding 'date' value.\n",
      "\n",
      "Here is the code to find the date:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Given dataframe\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-09', '2017-12-09', '2017-12-10', '2017-12-11', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-16', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [11, 11, 8, 13, 13, 14, 15, 12, 19, 19, 20, 15, 18, 18, 12, 20, 12, 19, 12, 14, 16, 13, 14, 13, 20, 21, 21, 16, 17, 9, 12, 18, 7, 11, 17, 22, 7, 16, 18, 18],\n",
      "    'place_name': ['할리스커피 종로본점', '올리브영 종로YBM점', '서울2호선 신림역 내선 2-3 / 외선 9-2', '공차 시청점', '서내과 내과', '서울2호선 신림역 내선 4-4 / 외선 7-1', '이마트 영등포점/일렉트로마트 영등포점', '할리스커피 세종로점', '서울2호선 잠실역 내선 3-1', 'ASHLEY 서울대입구점', '페리카나 흑석동점', '서울2호선 사당역 외선 3-1', '파르나스몰/아프리카 삼성파르나스몰점', '교동전선생 서소문점', 'COFFE & MORE', 'ARITAUM 서울대역점', '공차 시청점', 'Paul Bassett 코리아나호텔점', '할리스커피 세종로점', '사랑의교회', '서울2호선 사당역 내선 3-1', 'NESCAFE 조선일보점', '이디야 봉천역점', 'Paul Bassett 코리아나호텔점', '스타벅스 서소문로점', '서울2호선 신촌역 외선 9-1', '서울2호선 시청역 내선 3-2 / 외선 8-3', '올리브영 태평로1가점', 'CU 코리아나호텔점', '이디야 세종로점', '커피빈 서울시청뒤남강빌딩점', '서울2호선 시청역 내선 9-1 / 외선 2-4', '서울2호선 신대방역 내선 3-1', '올리브영 세종로점', '올리브영 태평로1가점', '서울2호선 충정로역 내선 4-1 / 외선 7-4', '서울2호선 신림역 내선 2-3 / 외선 9-2', '올리브영 태평로1가점', '서울2호선 시청역 내선 5-2 / 외선 6-3', '서울2호선 아현역 외선 7-1'],\n",
      "    'place_category': ['Coffee Shop', 'Drug Store', 'Subway Station', 'Teahouse', 'Internal Medicine Clinic', 'Subway Station', 'Electronics Shop', 'Coffee Shop', 'Subway Station', 'Western Food Restaurants', 'Chicken', 'Subway Station', 'Optical Store', 'Bar', 'Coffee Shop', 'Cosmetics Shop', 'Teahouse', 'Coffee Shop', 'Coffee Shop', 'Protestant Church', 'Subway Station', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Drug Store', 'Convenience Store', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Drug Store', 'Drug Store', 'Subway Station', 'Subway Station', 'Drug Store', 'Subway Station', 'Subway Station'],\n",
      "    'place_address': ['서울 종로구 종로2가 75-2', '서울 종로구 종로2가 55-\n",
      "['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26'] The date when the person visited 히든코인싱어노래연습장 is '2017-12-13'.\n",
      "['2017-12-29'] The date when the person visited 이디야 방이역점 is '2017-12-29'.\n",
      "['2018-01-03'] 2018-01-05\n",
      "['2018-01-04'] 2018-01-05\n",
      "['2018-01-04'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"서울5호선 아차산역 방화행 6-4\".\n",
      "\n",
      "Looking at the \"place_name\" column, we can see that the person visited various places, including subway stations, banks, restaurants, and department stores. We are specifically interested in the visit to \"서울5호선 아차산역 방화행 6-4\".\n",
      "\n",
      "To find the date when the person visited this specific place, we need to filter the dataframe based on the \"place_name\" column. We can use the following code to find the date:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Given dataframe\n",
      "df = pd.DataFrame({date : ['2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],hour : [21, 14, 15, 19, 21, 21, 7, 7, 13, 16, 17, 18, 18, 19, 19, 19, 20, 20, 20, 20, 21, 7, 12, 12, 13, 16, 17, 21, 21, 22, 7, 12, 16, 17, 18, 18, 18, 19, 20, 20],place_name : ['서울8호선 가락시장역 모란방면 2-2', 'KB국민은행 먹골역지점', '우리은행 태릉역지점', '짬뽕타임 이수점', '서울5호선 5419', '서울7호선 남성역 장암 방면 4-4', '서울7호선 군자역 장암 방면 4-4', '서울5호선 5223', '이디야 묵동자이점', '서울1호선 종로5가역 인천 신창행 5-1', '서울1호선 대방역 인천 신창행 5-1 / 용산급행 6-4', '타임스퀘어/Saint AUGUSTIN 타임스퀘어점', '파리바게뜨 영등포점', '이마트 영등포점 /비식품', '타임스퀘어/UNIQLO 타임스퀘어점', '이마트 영등포점 /식품 외', '세븐일레븐 서초사당역점', '서울2호선 신도림역 출근선 잠실방면 7-1', 'UNIQLO 사당파스텔점', '파리바게뜨 사당파스텔시티점', '서울8호선 잠실역 모란방면 2-2', '서울5호선 아차산역 방화행 6-4', '서울7호선 먹골역 장암 방면 6-4', '롯데리아 먹골역점', '서울6호선 태릉입구역 응암순환행 4-4', '서울1호선 대방역 인천 신창행 5-1 / 용산급행 6-4', '서울6호선 동묘앞역 봉화산행 8-3 / 응암순환행 1-2', '서울4호선 삼각지역 오이\n",
      "['2018-01-02', '2018-01-03', '2018-01-05'] 2018-01-04\n",
      "['2017-12-28', '2017-12-28'] 2017-12-31\n",
      "['2017-12-30'] The date when the person visited 세븐일레븐 도곡스타점 is 2018-01-05.\n",
      "['2017-12-26'] 2018-01-05\n",
      "['2017-12-26'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"place_category\" columns. We need to find the date when the person visited \"정관장 서대문역점\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the value \"정관장 서대문역점\".\n",
      "['2017-12-15'] The date when the person visited \"두꺼비부대찌개\" can be found by looking at the \"place_name\" column in the visit history dataframe. The value \"두꺼비부대찌개\" appears in the \"place_name\" column at index 0. Therefore, the date when the person visited \"두꺼비부대찌개\" is \"2017-12-15\".\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"place_category\" columns. We need to find the date when the person visited \"잠실눈사람안과\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the value \"잠실눈사람안과\".\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"서울3호선 3926\" is 2018-01-06.\n",
      "['2017-12-15', '2017-12-22', '2017-12-22'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"place_category\" columns. We need to find the date when the person visited \"청솔오리\".\n",
      "['2017-12-30', '2017-12-30'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"분당선 351132\".\n",
      "['2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"place_category\" columns. We need to find the date when the person visited \"예스자이엘라부동산\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the value \"예스자이엘라부동산\". Once we have the filtered dataframe, we can extract the date from the \"date\" column.\n",
      "\n",
      "Here is the code to find the date when the person visited \"예스자이엘라부동산\":\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Given dataframe\n",
      "df = pd.DataFrame({date : ['2017-12-14', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-25'],hour : [19, 9, 6, 10, 12, 14, 14, 15, 17, 18, 19, 6, 11, 11, 12, 21, 19, 20, 20, 21, 22, 22, 5, 2, 12, 4, 7, 11, 12, 18, 19, 3, 6, 17, 18, 18, 18, 19, 17, 17],place_name : ['다이소 대방남부점', '예스자이엘라부동산', '예스자이엘라부동산', '예스자이엘라부동산', '예스자이엘라부동산', '서울1호선 대방역 소요산행 9-1', 'IFC몰/CGV 여의도점/4,7관입구', 'IFC몰/CGV 여의도점/8-9관입구', 'IFC몰/올리브마켓 여의도IFC몰점', '칸느치킨', '칸느치킨', '서울1호선 대방역 소요산행 7-1', '정관장 트윈타워점', 'GS25 트윈타워점', 'GS25 트윈타워점', 'GS25 여의도자이점', '은행골 영등포점/초밥참치', '은행골 영등포점/초밥참치', '마더스연세치과', '은행골 영등포점/초밥참치', 'TWORLD PS&M영등포역점', '다이소 영등포본점', '예스자이엘라부동산', '예스자이엘라부동산', 'GS25 트윈타워점', '예스자이엘라부동산', '서울1호선 대방역 소요산행 7-1', 'GS25 트윈타워점', 'GS25 트윈타워점', '서울1호선 대방역 소요산행 7-1', '예스자이엘라부동산', '예스자이엘라부동산', '예스자이엘라부동산', '서울1호선 대방역 인천 신창행 6-4 / 용산급행 5-1', '서울2호선 신도림역 내선 4-4 / 외선 7-1', '서울1호선 신도림역 인천•신창방면 3-1(급행)/소요산방면 10-2(급행)', '서울1호선 311148', '서울1호선 대방역 동인천 천안급행 5-1', 'LG유플러스 영등포직영점', 'LG유플러스 영등포직영점'],place_category : ['Household Goods', 'Real Estate Agency', 'Real Estate Agency', 'Real Estate Agency', 'Real Estate Agency', 'Subway Station', 'Movie Theater', 'Movie Theater', 'Grocery Store', 'Chicken', 'Chicken', 'Subway Station', 'Health Additive Food Store', 'Convenience Store', 'Convenience Store', 'Convenience Store', 'Others(Restaurants)', 'Others(Restaurants)', 'Dental Clinic', 'Others(Restaurants)', 'Mobile Phone Shop', 'Household Goods', 'Real Estate Agency', 'Real Estate Agency', 'Convenience Store', 'Real Estate Agency', 'Subway Station', 'Convenience Store', 'Convenience Store', 'Subway Station', 'Real Estate Agency', 'Real Estate Agency', 'Real Estate Agency', 'Sub\n",
      "['2018-01-01'] The date when the person visited 버거킹 낙성대역점 is 2018-01-05.\n",
      "['2018-01-03'] 2018-01-04\n",
      "['2018-01-05'] The date when the person visited 펀앤조이 /인형뽑기 is 2018-01-05.\n",
      "['2017-12-18'] The date when the person visited \"바르미샤브샤브 삼성역점\" is 2017-12-18.\n",
      "['2017-12-25'] The date when the person visited IFC몰/Aesop IFC서울점 is 2017-12-25.\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] The date when the person visited 할리스커피 종로본점 is '2017-12-21'.\n",
      "['2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18'] The date when the person visited 황금복국 is 2017-12-18.\n",
      "['2017-12-29', '2018-01-04'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_address\" columns. \n",
      "\n",
      "To find the date when the person visited \"서울8호선 천호역 암사방면 2-2\", we need to filter the dataframe based on the place_address column. \n",
      "\n",
      "Here is the code to find the date:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe\n",
      "df = pd.DataFrame({date : ['2017-12-23', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],hour : [14, 13, 16, 13, 14, 21, 12, 15, 16, 18, 12, 16, 12, 15, 17, 7, 7, 10, 13, 14, 14, 18, 22, 23, 23, 12, 13, 15, 18, 14, 15, 15, 17, 12, 13, 17, 20, 20, 11, 18],place_name : ['THE PLACE 서울스퀘어점', '헤어메이드', '스타벅스 수유역점', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점/방콕9/비비고/차이나팩토리/제일제면소/투썸플레이스', '스타필드 코엑스몰점/스타벅스 코엑스몰점', '스타벅스 천호로데오점', 'YES 당구장 /당구장', 'KB국민은행 서초남지점', '복돈이부추삼겹살 사당본점', 'YES 당구장 /당구장', '서초공업사 /현대자동차수리점', '서울8호선 잠실역 암사방면 2-2', 'YES 당구장 /당구장', 'YES 당구장 /당구장', '스타벅스 남부터미널2점', '서울8호선 암사역 모란방면 2-2', '서울2호선 종합운동장역 내선 9-1', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 안국점', '서울3호선 안국역 대화행 7-1 / 오금행 4-4', 'YES 당구장 /당구장', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 마로니에공원점', 'GS25 암사역점', '서울8호선 천호역 암사방면 2-2', 'CGV 하계점', '스타벅스 신당역사거리점', '충무아트홀 대극장', '투썸플레이스 강변CGV점', '독도쭈꾸미 본점', '이마트 천호점', '스타벅스 천호로데오점', '백두산사우나', '롯데마트 강변점 /식품/비식품', '투썸플레이스 강변CGV점', '양촌리', '서울8호선 천호역 암사방면 2-2', '서울5호선 길동역 방화행 2-2', 'CGV 강변점', 'NATURE REPUBLIC 잠실지하점'],place_category : ['Western Food Restaurants', 'Hair Salon', 'Coffee Shop', 'Others(Restaurants)', 'Coffee Shop', 'Coffee Shop', 'Billiard', 'Bank', 'Korean Food Restaurants', 'Billiard', 'Others(Retail)', 'Subway Station', 'Billiard', 'Billiard', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Subway Station', 'Coffee Shop', 'Subway Station', 'Billiard', 'Subway Station', 'Coffee Shop', 'Convenience Store', 'Subway Station', 'Movie Theater', 'Coffee Shop', 'Others(Art Performing Center)', 'Coffee Shop', 'Korean Food Restaurants', 'Discount Department Store', 'Coffee Shop', 'Others(Retail)', 'Discount Department Store', 'Coffee Shop', 'Others(Restaurants)', 'Subway Station', 'Subway Station', 'Movie Theater', 'Cosmetics Shop'],place_address : ['서울 중구 남대문로5가 541', '서울 강동구 암사동 502-5', '서울 강북구 번동 418-18', '서울 강남구 삼성동159', '서울 강남구 삼성동 159', '서울 강동구 천호동 453-14', '서울 서초구 서초동 1579-6', '서울 서초구 서초동 1532-9', '서울 관악구 남현\n",
      "['2017-12-26'] The date when the person visited \"서울4호선 사당역 당고개방면 9-1/오이도방면 2-4\" is 2017-12-26.\n",
      "['2017-12-27'] 2018-01-05\n",
      "['2017-12-28'] 2017-12-29\n",
      "['2018-01-01'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_address\" columns. We need to find the date when the person visited \"서울2호선 잠실역 외선 3-1\".\n",
      "['2017-12-31', '2017-12-31'] The date when the person visited 스타벅스 대한극장점 is '2018-01-05'.\n",
      "['2017-12-27'] 2017-12-23\n",
      "['2017-12-18', '2017-12-21', '2018-01-05'] The key features of the data that could be useful in answering the question are the \"date\" column and the \"place_name\" column. We need to find the date when the person visited \"서울1호선 창동역 인천 신창행 9-1\".\n",
      "\n",
      "Looking at the \"place_name\" column, we can see that the desired place name appears in the 18th row of the dataframe. Therefore, the person visited \"서울1호선 창동역 인천 신창행 9-1\" on the 18th visit.\n",
      "\n",
      "Now, let's find the date of the 18th visit. According to the \"date\" column, the date of the 18th visit is '2017-12-14'.\n",
      "\n",
      "Therefore, the date when the person visited \"서울1호선 창동역 인천 신창행 9-1\" is '2017-12-14'.\n",
      "['2017-12-13', '2017-12-14', '2017-12-16', '2017-12-26', '2017-12-27', '2018-01-03'] The date when the person visited \"서울9호선 선정릉역 개화 방면 1-1\" can be found by filtering the dataframe based on the place_name column.\n",
      "['2018-01-05'] The key features of the data that could be useful in answering the question are the \"date\" column and the \"place_name\" column. We need to find the date when the person visited \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the specific value \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\". Then, we can retrieve the corresponding date from the \"date\" column.\n",
      "\n",
      "Here is the code to find the date:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Given dataframe\n",
      "df = pd.DataFrame({date : ['2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],hour : [7, 7, 8, 9, 10, 10, 10, 8, 8, 8, 8, 9, 17, 19, 20, 21, 8, 8, 9, 15, 15, 15, 15, 23, 22, 23, 23, 8, 8, 8, 9, 16, 16, 19, 19, 12, 12, 12, 13, 18],place_name : ['서울9호선 고속터미널역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울3호선 수서역 오금방면 9-1', '서울3호선 가락시장역 대화방면 7-1', '서울9호선 고속터미널역 개화 방면 2-4', 'THE FACE SHOP 신세계강남점', '서울3호선 고속터미널역 대화방면 5-1', '서울9호선 증미역 종합운동장 방면 2-4', '서울9호선 신논현역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울9호선 봉은사역 종합운동장 방면 2-4', '서울9호선 종합운동장역 (급행)김포공항 방면 1-1/ 종합운동장 방면 1-1', '왓포마사지 성내1호점', '스타벅스 길동사거리점', '스타벅스 길동사거리점', '이마트 가양점 /식품/비식품', '서울9호선 증미역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울9호선 신논현역 종합운동장 방면 2-4', '서울2호선 교대역 내선 7-1', '서울2호선 서초역 내선 7-1', '서울2호선 잠실역 내선 7-1', '서울2호선 종합운동장역 내선 7-1', '애플짐휘트니스클럽', '애플짐휘트니스클럽', '애플짐휘트니스클럽', '부에노커피', '서울9호선 증미역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울9호선 선유도역 종합운동장 방면 2-4', '서울9호선\n",
      "['2018-01-03'] The date when the person visited \"리바트 강동전시장점\" is 2018-01-03.\n",
      "['2017-12-28'] 2017-12-25\n",
      "['2018-01-05'] The key features of the data that could be useful in answering the question are the \"date\" column and the \"place_name\" column. We need to find the date when the person visited \"분당선 351342\".\n",
      "['2017-12-15', '2017-12-28', '2017-12-30'] The date when the person visited 햇빛병원 /내과 is '2017-12-15'.\n",
      "['2017-12-15'] The date when the person visited \"서울9호선 봉은사역 개화 방면 4-4\" is 2017-12-15.\n",
      "['2017-12-22'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"date\" columns. We need to find the date when the person visited \"아비꼬카레 신천점\".\n",
      "['2017-12-09'] The date when the person visited \"설빙 성신여대점\" is 2017-12-09.\n",
      "['2018-01-01'] 2017-12-24\n",
      "['2017-12-19'] The date when the person visited \"주민약국\" is 2017-12-19.\n",
      "['2017-12-17'] The date when the person visited \"롯데마트 서울역점 /식품\" can be found by looking at the \"place_name\" column. We need to find the date where the corresponding value in the \"place_name\" column is \"롯데마트 서울역점 /식품\". \n",
      "\n",
      "From the provided visit history, the date when the person visited \"롯데마트 서울역점 /식품\" is \"2017-12-14\".\n",
      "['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'] The date when the person visited NIKE 강남점 is '2017-12-31'.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"서울9호선 봉은사역 개화 방면 1-1\" is 2017-12-30.\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] The date when the person visited 서울야시장 is '2017-12-15'.\n",
      "['2017-12-13'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"서울6호선 공덕역 응암순환행 4-4\".\n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column and check for the value \"서울6호선 공덕역 응암순환행 4-4\".\n",
      "['2017-12-27', '2018-01-05'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\".\n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" column where the value is \"서울3호선 고속터미널역 오금방면 7-1\". Then, we can retrieve the corresponding date from the \"date\" column.\n",
      "\n",
      "The date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\" is 2017-12-27.\n",
      "['2018-01-03'] 2018-01-02\n",
      "['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'] The date when the person visited 퍼스트약국 is '2017-12-15'.\n",
      "['2018-01-03'] The key features of the data that could be useful in answering the question are the \"place_name\" and \"place_address\" columns. We need to find the date when the person visited \"서울2호선 한양대역 내선 7-1\". \n",
      "\n",
      "To find the date, we can filter the dataframe based on the \"place_name\" and \"place_address\" columns. \n",
      "\n",
      "Here is the code to find the date when the person visited \"서울2호선 한양대역 내선 7-1\":\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [15, 0, 7, 12, 13, 14, 21, 12, 13, 14, 20, 20, 11, 12, 15, 15, 17, 18, 16, 17, 18, 7, 11, 12, 11, 12, 12, 9, 12, 12, 18, 8, 9, 13, 15, 19, 17, 22, 14, 14],\n",
      "    'place_name': ['서울2호선 신설동역 지선 성수행 2-1', '서울3호선 교대역 오금방면 7-1', '파르나스몰/GS25 파르나스타워점', '파르나스몰/GS25 파르나스타워점', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울7호선 도봉산역 부평구청 방면 6-4', '서울2호선 잠실새내역 내선 3-1', '파르나스몰/18번완당명가', '스타필드 코엑스몰점/맥도날드 코엑스점', '파르나스몰/GS25 파르나스타워점', 'GS25 강남개포점', '다이소 영동프라자점', '스타필드 코엑스몰점/소풍 코엑스몰점', '파르나스몰/GS25 파르나스타워점', '서울4호선 동대문역사문화공원역 당고개방면 3-1/오이도방면 8-4', '투썸플레이스 한성대입구역점', '서울3호선 충무로역 오금방면 10-4', '피자스쿨 매봉역점', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울7호선 대림역 부평구청 방면 2-2', '서울7호선 대림역 장암 방면 6-4', '파르나스몰/GS25 파르나스타워점', '스타필드 코엑스몰점/도모다찌', '파르나스몰/GS25 파르나스타워점', 'GS25 강남개포점', 'CGV 강남점', 'GS25 개포럭키점', '파르나스몰/GS25 파르나스타워점', '파르나스몰/GS25 파르나스타워점', '스타필드 코엑스몰점/경성면옥 /도심공항타워', '파\n",
      "['2017-12-22'] The key features of the data that could be useful in answering the question are the \"date\" and \"place_name\" columns. We need to find the date when the person visited \"덕수궁피자\".\n",
      "['2017-12-31'] The date when the person visited 스타필드 코엑스몰점/커피빈 도심공항타워점 is 2018-01-05.\n",
      "json_wont\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 이찌마이 is 2017-12-30.\n",
      "['2017-12-31'] The date when the person visited \"서울5호선 왕십리역 방화행 6-4\" is 2017-12-31.\n",
      "['2017-12-22', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"요거프레소 동덕여대점\" is 2017-12-22.\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited TKS CAFE is 2017-12-26.\n",
      "['2017-12-28', '2018-01-02', '2018-01-04', '2018-01-05'] The date when the person visited GS25 문래시티점 is 2018-01-04.\n",
      "['2017-12-23'] The date when the person visited \"서울5호선 5472\" is 2017-12-23.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited \"미니스톱 신천역점\" is 2017-12-29.\n",
      "['2017-12-25', '2018-01-01'] The date when the person visited 풀잎채 두부사랑점 is 2017-12-25.\n",
      "['2018-01-02'] The date when the person visited \"서울2호선 잠실역 내선 3-1\" is 2018-01-02.\n",
      "['2017-12-16', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'] The date when the person visited \"위담한방병원 내과\" is 2017-12-16.\n",
      "['2017-12-29'] The date when the person visited \"서울7호선 강남구청역 부평구청 방면 2-2\" is 2017-12-28.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 영풍문고 강남역점 is 2017-12-29.\n",
      "['2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05'] The date when the person visited \"강남성결교회 /사무실\" is 2017-12-25.\n",
      "['2017-12-23'] The date when the person visited \"스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수\" is 2017-12-23.\n",
      "['2017-12-31'] The date when the person visited 크린업24 송파점 is 2017-12-31.\n",
      "['2017-12-06', '2017-12-06'] The date when the person visited \"피자보이시나 중앙대본점\" is 2017-12-06.\n",
      "['2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01'] The date when the person visited 오보테 /미용실 is 2017-12-23.\n",
      "['2017-12-22'] The date when the person visited 강가 역삼점 is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타벅스 이수역점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\" is 2017-12-27.\n",
      "['2018-01-02'] The date when the person visited 분당선 351939 is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"현대백화점 무역센터점 /식품/행사장\" is 2017-12-18.\n",
      "['2017-12-22', '2017-12-29', '2018-01-05'] The date when the person visited \"미소야 서초점\" is 2017-12-22.\n",
      "['2017-12-23'] The date when the person visited CU 925신논현역점 is 2017-12-23.\n",
      "['2017-12-27', '2017-12-28', '2018-01-02', '2018-01-03'] The date when the person visited \"신분당선 강남역 광교방면 2-2\" is 2018-01-03.\n",
      "['2017-12-13'] The date when the person visited \"올리브영 강변역점\" is 2017-12-13.\n",
      "['2018-01-03'] The date when the person visited \"서울4호선 숙대입구역 당고개방면 9-1\" is 2018-01-03.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 스타필드 코엑스몰점/CUBE is 2017-12-29.\n",
      "['2017-12-18'] The date when the person visited 곰돌이스타약국 is 2017-12-18.\n",
      "['2017-12-11'] The date when the person visited \"서울5호선 5756\" is 2017-12-11.\n",
      "['2017-12-15', '2017-12-18', '2018-01-04'] The date when the person visited \"서울2호선 삼성역 내선 3-1 / 외선 8-4\" is 2018-01-04.\n",
      "['2017-12-23', '2017-12-26', '2017-12-26', '2017-12-29', '2017-12-30'] The date when the person visited \"애니벅스 애니학원 강남본점\" is 2017-12-23.\n",
      "['2017-12-08'] The date when the person visited \"서울2호선 서초역 외선 5-1\" is 2017-12-08.\n",
      "['2017-12-27'] The date when the person visited 이디야 서울고교점 is 2017-12-28.\n",
      "['2017-12-22', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'] The date when the person visited \"스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이\" is 2018-01-02.\n",
      "['2017-12-22', '2017-12-22'] The date when the person visited 버거킹 시청역점 is 2017-12-22.\n",
      "['2017-12-10', '2018-01-05'] The date when the person visited \"서울2호선 신림역 내선 2-3 / 외선 9-2\" is 2018-01-05.\n",
      "['2017-12-22'] The date when the person visited 스타필드 코엑스몰점/BUTTER 코엑스점 is 2017-12-22.\n",
      "['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26'] The date when the person visited 히든코인싱어노래연습장 is 2017-12-13.\n",
      "['2017-12-29'] The date when the person visited 이디야 방이역점 is 2017-12-29.\n",
      "['2018-01-03'] The date when the person visited \"롯데마트 김포공항점 /토이저러스 외\" is 2018-01-03.\n",
      "['2018-01-04'] The date when the person visited \"포도몰 /남성의류\" is 2018-01-04.\n",
      "['2018-01-04'] The date when the person visited \"서울5호선 아차산역 방화행 6-4\" is 2018-01-04.\n",
      "['2018-01-02', '2018-01-03', '2018-01-05'] The date when the person visited \"커피식스쥬스식스 구로대륭2차점\" is 2018-01-02.\n",
      "['2017-12-14', '2017-12-14'] The date when the person visited \"스타필드 코엑스몰점/빨라쪼 코엑스몰점\" is 2017-12-14.\n",
      "['2017-12-28', '2017-12-28'] The date when the person visited CGV 군자점 is 2017-12-28.\n",
      "['2017-12-30'] The date when the person visited 세븐일레븐 도곡스타점 is 2017-12-30.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트 is 2017-12-26.\n",
      "['2017-12-26'] The date when the person visited 정관장 서대문역점 is 2017-12-26.\n",
      "['2017-12-15'] The date when the person visited \"두꺼비부대찌개\" is 2017-12-15.\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] The date when the person visited 잠실눈사람안과 is 2017-12-27.\n",
      "['2017-12-29'] The date when the person visited 이마트 자양점/몰리스펫샵 이마트자양점 is 2017-12-29.\n",
      "['2017-12-21'] The date when the person visited REFESH COFFEE&JUICE is 2017-12-21.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22'] The date when the person visited 투썸플레이스 잠실신천점 is 2017-12-22.\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited 서울3호선 3926 is 2018-01-05.\n",
      "['2017-12-15', '2017-12-22', '2017-12-22'] The date when the person visited 청솔오리 is 2017-12-15.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"분당선 351132\" is 2017-12-30.\n",
      "['2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23'] The date when the person visited \"예스자이엘라부동산\" is 2017-12-15.\n",
      "['2018-01-01'] The date when the person visited 버거킹 낙성대역점 is 2018-01-02.\n",
      "['2017-12-17', '2018-01-01', '2018-01-01'] The date when the person visited 롯데리아 월드점 is 2018-01-01.\n",
      "['2017-12-15'] The date when the person visited \"롯데백화점 강남점 본관 /여성패션\" is 2017-12-15.\n",
      "['2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'] The date when the person visited \"고려대학교 안암병원 척추센테/통증센테\" is 2017-12-30.\n",
      "['2018-01-03'] The date when the person visited MINI GOLD 돈암점 is 2018-01-03.\n",
      "['2018-01-05'] The date when the person visited 펀앤조이 /인형뽑기 is 2018-01-05.\n",
      "['2017-12-26', '2018-01-02', '2018-01-05'] The date when the person visited \"서울9호선 선정릉역 종합운동장 방면 2-4\" is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"바르미샤브샤브 삼성역점\" is 2017-12-18.\n",
      "['2017-12-25'] The date when the person visited IFC몰/Aesop IFC서울점 is 2017-12-25.\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] The date when the person visited 할리스커피 종로본점 is 2017-12-21.\n",
      "['2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18'] The date when the person visited 황금복국 is 2017-12-18.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-29'] The date when the person visited \"투썸플레이스 중계CGV스윗바점\" is 2017-12-22.\n",
      "['2017-12-29', '2018-01-04'] The date when the person visited \"서울8호선 천호역 암사방면 2-2\" is 2018-01-04.\n",
      "['2017-12-26'] The date when the person visited \"서울4호선 사당역 당고개방면 9-1/오이도방면 2-4\" is 2017-12-26.\n",
      "['2017-12-27'] The date when the person visited Art Billiard Club is 2017-12-27.\n",
      "['2017-12-24', '2017-12-24', '2017-12-24'] The date when the person visited Paul Bassett 종로1 가점 is 2017-12-24.\n",
      "['2017-12-19'] The date when the person visited 종가집 is 2017-12-19.\n",
      "['2017-12-28'] The date when the person visited 엔제리너스 사당역점 is 2017-12-28.\n",
      "['2018-01-01'] The date when the person visited \"서울2호선 잠실역 외선 3-1\" is 2018-01-01.\n",
      "['2017-12-31', '2017-12-31'] The date when the person visited 스타벅스 대한극장점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited 이디야 수서역점 is 2017-12-27.\n",
      "['2017-12-18', '2017-12-21', '2018-01-05'] The date when the person visited \"서울1호선 창동역 인천 신창행 9-1\" is 2018-01-05.\n",
      "['2017-12-13', '2017-12-14', '2017-12-16', '2017-12-26', '2017-12-27', '2018-01-03'] The date when the person visited \"서울9호선 선정릉역 개화 방면 1-1\" is 2017-12-13.\n",
      "['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"현대백화점 무역센터점 /영캐주얼\" is 2017-12-27.\n",
      "['2018-01-05'] The date when the person visited \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"리바트 강동전시장점\" is 2018-01-03.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점/STUDIO TOMBOY is 2017-12-26.\n",
      "['2018-01-02', '2018-01-04'] The date when the person visited 스타벅스 삼성역점 is 2018-01-02.\n",
      "['2017-12-28'] The date when the person visited \"파리바게뜨 서울적십자병원점\" is 2017-12-28.\n",
      "['2017-12-16'] The date when the person visited KEB하나은행 서압구정지점 is 2017-12-16.\n",
      "['2018-01-05'] The date when the person visited 분당선 351342 is 2018-01-05.\n",
      "['2017-12-15', '2017-12-28', '2017-12-30'] The date when the person visited 햇빛병원 /내과 is 2017-12-28.\n",
      "['2017-12-15'] The date when the person visited \"서울9호선 봉은사역 개화 방면 4-4\" is 2018-01-02.\n",
      "['2017-12-22'] The date when the person visited \"아비꼬카레 신천점\" is 2017-12-22.\n",
      "['2017-12-15', '2017-12-15'] The date when the person visited 스타필드 코엑스몰점/메가박스 코엑스몰점/매표소 is 2017-12-15.\n",
      "['2017-12-09'] The date when the person visited \"설빙 성신여대점\" is 2017-12-09.\n",
      "['2018-01-01'] The date when the person visited 스타벅스 청담영동대로점 is 2018-01-02.\n",
      "['2017-12-14'] The date when the person visited \"서울5호선 영등포구청역 상일동 마천행 4-4\" is 2017-12-14.\n",
      "['2017-12-19'] The date when the person visited 주민약국 is 2017-12-19.\n",
      "['2017-12-17'] The date when the person visited \"롯데마트 서울역점 /식품\" is 2017-12-17.\n",
      "['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'] The date when the person visited NIKE 강남점 is 2017-12-29.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"서울9호선 봉은사역 개화 방면 1-1\" is 2017-12-30.\n",
      "['2018-01-05'] The date when the person visited 세븐일레븐 방이한양점 is 2018-01-05.\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] The date when the person visited 서울야시장 is 2017-12-14.\n",
      "['2017-12-29'] The date when the person visited 밀숲 반포점 is 2017-12-29.\n",
      "['2017-12-13'] The date when the person visited \"서울6호선 공덕역 응암순환행 4-4\" is 2017-12-18.\n",
      "['2017-12-27', '2018-01-05'] The date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited 엔터식스 강남점/INDI BRAND 엔터식스반포점 is 2018-01-03.\n",
      "['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'] The date when the person visited 퍼스트약국 is 2017-12-15.\n",
      "['2018-01-05'] The date when the person visited 파르나스몰/18번완당명가 is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"서울2호선 한양대역 내선 7-1\" is 2018-01-03.\n",
      "['2017-12-22'] The date when the person visited \"덕수궁피자\" is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타필드 코엑스몰점/커피빈 도심공항타워점 is 2017-12-31.\n",
      "['2017-12-23'] The date when the person visited 코스트코 양평점 /의류 is 2017-12-23.\n",
      "tabsep\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 이찌마이 is 2017-12-30.\n",
      "['2017-12-31'] The date when the person visited \"서울5호선 왕십리역 방화행 6-4\" is 2017-12-31.\n",
      "['2017-12-22', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"요거프레소 동덕여대점\" is 2017-12-22.\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited TKS CAFE is 2017-12-26.\n",
      "['2017-12-28', '2018-01-02', '2018-01-04', '2018-01-05'] The date when the person visited GS25 문래시티점 is 2018-01-02.\n",
      "['2017-12-23'] The date when the person visited \"서울5호선 5472\" is 2017-12-23.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited \"미니스톱 신천역점\" is 2017-12-29.\n",
      "['2017-12-25', '2018-01-01'] The date when the person visited 풀잎채 두부사랑점 is 2017-12-25.\n",
      "['2018-01-02'] The date when the person visited \"서울2호선 잠실역 내선 3-1\" is 2018-01-02.\n",
      "['2017-12-16', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'] The date when the person visited \"위담한방병원 내과\" is 2017-12-16.\n",
      "['2017-12-29'] The date when the person visited \"서울7호선 강남구청역 부평구청 방면 2-2\" is 2017-12-28.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 영풍문고 강남역점 is 2017-12-29.\n",
      "['2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05'] The date when the person visited 강남성결교회 /사무실 is 2017-12-25.\n",
      "['2017-12-23'] The date when the person visited \"스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수\" is 2017-12-23.\n",
      "['2017-12-31'] The date when the person visited \"크린업24 송파점\" is 2017-12-31.\n",
      "['2017-12-06', '2017-12-06'] The date when the person visited \"피자보이시나 중앙대본점\" is 2017-12-06.\n",
      "['2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01'] The date when the person visited 오보테 /미용실 is 2017-12-23.\n",
      "['2017-12-22'] The date when the person visited \"강가 역삼점\" is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타벅스 이수역점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\" is 2017-12-27.\n",
      "['2018-01-02'] The date when the person visited 분당선 351939 is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"현대백화점 무역센터점 /식품/행사장\" is 2017-12-18.\n",
      "['2017-12-22', '2017-12-29', '2018-01-05'] The date when the person visited \"미소야 서초점\" is 2017-12-22.\n",
      "['2017-12-23'] The date when the person visited CU 925신논현역점 is 2017-12-23.\n",
      "['2017-12-27', '2017-12-28', '2018-01-02', '2018-01-03'] The date when the person visited \"신분당선 강남역 광교방면 2-2\" is 2017-12-27.\n",
      "['2017-12-13'] The date when the person visited \"올리브영 강변역점\" is 2017-12-13.\n",
      "['2018-01-03'] The date when the person visited \"서울4호선 숙대입구역 당고개방면 9-1\" is 2018-01-03.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 스타필드 코엑스몰점/CUBE is 2017-12-29.\n",
      "['2017-12-18'] The date when the person visited 곰돌이스타약국 is 2017-12-18.\n",
      "['2017-12-11'] The date when the person visited \"서울5호선 5756\" is 2017-12-11.\n",
      "['2017-12-15', '2017-12-18', '2018-01-04'] The date when the person visited \"서울2호선 삼성역 내선 3-1 / 외선 8-4\" is 2018-01-04.\n",
      "['2017-12-23', '2017-12-26', '2017-12-26', '2017-12-29', '2017-12-30'] The date when the person visited \"애니벅스 애니학원 강남본점\" is 2017-12-23.\n",
      "['2017-12-08'] The date when the person visited \"서울2호선 서초역 외선 5-1\" is 2017-12-08.\n",
      "['2017-12-27'] The date when the person visited 이디야 서울고교점 is 2017-12-27.\n",
      "['2017-12-22', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'] The date when the person visited \"스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이\" is 2018-01-02.\n",
      "['2017-12-22', '2017-12-22'] The date when the person visited 버거킹 시청역점 is 2017-12-22.\n",
      "['2017-12-10', '2018-01-05'] The date when the person visited \"서울2호선 신림역 내선 2-3 / 외선 9-2\" is 2018-01-05.\n",
      "['2017-12-22'] The date when the person visited 스타필드 코엑스몰점/BUTTER 코엑스점 is 2017-12-22.\n",
      "['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26'] The date when the person visited 히든코인싱어노래연습장 is 2017-12-13.\n",
      "['2017-12-29'] The date when the person visited 이디야 방이역점 is 2017-12-29.\n",
      "['2018-01-03'] The date when the person visited \"롯데마트 김포공항점 /토이저러스 외\" is 2018-01-03.\n",
      "['2018-01-04'] The date when the person visited \"포도몰 /남성의류\" is 2018-01-04.\n",
      "['2018-01-04'] The date when the person visited \"서울5호선 아차산역 방화행 6-4\" is 2018-01-04.\n",
      "['2018-01-02', '2018-01-03', '2018-01-05'] The date when the person visited \"커피식스쥬스식스 구로대륭2차점\" is 2018-01-02.\n",
      "['2017-12-14', '2017-12-14'] The date when the person visited \"스타필드 코엑스몰점/빨라쪼 코엑스몰점\" is 2017-12-14.\n",
      "['2017-12-28', '2017-12-28'] The date when the person visited CGV 군자점 is 2017-12-28.\n",
      "['2017-12-30'] The date when the person visited 세븐일레븐 도곡스타점 is 2017-12-30.\n",
      "['2017-12-26'] The date when the person visited \"스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트\" is 2017-12-26.\n",
      "['2017-12-26'] The date when the person visited 정관장 서대문역점 is 2017-12-26.\n",
      "['2017-12-15'] The date when the person visited \"두꺼비부대찌개\" is 2017-12-15.\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] The date when the person visited 잠실눈사람안과 is 2017-12-27.\n",
      "['2017-12-29'] The date when the person visited 이마트 자양점/몰리스펫샵 이마트자양점 is 2017-12-29.\n",
      "['2017-12-21'] The date when the person visited REFESH COFFEE&JUICE is 2017-12-21.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22'] The date when the person visited 투썸플레이스 잠실신천점 is 2017-12-22.\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"서울3호선 3926\" is 2018-01-05.\n",
      "['2017-12-15', '2017-12-22', '2017-12-22'] The date when the person visited 청솔오리 is 2017-12-15.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"분당선 351132\" is 2017-12-30.\n",
      "['2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23'] The date when the person visited \"예스자이엘라부동산\" is 2017-12-15.\n",
      "['2018-01-01'] The date when the person visited 버거킹 낙성대역점 is 2018-01-02.\n",
      "['2017-12-17', '2018-01-01', '2018-01-01'] The date when the person visited 롯데리아 월드점 is 2018-01-01.\n",
      "['2017-12-15'] The date when the person visited \"롯데백화점 강남점 본관 /여성패션\" is 2017-12-15.\n",
      "['2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'] The date when the person visited \"고려대학교 안암병원 척추센테/통증센테\" is 2017-12-30.\n",
      "['2018-01-03'] The date when the person visited MINI GOLD 돈암점 is 2018-01-03.\n",
      "['2018-01-05'] The date when the person visited 펀앤조이 /인형뽑기 is 2018-01-05.\n",
      "['2017-12-26', '2018-01-02', '2018-01-05'] The date when the person visited \"서울9호선 선정릉역 종합운동장 방면 2-4\" is 2017-12-26.\n",
      "['2017-12-18'] The date when the person visited \"바르미샤브샤브 삼성역점\" is 2017-12-18.\n",
      "['2017-12-25'] The date when the person visited IFC몰/Aesop IFC서울점 is 2017-12-25.\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] The date when the person visited 할리스커피 종로본점 is 2017-12-21.\n",
      "['2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18'] The date when the person visited 황금복국 is 2017-12-18.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-29'] The date when the person visited \"투썸플레이스 중계CGV스윗바점\" is 2017-12-22.\n",
      "['2017-12-29', '2018-01-04'] The date when the person visited \"서울8호선 천호역 암사방면 2-2\" is 2017-12-29.\n",
      "['2017-12-26'] The date when the person visited \"서울4호선 사당역 당고개방면 9-1/오이도방면 2-4\" is 2017-12-26.\n",
      "['2017-12-27'] The date when the person visited Art Billiard Club is 2017-12-27.\n",
      "['2017-12-24', '2017-12-24', '2017-12-24'] The date when the person visited Paul Bassett 종로1 가점 is 2017-12-24.\n",
      "['2017-12-19'] The date when the person visited 종가집 is 2017-12-19.\n",
      "['2017-12-28'] The date when the person visited 엔제리너스 사당역점 is 2017-12-28.\n",
      "['2018-01-01'] The date when the person visited \"서울2호선 잠실역 외선 3-1\" is 2018-01-01.\n",
      "['2017-12-31', '2017-12-31'] The date when the person visited 스타벅스 대한극장점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited 이디야 수서역점 is 2017-12-27.\n",
      "['2017-12-18', '2017-12-21', '2018-01-05'] The date when the person visited \"서울1호선 창동역 인천 신창행 9-1\" is 2017-12-18.\n",
      "['2017-12-13', '2017-12-14', '2017-12-16', '2017-12-26', '2017-12-27', '2018-01-03'] The date when the person visited \"서울9호선 선정릉역 개화 방면 1-1\" is 2017-12-13.\n",
      "['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"현대백화점 무역센터점 /영캐주얼\" is 2017-12-27.\n",
      "['2018-01-05'] The date when the person visited \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"리바트 강동전시장점\" is 2018-01-03.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점/STUDIO TOMBOY is 2017-12-26.\n",
      "['2018-01-02', '2018-01-04'] The date when the person visited 스타벅스 삼성역점 is 2018-01-02.\n",
      "['2017-12-28'] The date when the person visited \"파리바게뜨 서울적십자병원점\" is 2017-12-28.\n",
      "['2017-12-16'] The date when the person visited KEB하나은행 서압구정지점 is 2017-12-16.\n",
      "['2018-01-05'] The date when the person visited \"분당선 351342\" is 2018-01-05.\n",
      "['2017-12-15', '2017-12-28', '2017-12-30'] The date when the person visited 햇빛병원 /내과 is 2017-12-15.\n",
      "['2017-12-15'] The date when the person visited \"서울9호선 봉은사역 개화 방면 4-4\" is 2018-01-02.\n",
      "['2017-12-22'] The date when the person visited \"아비꼬카레 신천점\" is 2017-12-22.\n",
      "['2017-12-15', '2017-12-15'] The date when the person visited \"스타필드 코엑스몰점/메가박스 코엑스몰점/매표소\" is 2017-12-15.\n",
      "['2017-12-09'] The date when the person visited \"설빙 성신여대점\" is 2017-12-09.\n",
      "['2018-01-01'] The date when the person visited 스타벅스 청담영동대로점 is 2018-01-01.\n",
      "['2017-12-14'] The date when the person visited \"서울5호선 영등포구청역 상일동 마천행 4-4\" is 2017-12-14.\n",
      "['2017-12-19'] The date when the person visited \"주민약국\" is 2017-12-19.\n",
      "['2017-12-17'] The date when the person visited \"롯데마트 서울역점 /식품\" is 2017-12-17.\n",
      "['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'] The date when the person visited NIKE 강남점 is 2017-12-29.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"서울9호선 봉은사역 개화 방면 1-1\" is 2017-12-30.\n",
      "['2018-01-05'] The date when the person visited 세븐일레븐 방이한양점 is 2018-01-05.\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] The date when the person visited 서울야시장 is 2017-12-14.\n",
      "['2017-12-29'] The date when the person visited \"밀숲 반포점\" is 2017-12-29.\n",
      "['2017-12-13'] The date when the person visited \"서울6호선 공덕역 응암순환행 4-4\" is 2017-12-13.\n",
      "['2017-12-27', '2018-01-05'] The date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited 엔터식스 강남점/INDI BRAND 엔터식스반포점 is 2018-01-03.\n",
      "['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'] The date when the person visited 퍼스트약국 is 2017-12-15.\n",
      "['2018-01-05'] The date when the person visited 파르나스몰/18번완당명가 is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"서울2호선 한양대역 내선 7-1\" is 2018-01-03.\n",
      "['2017-12-22'] The date when the person visited \"덕수궁피자\" is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited \"스타필드 코엑스몰점/커피빈 도심공항타워점\" is 2017-12-31.\n",
      "['2017-12-23'] The date when the person visited 코스트코 양평점 /의류 is 2017-12-23.\n",
      "commasep\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 이찌마이 is 2017-12-30.\n",
      "['2017-12-31'] The date when the person visited \"서울5호선 왕십리역 방화행 6-4\" is 2017-12-31.\n",
      "['2017-12-22', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"요거프레소 동덕여대점\" is 2017-12-22.\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited TKS CAFE is 2017-12-26.\n",
      "['2017-12-28', '2018-01-02', '2018-01-04', '2018-01-05'] The date when the person visited GS25 문래시티점 is 2018-01-02.\n",
      "['2017-12-23'] The date when the person visited \"서울5호선 5472\" is 2017-12-23.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited \"미니스톱 신천역점\" is 2017-12-29.\n",
      "['2017-12-25', '2018-01-01'] The date when the person visited 풀잎채 두부사랑점 is 2017-12-25.\n",
      "['2018-01-02'] The date when the person visited \"서울2호선 잠실역 내선 3-1\" is 2018-01-02.\n",
      "['2017-12-16', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'] The date when the person visited \"위담한방병원 내과\" is 2017-12-16.\n",
      "['2017-12-29'] The date when the person visited \"서울7호선 강남구청역 부평구청 방면 2-2\" is 2017-12-28.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 영풍문고 강남역점 is 2017-12-29.\n",
      "['2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05'] The date when the person visited 강남성결교회 /사무실 is 2017-12-25.\n",
      "['2017-12-23'] The date when the person visited \"스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수\" is 2017-12-23.\n",
      "['2017-12-31'] The date when the person visited 크린업24 송파점 is 2017-12-31.\n",
      "['2017-12-06', '2017-12-06'] The date when the person visited \"피자보이시나 중앙대본점\" is 2017-12-06.\n",
      "['2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01'] The date when the person visited 오보테 /미용실 is 2017-12-23.\n",
      "['2017-12-22'] The date when the person visited \"강가 역삼점\" is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타벅스 이수역점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\" is 2017-12-27.\n",
      "['2018-01-02'] The date when the person visited 분당선 351939 is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"현대백화점 무역센터점 /식품/행사장\" is 2017-12-18.\n",
      "['2017-12-22', '2017-12-29', '2018-01-05'] The date when the person visited \"미소야 서초점\" is 2017-12-22.\n",
      "['2017-12-23'] The date when the person visited CU 925신논현역점 is 2017-12-23.\n",
      "['2017-12-27', '2017-12-28', '2018-01-02', '2018-01-03'] The date when the person visited \"신분당선 강남역 광교방면 2-2\" is 2017-12-27.\n",
      "['2017-12-13'] The date when the person visited \"올리브영 강변역점\" is 2017-12-13.\n",
      "['2018-01-03'] The date when the person visited \"서울4호선 숙대입구역 당고개방면 9-1\" is 2018-01-03.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 스타필드 코엑스몰점/CUBE is 2017-12-29.\n",
      "['2017-12-18'] The date when the person visited 곰돌이스타약국 is 2017-12-18.\n",
      "['2017-12-11'] The date when the person visited \"서울5호선 5756\" is 2017-12-11.\n",
      "['2017-12-15', '2017-12-18', '2018-01-04'] The date when the person visited \"서울2호선 삼성역 내선 3-1 / 외선 8-4\" is 2018-01-04.\n",
      "['2017-12-23', '2017-12-26', '2017-12-26', '2017-12-29', '2017-12-30'] The date when the person visited \"애니벅스 애니학원 강남본점\" is 2017-12-26.\n",
      "['2017-12-08'] The date when the person visited \"서울2호선 서초역 외선 5-1\" is 2017-12-08.\n",
      "['2017-12-27'] The date when the person visited 이디야 서울고교점 is 2017-12-27.\n",
      "['2017-12-22', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'] The date when the person visited \"스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이\" is 2018-01-02.\n",
      "['2017-12-22', '2017-12-22'] The date when the person visited 버거킹 시청역점 is 2017-12-22.\n",
      "['2017-12-10', '2018-01-05'] The date when the person visited \"서울2호선 신림역 내선 2-3 / 외선 9-2\" is 2018-01-05.\n",
      "['2017-12-22'] The date when the person visited 스타필드 코엑스몰점/BUTTER 코엑스점 is 2017-12-22.\n",
      "['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26'] The date when the person visited 히든코인싱어노래연습장 is 2017-12-13.\n",
      "['2017-12-29'] The date when the person visited 이디야 방이역점 is 2017-12-29.\n",
      "['2018-01-03'] The date when the person visited \"롯데마트 김포공항점 /토이저러스 외\" is 2018-01-03.\n",
      "['2018-01-04'] The date when the person visited \"포도몰 /남성의류\" is 2018-01-04.\n",
      "['2018-01-04'] The date when the person visited \"서울5호선 아차산역 방화행 6-4\" is 2018-01-04.\n",
      "['2018-01-02', '2018-01-03', '2018-01-05'] The date when the person visited \"커피식스쥬스식스 구로대륭2차점\" is 2018-01-02.\n",
      "['2017-12-14', '2017-12-14'] The date when the person visited \"스타필드 코엑스몰점/빨라쪼 코엑스몰점\" is 2017-12-14.\n",
      "['2017-12-28', '2017-12-28'] The date when the person visited CGV 군자점 is 2017-12-28.\n",
      "['2017-12-30'] The date when the person visited 세븐일레븐 도곡스타점 is 2017-12-30.\n",
      "['2017-12-26'] The date when the person visited \"스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트\" is 2017-12-26.\n",
      "['2017-12-26'] The date when the person visited 정관장 서대문역점 is 2017-12-26.\n",
      "['2017-12-15'] The date when the person visited \"두꺼비부대찌개\" is 2017-12-15.\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] The date when the person visited 잠실눈사람안과 is 2017-12-27.\n",
      "['2017-12-29'] The date when the person visited \"이마트 자양점/몰리스펫샵 이마트자양점\" is 2017-12-29.\n",
      "['2017-12-21'] The date when the person visited REFESH COFFEE&JUICE is 2017-12-21.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22'] The date when the person visited 투썸플레이스 잠실신천점 is 2017-12-22.\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"서울3호선 3926\" is 2018-01-05.\n",
      "['2017-12-15', '2017-12-22', '2017-12-22'] The date when the person visited 청솔오리 is 2017-12-15.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"분당선 351132\" is 2017-12-30.\n",
      "['2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23'] The date when the person visited \"예스자이엘라부동산\" is 2017-12-15.\n",
      "['2018-01-01'] The date when the person visited 버거킹 낙성대역점 is 2018-01-02.\n",
      "['2017-12-17', '2018-01-01', '2018-01-01'] The date when the person visited 롯데리아 월드점 is 2017-12-17.\n",
      "['2017-12-15'] The date when the person visited \"롯데백화점 강남점 본관 /여성패션\" is 2017-12-15.\n",
      "['2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'] The date when the person visited \"고려대학교 안암병원 척추센테/통증센테\" is 2017-12-30.\n",
      "['2018-01-03'] The date when the person visited MINI GOLD 돈암점 is 2018-01-03.\n",
      "['2018-01-05'] The date when the person visited 펀앤조이 /인형뽑기 is 2018-01-05.\n",
      "['2017-12-26', '2018-01-02', '2018-01-05'] The date when the person visited \"서울9호선 선정릉역 종합운동장 방면 2-4\" is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"바르미샤브샤브 삼성역점\" is 2017-12-18.\n",
      "['2017-12-25'] The date when the person visited IFC몰/Aesop IFC서울점 is 2017-12-25.\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] The date when the person visited 할리스커피 종로본점 is 2017-12-21.\n",
      "['2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18'] The date when the person visited 황금복국 is 2017-12-18.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-29'] The date when the person visited \"투썸플레이스 중계CGV스윗바점\" is 2017-12-22.\n",
      "['2017-12-29', '2018-01-04'] The date when the person visited \"서울8호선 천호역 암사방면 2-2\" is 2017-12-29.\n",
      "['2017-12-26'] The date when the person visited \"서울4호선 사당역 당고개방면 9-1/오이도방면 2-4\" is 2017-12-26.\n",
      "['2017-12-27'] The date when the person visited Art Billiard Club is 2017-12-27.\n",
      "['2017-12-24', '2017-12-24', '2017-12-24'] The date when the person visited Paul Bassett 종로1 가점 is 2017-12-24.\n",
      "['2017-12-19'] The date when the person visited 종가집 is 2017-12-19.\n",
      "['2017-12-28'] The date when the person visited 엔제리너스 사당역점 is 2017-12-28.\n",
      "['2018-01-01'] The date when the person visited \"서울2호선 잠실역 외선 3-1\" is 2018-01-01.\n",
      "['2017-12-31', '2017-12-31'] The date when the person visited 스타벅스 대한극장점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited 이디야 수서역점 is 2017-12-27.\n",
      "['2017-12-18', '2017-12-21', '2018-01-05'] The date when the person visited \"서울1호선 창동역 인천 신창행 9-1\" is 2018-01-05.\n",
      "['2017-12-13', '2017-12-14', '2017-12-16', '2017-12-26', '2017-12-27', '2018-01-03'] The date when the person visited \"서울9호선 선정릉역 개화 방면 1-1\" is 2017-12-13.\n",
      "['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"현대백화점 무역센터점 /영캐주얼\" is 2017-12-27.\n",
      "['2018-01-05'] The date when the person visited \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"리바트 강동전시장점\" is 2018-01-03.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점/STUDIO TOMBOY is 2017-12-26.\n",
      "['2018-01-02', '2018-01-04'] The date when the person visited 스타벅스 삼성역점 is 2018-01-04.\n",
      "['2017-12-28'] The date when the person visited \"파리바게뜨 서울적십자병원점\" is 2017-12-28.\n",
      "['2017-12-16'] The date when the person visited KEB하나은행 서압구정지점 is 2017-12-16.\n",
      "['2018-01-05'] The date when the person visited \"분당선 351342\" is 2018-01-05.\n",
      "['2017-12-15', '2017-12-28', '2017-12-30'] The date when the person visited 햇빛병원 /내과 is 2017-12-15.\n",
      "['2017-12-15'] The date when the person visited \"서울9호선 봉은사역 개화 방면 4-4\" is 2018-01-02.\n",
      "['2017-12-22'] The date when the person visited \"아비꼬카레 신천점\" is 2017-12-22.\n",
      "['2017-12-15', '2017-12-15'] The date when the person visited \"스타필드 코엑스몰점/메가박스 코엑스몰점/매표소\" is 2017-12-15.\n",
      "['2017-12-09'] The date when the person visited \"설빙 성신여대점\" is 2017-12-09.\n",
      "['2018-01-01'] The date when the person visited 스타벅스 청담영동대로점 is 2018-01-02.\n",
      "['2017-12-14'] The date when the person visited \"서울5호선 영등포구청역 상일동 마천행 4-4\" is 2017-12-14.\n",
      "['2017-12-19'] The date when the person visited \"주민약국\" is 2017-12-19.\n",
      "['2017-12-17'] The date when the person visited \"롯데마트 서울역점 /식품\" is 2017-12-17.\n",
      "['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'] The date when the person visited NIKE 강남점 is 2017-12-29.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"서울9호선 봉은사역 개화 방면 1-1\" is 2017-12-30.\n",
      "['2018-01-05'] The date when the person visited 세븐일레븐 방이한양점 is 2018-01-05.\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] The date when the person visited 서울야시장 is 2017-12-14.\n",
      "['2017-12-29'] The date when the person visited 밀숲 반포점 is 2017-12-29.\n",
      "['2017-12-13'] The date when the person visited \"서울6호선 공덕역 응암순환행 4-4\" is 2017-12-13.\n",
      "['2017-12-27', '2018-01-05'] The date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited 엔터식스 강남점/INDI BRAND 엔터식스반포점 is 2018-01-03.\n",
      "['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'] The date when the person visited 퍼스트약국 is 2017-12-15.\n",
      "['2018-01-05'] The date when the person visited \"파르나스몰/18번완당명가\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"서울2호선 한양대역 내선 7-1\" is 2018-01-03.\n",
      "['2017-12-22'] The date when the person visited \"덕수궁피자\" can be found by looking at the \"place_name\" feature in the visit history. We need to find the date when the value of \"place_name\" is \"덕수궁피자\". \n",
      "\n",
      "From the provided visit history, we can see that the person visited \"덕수궁피자\" on the date \"2017-12-22\".\n",
      "['2017-12-31'] The date when the person visited \"스타필드 코엑스몰점/커피빈 도심공항타워점\" is 2017-12-31.\n",
      "['2017-12-23'] The date when the person visited 코스트코 양평점 /의류 is 2017-12-23.\n",
      "totext\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 이찌마이 is 2017-12-30.\n",
      "['2017-12-31'] The date when the person visited \"서울5호선 왕십리역 방화행 6-4\" is 2017-12-31.\n",
      "['2017-12-22', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"요거프레소 동덕여대점\" is 2017-12-22.\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited TKS CAFE is 2017-12-26.\n",
      "['2017-12-28', '2018-01-02', '2018-01-04', '2018-01-05'] The date when the person visited GS25 문래시티점 is 2018-01-02.\n",
      "['2017-12-23'] The date when the person visited 서울5호선 5472 is 2017-12-23.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited \"미니스톱 신천역점\" is 2017-12-29.\n",
      "['2017-12-25', '2018-01-01'] The date when the person visited \"풀잎채 두부사랑점\" is 2017-12-25.\n",
      "['2018-01-02'] The date when the person visited \"서울2호선 잠실역 내선 3-1\" is 2018-01-05.\n",
      "['2017-12-16', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'] The date when the person visited \"위담한방병원 내과\" is 2017-12-16.\n",
      "['2017-12-29'] The date when the person visited \"서울7호선 강남구청역 부평구청 방면 2-2\" is 2017-12-28.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 영풍문고 강남역점 is 2017-12-29.\n",
      "['2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05'] The date when the person visited 강남성결교회 /사무실 is 2017-12-25.\n",
      "['2017-12-23'] The date when the person visited 스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수 is 2017-12-23.\n",
      "['2017-12-31'] The date when the person visited 크린업24 송파점 is 2017-12-31.\n",
      "['2017-12-06', '2017-12-06'] The date when the person visited \"피자보이시나 중앙대본점\" is 2017-12-06.\n",
      "['2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01'] The date when the person visited 오보테 /미용실 is 2017-12-23.\n",
      "['2017-12-22'] The date when the person visited 강가 역삼점 is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타벅스 이수역점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\" is 2017-12-27.\n",
      "['2018-01-02'] The date when the person visited 분당선 351939 is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"현대백화점 무역센터점 /식품/행사장\" is 2017-12-18.\n",
      "['2017-12-22', '2017-12-29', '2018-01-05'] The date when the person visited \"미소야 서초점\" is 2017-12-22.\n",
      "['2017-12-23'] The date when the person visited CU 925신논현역점 is 2017-12-23.\n",
      "['2017-12-27', '2017-12-28', '2018-01-02', '2018-01-03'] The date when the person visited \"신분당선 강남역 광교방면 2-2\" is 2017-12-27.\n",
      "['2017-12-13'] The date when the person visited 올리브영 강변역점 is 2017-12-13.\n",
      "['2018-01-03'] The date when the person visited \"서울4호선 숙대입구역 당고개방면 9-1\" is 2018-01-03.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 스타필드 코엑스몰점/CUBE is 2017-12-29.\n",
      "['2017-12-18'] The date when the person visited 곰돌이스타약국 is 2017-12-18.\n",
      "['2017-12-11'] The date when the person visited \"서울5호선 5756\" is 2017-12-11.\n",
      "['2017-12-15', '2017-12-18', '2018-01-04'] The date when the person visited \"서울2호선 삼성역 내선 3-1 / 외선 8-4\" is 2018-01-04.\n",
      "['2017-12-23', '2017-12-26', '2017-12-26', '2017-12-29', '2017-12-30'] The date when the person visited 애니벅스 애니학원 강남본점 is 2017-12-26.\n",
      "['2017-12-08'] The date when the person visited \"서울2호선 서초역 외선 5-1\" is 2017-12-08.\n",
      "['2017-12-27'] The date when the person visited 이디야 서울고교점 is 2017-12-27.\n",
      "['2017-12-22', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'] The date when the person visited \"스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이\" is 2018-01-02.\n",
      "['2017-12-22', '2017-12-22'] The date when the person visited 버거킹 시청역점 is 2017-12-22.\n",
      "['2017-12-10', '2018-01-05'] The date when the person visited \"서울2호선 신림역 내선 2-3 / 외선 9-2\" is 2018-01-05.\n",
      "['2017-12-22'] The date when the person visited 스타필드 코엑스몰점/BUTTER 코엑스점 is 2017-12-22.\n",
      "['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26'] The date when the person visited 히든코인싱어노래연습장 is 2017-12-13.\n",
      "['2017-12-29'] The date when the person visited 이디야 방이역점 is 2017-12-29.\n",
      "['2018-01-03'] The date when the person visited \"롯데마트 김포공항점 /토이저러스 외\" is 2018-01-03.\n",
      "['2018-01-04'] The date when the person visited \"포도몰 /남성의류\" is 2018-01-04.\n",
      "['2018-01-04'] The date when the person visited \"서울5호선 아차산역 방화행 6-4\" is 2018-01-04.\n",
      "['2018-01-02', '2018-01-03', '2018-01-05'] The date when the person visited \"커피식스쥬스식스 구로대륭2차점\" is 2018-01-02.\n",
      "['2017-12-14', '2017-12-14'] The date when the person visited 스타필드 코엑스몰점/빨라쪼 코엑스몰점 is 2017-12-14.\n",
      "['2017-12-28', '2017-12-28'] The date when the person visited CGV 군자점 is 2017-12-28.\n",
      "['2017-12-30'] The date when the person visited 세븐일레븐 도곡스타점 is 2017-12-30.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트 is 2017-12-26.\n",
      "['2017-12-26'] The date when the person visited 정관장 서대문역점 is 2017-12-26.\n",
      "['2017-12-15'] The date when the person visited \"두꺼비부대찌개\" is 2017-12-15.\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] The date when the person visited 잠실눈사람안과 is 2017-12-27.\n",
      "['2017-12-29'] The date when the person visited 이마트 자양점/몰리스펫샵 이마트자양점 is 2017-12-29.\n",
      "['2017-12-21'] The date when the person visited REFESH COFFEE&JUICE is 2017-12-21.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22'] The date when the person visited 투썸플레이스 잠실신천점 is 2017-12-22.\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited 서울3호선 3926 is 2018-01-05.\n",
      "['2017-12-15', '2017-12-22', '2017-12-22'] The date when the person visited 청솔오리 is 2017-12-15.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 분당선 351132 is 2017-12-30.\n",
      "['2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23'] The date when the person visited \"예스자이엘라부동산\" is 2017-12-15.\n",
      "['2018-01-01'] The date when the person visited 버거킹 낙성대역점 is 2018-01-01.\n",
      "['2017-12-17', '2018-01-01', '2018-01-01'] The date when the person visited 롯데리아 월드점 is 2018-01-01.\n",
      "['2017-12-15'] The date when the person visited \"롯데백화점 강남점 본관 /여성패션\" is 2017-12-15.\n",
      "['2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'] The date when the person visited \"고려대학교 안암병원 척추센테/통증센테\" is 2017-12-30.\n",
      "['2018-01-03'] The date when the person visited MINI GOLD 돈암점 is 2018-01-03.\n",
      "['2018-01-05'] The date when the person visited 펀앤조이 /인형뽑기 is 2018-01-05.\n",
      "['2017-12-26', '2018-01-02', '2018-01-05'] The date when the person visited \"서울9호선 선정릉역 종합운동장 방면 2-4\" is 2017-12-26.\n",
      "['2017-12-18'] The date when the person visited \"바르미샤브샤브 삼성역점\" is 2017-12-18.\n",
      "['2017-12-25'] The date when the person visited IFC몰/Aesop IFC서울점 is 2017-12-25.\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] The date when the person visited 할리스커피 종로본점 is 2017-12-21.\n",
      "['2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18'] The date when the person visited 황금복국 is 2017-12-18.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-29'] The date when the person visited \"투썸플레이스 중계CGV스윗바점\" is 2017-12-22.\n",
      "['2017-12-29', '2018-01-04'] The date when the person visited \"서울8호선 천호역 암사방면 2-2\" is 2018-01-04.\n",
      "['2017-12-26'] The date when the person visited \"서울4호선 사당역 당고개방면 9-1/오이도방면 2-4\" is 2017-12-26.\n",
      "['2017-12-27'] The date when the person visited Art Billiard Club is 2017-12-27.\n",
      "['2017-12-24', '2017-12-24', '2017-12-24'] The date when the person visited Paul Bassett 종로1 가점 is 2017-12-24.\n",
      "['2017-12-19'] The date when the person visited 종가집 is 2017-12-19.\n",
      "['2017-12-28'] The date when the person visited 엔제리너스 사당역점 is 2017-12-28.\n",
      "['2018-01-01'] The date when the person visited \"서울2호선 잠실역 외선 3-1\" is 2018-01-01.\n",
      "['2017-12-31', '2017-12-31'] The date when the person visited 스타벅스 대한극장점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited 이디야 수서역점 is 2017-12-27.\n",
      "['2017-12-18', '2017-12-21', '2018-01-05'] The date when the person visited \"서울1호선 창동역 인천 신창행 9-1\" is 2018-01-05.\n",
      "['2017-12-13', '2017-12-14', '2017-12-16', '2017-12-26', '2017-12-27', '2018-01-03'] The date when the person visited \"서울9호선 선정릉역 개화 방면 1-1\" is 2017-12-13.\n",
      "['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"현대백화점 무역센터점 /영캐주얼\" is 2017-12-27.\n",
      "['2018-01-05'] The date when the person visited \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited 리바트 강동전시장점 is 2018-01-03.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점/STUDIO TOMBOY is 2017-12-26.\n",
      "['2018-01-02', '2018-01-04'] The date when the person visited 스타벅스 삼성역점 is 2018-01-02.\n",
      "['2017-12-28'] The date when the person visited \"파리바게뜨 서울적십자병원점\" is 2017-12-28.\n",
      "['2017-12-16'] The date when the person visited KEB하나은행 서압구정지점 is 2017-12-16.\n",
      "['2018-01-05'] The date when the person visited 분당선 351342 is 2018-01-05.\n",
      "['2017-12-15', '2017-12-28', '2017-12-30'] The date when the person visited 햇빛병원 /내과 is 2017-12-28.\n",
      "['2017-12-15'] The date when the person visited \"서울9호선 봉은사역 개화 방면 4-4\" is 2017-12-15.\n",
      "['2017-12-22'] The date when the person visited \"아비꼬카레 신천점\" is 2017-12-22.\n",
      "['2017-12-15', '2017-12-15'] The date when the person visited 스타필드 코엑스몰점/메가박스 코엑스몰점/매표소 is 2017-12-15.\n",
      "['2017-12-09'] The date when the person visited \"설빙 성신여대점\" is 2017-12-09.\n",
      "['2018-01-01'] The date when the person visited 스타벅스 청담영동대로점 is 2018-01-01.\n",
      "['2017-12-14'] The date when the person visited \"서울5호선 영등포구청역 상일동 마천행 4-4\" is 2017-12-14.\n",
      "['2017-12-19'] The date when the person visited 주민약국 is 2017-12-19.\n",
      "['2017-12-17'] The date when the person visited \"롯데마트 서울역점 /식품\" is 2017-12-17.\n",
      "['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'] The date when the person visited NIKE 강남점 is 2017-12-29.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"서울9호선 봉은사역 개화 방면 1-1\" is 2017-12-30.\n",
      "['2018-01-05'] The date when the person visited 세븐일레븐 방이한양점 is 2018-01-05.\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] The date when the person visited 서울야시장 is 2017-12-14.\n",
      "['2017-12-29'] The date when the person visited 밀숲 반포점 is 2017-12-29.\n",
      "['2017-12-13'] The date when the person visited \"서울6호선 공덕역 응암순환행 4-4\" is 2017-12-18.\n",
      "['2017-12-27', '2018-01-05'] The date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited 엔터식스 강남점/INDI BRAND 엔터식스반포점 is 2018-01-03.\n",
      "['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'] The date when the person visited 퍼스트약국 is 2017-12-15.\n",
      "['2018-01-05'] The date when the person visited 파르나스몰/18번완당명가 is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"서울2호선 한양대역 내선 7-1\" is 2018-01-03.\n",
      "['2017-12-22'] The date when the person visited \"덕수궁피자\" is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타필드 코엑스몰점/커피빈 도심공항타워점 is 2017-12-31.\n",
      "['2017-12-23'] The date when the person visited \"코스트코 양평점 /의류\" is 2017-12-23.\n",
      "totextvisited\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 이찌마이 is 2017-12-30.\n",
      "['2017-12-31'] The date when the person visited \"서울5호선 왕십리역 방화행 6-4\" is 2017-12-31.\n",
      "['2017-12-22', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"요거프레소 동덕여대점\" is 2017-12-22.\n",
      "['2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited TKS CAFE is 2017-12-26.\n",
      "['2017-12-28', '2018-01-02', '2018-01-04', '2018-01-05'] The date when the person visited GS25 문래시티점 is 2017-12-28.\n",
      "['2017-12-23'] The date when the person visited 서울5호선 5472 is 2017-12-23.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited \"미니스톱 신천역점\" is 2017-12-29.\n",
      "['2017-12-25', '2018-01-01'] The date when the person visited 풀잎채 두부사랑점 is 2017-12-25.\n",
      "['2018-01-02'] The date when the person visited \"서울2호선 잠실역 내선 3-1\" is 2018-01-02.\n",
      "['2017-12-16', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'] The date when the person visited \"위담한방병원 내과\" is 2017-12-16.\n",
      "['2017-12-29'] The date when the person visited \"서울7호선 강남구청역 부평구청 방면 2-2\" is 2017-12-28.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 영풍문고 강남역점 is 2017-12-29.\n",
      "['2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05'] The date when the person visited 강남성결교회 /사무실 is 2017-12-25.\n",
      "['2017-12-23'] The date when the person visited 스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수 is 2017-12-23.\n",
      "['2017-12-31'] The date when the person visited 크린업24 송파점 is 2017-12-31.\n",
      "['2017-12-06', '2017-12-06'] The date when the person visited \"피자보이시나 중앙대본점\" is 2017-12-06.\n",
      "['2017-12-22'] The date when the person visited 강가 역삼점 is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타벅스 이수역점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited \"서울5호선 목동역 상일동 마천행 6-4\" is 2017-12-27.\n",
      "['2018-01-02'] The date when the person visited 분당선 351939 is 2018-01-02.\n",
      "['2017-12-18'] The date when the person visited \"현대백화점 무역센터점 /식품/행사장\" is 2017-12-18.\n",
      "['2017-12-22', '2017-12-29', '2018-01-05'] The date when the person visited \"미소야 서초점\" is 2017-12-22.\n",
      "['2017-12-23'] The date when the person visited CU 925신논현역점 is 2017-12-23.\n",
      "['2017-12-27', '2017-12-28', '2018-01-02', '2018-01-03'] The date when the person visited \"신분당선 강남역 광교방면 2-2\" is 2017-12-27.\n",
      "['2017-12-13'] The date when the person visited 올리브영 강변역점 is 2017-12-13.\n",
      "['2018-01-03'] The date when the person visited \"서울4호선 숙대입구역 당고개방면 9-1\" is 2018-01-03.\n",
      "['2017-12-29', '2017-12-29'] The date when the person visited 스타필드 코엑스몰점/CUBE is 2017-12-29.\n",
      "['2017-12-18'] The date when the person visited 곰돌이스타약국 is 2017-12-18.\n",
      "['2017-12-11'] The date when the person visited 서울5호선 5756 is 2017-12-11.\n",
      "['2017-12-15', '2017-12-18', '2018-01-04'] The date when the person visited \"서울2호선 삼성역 내선 3-1 / 외선 8-4\" is 2017-12-15.\n",
      "['2017-12-23', '2017-12-26', '2017-12-26', '2017-12-29', '2017-12-30'] The date when the person visited 애니벅스 애니학원 강남본점 is 2017-12-23.\n",
      "['2017-12-08'] The date when the person visited \"서울2호선 서초역 외선 5-1\" is 2017-12-08.\n",
      "['2017-12-27'] The date when the person visited 이디야 서울고교점 is 2017-12-27.\n",
      "['2017-12-22', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'] The date when the person visited \"스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이\" is 2017-12-22.\n",
      "['2017-12-22', '2017-12-22'] The date when the person visited 버거킹 시청역점 is 2017-12-22.\n",
      "['2017-12-10', '2018-01-05'] The date when the person visited \"서울2호선 신림역 내선 2-3 / 외선 9-2\" is 2017-12-10.\n",
      "['2017-12-22'] The date when the person visited 스타필드 코엑스몰점/BUTTER 코엑스점 is 2017-12-22.\n",
      "['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26'] The date when the person visited 히든코인싱어노래연습장 is 2017-12-13.\n",
      "['2017-12-29'] The date when the person visited 이디야 방이역점 is 2017-12-29.\n",
      "['2018-01-03'] The date when the person visited 롯데마트 김포공항점 /토이저러스 외 is 2018-01-03.\n",
      "['2018-01-04'] The date when the person visited \"포도몰 /남성의류\" is 2018-01-04.\n",
      "['2018-01-04'] The date when the person visited \"서울5호선 아차산역 방화행 6-4\" is 2018-01-04.\n",
      "['2018-01-02', '2018-01-03', '2018-01-05'] The date when the person visited \"커피식스쥬스식스 구로대륭2차점\" is 2018-01-02.\n",
      "['2017-12-14', '2017-12-14'] The date when the person visited 스타필드 코엑스몰점/빨라쪼 코엑스몰점 is 2017-12-14.\n",
      "['2017-12-28', '2017-12-28'] The date when the person visited CGV 군자점 is 2017-12-28.\n",
      "['2017-12-30'] The date when the person visited 세븐일레븐 도곡스타점 is 2017-12-30.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트 is 2017-12-26.\n",
      "['2017-12-26'] The date when the person visited 정관장 서대문역점 is 2017-12-26.\n",
      "['2017-12-15'] The date when the person visited \"두꺼비부대찌개\" is 2017-12-15.\n",
      "['2017-12-27', '2017-12-28', '2018-01-03', '2018-01-03'] The date when the person visited 잠실눈사람안과 is 2017-12-27.\n",
      "['2017-12-21'] The date when the person visited REFESH COFFEE&JUICE is 2017-12-21.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22'] The date when the person visited 투썸플레이스 잠실신천점 is 2017-12-22.\n",
      "['2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited 서울3호선 3926 is 2018-01-05.\n",
      "['2017-12-15', '2017-12-22', '2017-12-22'] The date when the person visited 청솔오리 is 2017-12-15.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited 분당선 351132 is 2017-12-30.\n",
      "['2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23'] The date when the person visited 예스자이엘라부동산 is 2017-12-15.\n",
      "['2018-01-01'] The date when the person visited 버거킹 낙성대역점 is 2018-01-01.\n",
      "['2017-12-17', '2018-01-01', '2018-01-01'] The date when the person visited 롯데리아 월드점 is 2017-12-17.\n",
      "['2017-12-15'] The date when the person visited \"롯데백화점 강남점 본관 /여성패션\" is 2017-12-15.\n",
      "['2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'] The date when the person visited \"고려대학교 안암병원 척추센테/통증센테\" is 2017-12-30.\n",
      "['2018-01-03'] The date when the person visited MINI GOLD 돈암점 is 2018-01-03.\n",
      "['2018-01-05'] The date when the person visited 펀앤조이 /인형뽑기 is 2018-01-05.\n",
      "['2017-12-26', '2018-01-02', '2018-01-05'] The date when the person visited \"서울9호선 선정릉역 종합운동장 방면 2-4\" is 2017-12-26.\n",
      "['2017-12-18'] The date when the person visited \"바르미샤브샤브 삼성역점\" is 2017-12-18.\n",
      "['2017-12-25'] The date when the person visited IFC몰/Aesop IFC서울점 is 2017-12-25.\n",
      "['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02'] The date when the person visited 할리스커피 종로본점 is 2017-12-21.\n",
      "['2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18'] The date when the person visited 황금복국 is 2017-12-18.\n",
      "['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-29'] The date when the person visited \"투썸플레이스 중계CGV스윗바점\" is 2017-12-22.\n",
      "['2017-12-29', '2018-01-04'] The date when the person visited \"서울8호선 천호역 암사방면 2-2\" is 2017-12-29.\n",
      "['2017-12-26'] The date when the person visited \"서울4호선 사당역 당고개방면 9-1/오이도방면 2-4\" is 2017-12-26.\n",
      "['2017-12-27'] The date when the person visited Art Billiard Club is 2017-12-27.\n",
      "['2017-12-24', '2017-12-24', '2017-12-24'] The date when the person visited Paul Bassett 종로1 가점 is 2017-12-24.\n",
      "['2017-12-19'] The date when the person visited 종가집 is 2017-12-19.\n",
      "['2017-12-28'] The date when the person visited 엔제리너스 사당역점 is 2017-12-28.\n",
      "['2018-01-01'] The date when the person visited \"서울2호선 잠실역 외선 3-1\" is 2018-01-01.\n",
      "['2017-12-31', '2017-12-31'] The date when the person visited 스타벅스 대한극장점 is 2017-12-31.\n",
      "['2017-12-27'] The date when the person visited 이디야 수서역점 is 2017-12-27.\n",
      "['2017-12-18', '2017-12-21', '2018-01-05'] The date when the person visited \"서울1호선 창동역 인천 신창행 9-1\" is 2017-12-18.\n",
      "['2017-12-13', '2017-12-14', '2017-12-16', '2017-12-26', '2017-12-27', '2018-01-03'] The date when the person visited \"서울9호선 선정릉역 개화 방면 1-1\" is 2017-12-13.\n",
      "['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'] The date when the person visited \"현대백화점 무역센터점 /영캐주얼\" is 2017-12-27.\n",
      "['2018-01-05'] The date when the person visited \"서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3\" is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited 리바트 강동전시장점 is 2018-01-03.\n",
      "['2017-12-26'] The date when the person visited 스타필드 코엑스몰점/STUDIO TOMBOY is 2017-12-26.\n",
      "['2018-01-02', '2018-01-04'] The date when the person visited 스타벅스 삼성역점 is 2018-01-02.\n",
      "['2017-12-16'] The date when the person visited KEB하나은행 서압구정지점 is 2017-12-16.\n",
      "['2018-01-05'] The date when the person visited 분당선 351342 is 2018-01-05.\n",
      "['2017-12-15', '2017-12-28', '2017-12-30'] The date when the person visited 햇빛병원 /내과 is 2017-12-15.\n",
      "['2017-12-15'] The date when the person visited \"서울9호선 봉은사역 개화 방면 4-4\" is 2017-12-15.\n",
      "['2017-12-22'] The date when the person visited 아비꼬카레 신천점 is 2017-12-22.\n",
      "['2017-12-15', '2017-12-15'] The date when the person visited 스타필드 코엑스몰점/메가박스 코엑스몰점/매표소 is 2017-12-15.\n",
      "['2017-12-09'] The date when the person visited \"설빙 성신여대점\" is 2017-12-09.\n",
      "['2018-01-01'] The date when the person visited 스타벅스 청담영동대로점 is 2018-01-01.\n",
      "['2017-12-14'] The date when the person visited \"서울5호선 영등포구청역 상일동 마천행 4-4\" is 2017-12-14.\n",
      "['2017-12-19'] The date when the person visited 주민약국 is 2017-12-19.\n",
      "['2017-12-17'] The date when the person visited \"롯데마트 서울역점 /식품\" is 2017-12-17.\n",
      "['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'] The date when the person visited NIKE 강남점 is 2017-12-29.\n",
      "['2017-12-30', '2017-12-30'] The date when the person visited \"서울9호선 봉은사역 개화 방면 1-1\" is 2017-12-30.\n",
      "['2018-01-05'] The date when the person visited 세븐일레븐 방이한양점 is 2018-01-05.\n",
      "['2017-12-14', '2017-12-14', '2017-12-14'] The date when the person visited 서울야시장 is 2017-12-14.\n",
      "['2017-12-29'] The date when the person visited 밀숲 반포점 is 2017-12-29.\n",
      "['2017-12-13'] The date when the person visited \"서울6호선 공덕역 응암순환행 4-4\" is 2017-12-18.\n",
      "['2017-12-27', '2018-01-05'] The date when the person visited \"서울3호선 고속터미널역 오금방면 7-1\" is 2017-12-27.\n",
      "['2018-01-03'] The date when the person visited 엔터식스 강남점/INDI BRAND 엔터식스반포점 is 2018-01-03.\n",
      "['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'] The date when the person visited 퍼스트약국 is 2017-12-15.\n",
      "['2018-01-05'] The date when the person visited 파르나스몰/18번완당명가 is 2018-01-05.\n",
      "['2018-01-03'] The date when the person visited \"서울2호선 한양대역 내선 7-1\" is 2018-01-03.\n",
      "['2017-12-22'] The date when the person visited 덕수궁피자 is 2017-12-22.\n",
      "['2017-12-31'] The date when the person visited 스타필드 코엑스몰점/커피빈 도심공항타워점 is 2017-12-31.\n",
      "['2017-12-23'] The date when the person visited 코스트코 양평점 /의류 is 2017-12-23.\n"
     ]
    }
   ],
   "source": [
    "# ds_ask_date_dfloader_score = []\n",
    "oi_ask_date_dfloader_wont_score = []\n",
    "# ds_ask_date_json_score = []\n",
    "oi_ask_date_json_wont_score = []\n",
    "oi_ask_date_tabsep_score = []\n",
    "oi_ask_date_commasep_score = []\n",
    "oi_ask_date_totext_score = []\n",
    "oi_ask_date_totextvisited_score = []\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(possible_dates_ans, ds_ask_date_dfloader):\n",
    "#     ds_ask_date_dfloader_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(possible_dates_ans, oi_ask_date_dfloader_wont):\n",
    "    oi_ask_date_dfloader_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(possible_dates_ans, ds_ask_date_json):\n",
    "#     ds_ask_date_json_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(possible_dates_ans, oi_ask_date_json_wont):\n",
    "    oi_ask_date_json_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(possible_dates_ans, oi_ask_date_tabsep):\n",
    "    oi_ask_date_tabsep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(possible_dates_ans, oi_ask_date_commasep):\n",
    "    oi_ask_date_commasep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(possible_dates_ans, oi_ask_date_totext):\n",
    "    oi_ask_date_totext_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(possible_dates_ans, oi_ask_date_totextvisited):\n",
    "    oi_ask_date_totextvisited_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d09bef6-2bc5-47bc-8dea-3a3113d265d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.026785714285714284\n"
     ]
    }
   ],
   "source": [
    "# print(sum(ds_ask_date_dfloader_score)/user_number)\n",
    "print(sum(oi_ask_date_dfloader_wont_score)/user_number)\n",
    "# print(sum(ds_ask_date_json_score)/user_number)\n",
    "print(sum(oi_ask_date_json_wont_score)/user_number)\n",
    "print(sum(oi_ask_date_tabsep_score)/user_number)\n",
    "print(sum(oi_ask_date_commasep_score)/user_number)\n",
    "print(sum(oi_ask_date_totext_score)/user_number)\n",
    "print(sum(oi_ask_date_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "764620ad-925a-4f1f-be9c-2aa0892089f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 -------\n",
      "------ 1 -------\n",
      "------ 2 -------\n",
      "------ 3 -------\n",
      "------ 4 -------\n",
      "------ 5 -------\n",
      "------ 6 -------\n",
      "------ 7 -------\n",
      "------ 8 -------\n",
      "------ 9 -------\n",
      "------ 10 -------\n",
      "------ 11 -------\n",
      "------ 12 -------\n",
      "------ 13 -------\n",
      "------ 14 -------\n",
      "------ 15 -------\n",
      "------ 16 -------\n",
      "------ 17 -------\n",
      "------ 18 -------\n",
      "------ 19 -------\n",
      "------ 20 -------\n",
      "------ 21 -------\n",
      "------ 22 -------\n",
      "------ 23 -------\n",
      "------ 24 -------\n",
      "------ 25 -------\n",
      "------ 26 -------\n",
      "------ 27 -------\n",
      "------ 28 -------\n",
      "------ 29 -------\n",
      "------ 30 -------\n",
      "------ 31 -------\n",
      "------ 32 -------\n",
      "------ 33 -------\n",
      "------ 34 -------\n",
      "------ 35 -------\n",
      "------ 36 -------\n",
      "------ 37 -------\n",
      "------ 38 -------\n",
      "------ 39 -------\n",
      "------ 40 -------\n",
      "------ 41 -------\n",
      "------ 42 -------\n",
      "------ 43 -------\n",
      "------ 44 -------\n",
      "------ 45 -------\n",
      "------ 46 -------\n",
      "------ 47 -------\n",
      "------ 48 -------\n",
      "------ 49 -------\n",
      "------ 50 -------\n",
      "------ 51 -------\n",
      "------ 52 -------\n",
      "------ 53 -------\n",
      "------ 54 -------\n",
      "------ 55 -------\n",
      "------ 56 -------\n",
      "------ 57 -------\n",
      "------ 58 -------\n",
      "------ 59 -------\n",
      "------ 60 -------\n",
      "------ 61 -------\n",
      "------ 62 -------\n",
      "------ 63 -------\n",
      "------ 64 -------\n",
      "------ 65 -------\n",
      "------ 66 -------\n",
      "------ 67 -------\n",
      "------ 68 -------\n",
      "------ 69 -------\n",
      "------ 70 -------\n",
      "------ 71 -------\n",
      "------ 72 -------\n",
      "------ 73 -------\n",
      "------ 74 -------\n",
      "------ 75 -------\n",
      "------ 76 -------\n",
      "------ 77 -------\n",
      "------ 78 -------\n",
      "------ 79 -------\n",
      "------ 80 -------\n",
      "------ 81 -------\n",
      "------ 82 -------\n",
      "------ 83 -------\n",
      "------ 84 -------\n",
      "------ 85 -------\n",
      "------ 86 -------\n",
      "------ 87 -------\n",
      "------ 88 -------\n",
      "------ 89 -------\n",
      "------ 90 -------\n",
      "------ 91 -------\n",
      "------ 92 -------\n",
      "------ 93 -------\n",
      "------ 94 -------\n",
      "------ 95 -------\n",
      "------ 96 -------\n",
      "------ 97 -------\n",
      "------ 98 -------\n",
      "------ 99 -------\n",
      "------ 100 -------\n",
      "------ 101 -------\n",
      "------ 102 -------\n",
      "------ 103 -------\n",
      "------ 104 -------\n",
      "------ 105 -------\n",
      "------ 106 -------\n",
      "------ 107 -------\n",
      "------ 108 -------\n",
      "------ 109 -------\n",
      "------ 110 -------\n",
      "------ 111 -------\n"
     ]
    }
   ],
   "source": [
    "# oi_ask_place_dfloader = []\n",
    "oi_ask_place_dfloader_wont = []\n",
    "# ds_ask_place_json = []\n",
    "oi_ask_place_json_wont = []\n",
    "oi_ask_place_tabsep = []\n",
    "oi_ask_place_commasep = []\n",
    "oi_ask_place_totext = []\n",
    "oi_ask_place_totextvisited = []\n",
    "\n",
    "system_prompt = 'You only answer in the following format: place_name. Don\\'t answer in a sentence.'\n",
    "\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('------', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_lookup/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # dates_to_reply = str(dates_ans[i])\n",
    "\n",
    "    user_prompt = 'The user\\'s visit history below is delimited by three backticks. Your goal is to answer the question \\'Where did the person visit on ' + str(the_dates[i]) + '?\\' If you have several places, answer only one place. Look into the features of the user\\'s visit history and put emphasis on key features of the data that could be useful in answering the question.'\n",
    "\n",
    "\n",
    "    \n",
    "       \n",
    "    system_prompt_dfloader = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "    1. The visit history is in the format of pandas dataframe loader.\n",
    "    2. Each column name(index, date, hour, place_name, place_category, and place_address) is indicated before each colon and values are represented in a list format after each colon.\n",
    "    3. The order of values in each list is kept the same, meaning that nth value in one list and nth value in another list are both included in the person’s one specific visit log information.\n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_json = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "    1. The visit history is in the format of JSON.\n",
    "    2. The number before each colon before each dictionary format indicates the index number of the visit log and the dictionary format data after each colon includes each column name( index, date, hour, place_name, place_category, and place_address) and the value corresponding to the column. \n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_tabsep = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "    1. Each line contains one log of the visit history.\n",
    "    2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "    3. Each item that corresponds to each feature is separated by a tab.\n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_commasep = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "    1. Each line contains one log of the visit history.\n",
    "    2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "    3. Each item that corresponds to each feature is separated by a comma.\n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_totext = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "    1. The visit history is in the text(sentence) format.\n",
    "    2. In the sentence, each visit log is included in order of time. \n",
    "    3. Each visit log includes date, hour, place_name, place_category, and place_address. \n",
    "    ''' + system_prompt\n",
    "    \n",
    "    system_prompt_totextvisited = '''\n",
    "    You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "    1. The visit history is in the text(sentence) format.\n",
    "    2. In the sentence, for each place, its place_name, place_category, and place_address are followed by all visited dates and hours to the place. \n",
    "    ''' + system_prompt\n",
    "    \n",
    "    # print('format 1')\n",
    "    # output, tok = gpt_api(system_prompt_dfloader, user_prompt, dfloader(user_log))\n",
    "    # oi_ask_place_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    output, tok = oi_api(system_prompt_dfloader, user_prompt, dfloader_wont(user_log))\n",
    "    oi_ask_place_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # output, tok = gpt_api(system_prompt_json, user_prompt, json(user_log))\n",
    "    # oi_ask_place_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    output, tok = oi_api(system_prompt_json, user_prompt, json_wont(user_log))\n",
    "    oi_ask_place_json_wont.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_tabsep, user_prompt, tabsep(user_log))\n",
    "    oi_ask_place_tabsep.append(output)\n",
    "    \n",
    "    output, tok = oi_api(system_prompt_commasep, user_prompt, commasep(user_log))\n",
    "    oi_ask_place_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = oi_api(system_prompt_totext, user_prompt, totext(user_log))\n",
    "    oi_ask_place_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = oi_api(system_prompt_totextvisited, user_prompt, totextvisited(user_log))\n",
    "    oi_ask_place_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4c3a2ba-6fd5-495a-a745-b49ef2230c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 4-3', '서울5호선 왕십리역 방화행 6-4', '서울7호선 장승배기역 부평구청 방면 2-2', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 351420', '서울7호선 고속터미널역 장암 방면 4-4'] 스타필드 코엑스몰점/KIEHL'S 코엑스몰부티크점\n",
      "['미소식품가정식백반', 'TKS CAFE'] 서울4호선 충무로역 오이도방면 7-1\n",
      "['마돈나노래연습장', 'GS25 문래시티점'] 스타벅스 하이테크시티점\n",
      "['미니스톱 신천역점', '미니스톱 신천역점', '허수아비돈까스쌀국수 대학동점'] 투썸플레이스 서울대역중앙점\n",
      "['스타벅스 잠실점', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너'] 한사랑의원 내과.소아과.이비인후과.피부과\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['영풍문고 강남역점', '영풍문고 강남역점', '더블트러블 #강남역 #샌드위치', 'YES24 중고서점강남점', '고씨네 강남역점 /일본카레전문', 'UNIQLO 사당파스텔점', '신분당선 강남역 광교방면 3-4', '서울3호선 양재역 오금방면 5-1', '서울3호선 양재역 오금방면 7-1'] UNIQLO 강남점\n",
      "['강남성결교회 /사무실', 'GS25 논현진실점', '강남성결교회 /사무실', 'GS25 논현진실점', '서울8호선 잠실역 암사방면 2-2'] 스타필드 코엑스몰점\n",
      "['미자식당', '미자식당', '일신부동산', '크린업24 송파점', '뚜레쥬르 배명사거리점', '이디야 송파하비오점', 'Watsons 파크하비오점'] 스타벅스 송파아이파크점\n",
      "['강가 역삼점'] 스타벅스 반포역점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울4호선 총신대입구(이수)역 오이도행 7-1\n",
      "['분당선 351939'] 스타칼리휘트니스\n",
      "['현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점'] 3POP PC #116055#서울#강남구#대치동\n",
      "['미소야 서초점'] 스타필드 코엑스몰점\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 투썸플레이스 선정릉역점\n",
      "['서울2호선 신당역 내선 5-1', '올리브영 강변역점'] 서울5호선 5048\n",
      "['서울4호선 신용산역 당고개방면 9-1', '서울4호선 숙대입구역 당고개방면 9-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4'] 현대백화점 무역센터점 /영캐주얼\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점/딥티크 코엑스몰점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 분당선 강남구청역 왕십리방면 6-4\n",
      "['이디야 서울고교점'] 서울2호선 삼성역 내선 5-1 / 외선 6-4\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /원더브라/쥬스스타', '스타필드 코엑스몰점/맥도날드 코엑스점', \"스타필드 코엑스몰점/IT'S SKIN 코엑스점\", '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이'] 이디야 대치역점\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타필드 코엑스몰점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['GS25 방화샤르망점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/THE BODY SHOP 롯데백화점김포공항점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '서울5호선 김포공항역 방화행 2-2', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /토이저러스 외'] 맥도날드 염창DT점\n",
      "['동명공인중개사', 'CU 역삼포스틸점', '파리바게뜨 역삼특허청점', '서울2호선 강남역 내선 5-1', 'KEEP YOUR FORK /푸드코트', '스타벅스 포도몰점', '포도몰 /남성의류', '이불나라'] IFC몰/더플레이스 여의도IFC점\n",
      "['서울5호선 아차산역 방화행 6-4', '서울7호선 먹골역 장암 방면 6-4', '롯데리아 먹골역점', '서울6호선 태릉입구역 응암순환행 4-4', '서울1호선 대방역 인천 신창행 5-1 / 용산급행 6-4', '서울6호선 동묘앞역 봉화산행 8-3 / 응암순환행 1-2', '서울4호선 삼각지역 오이도방면 9-1', '서울6호선 한강진역 응암순환행 4-4', '분당선 강남구청역 수원방면 5-3'] 서울8호선 가락시장역 모란방면 2-2\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울6호선 월드컵경기장역 봉화산행 2-2\n",
      "['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점'] 스타필드 코엑스몰점\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/에잇세컨즈 IFC몰점\n",
      "['세븐일레븐 도곡2호점', '세븐일레븐 도곡스타점'] YES24 강남점\n",
      "['서울8호선 복정역 /암사방면2-2', '롯데월드몰/8seconds 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '롯데월드몰/UNIQLO 롯데월드몰점', '스타필드 코엑스몰점 /자라/아르마니진', '스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트'] 서울2호선 잠실역 외선 3-1\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 스타필드 코엑스몰점\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 롯데마트 잠실점 /비식품코너\n",
      "['베테랑 센트럴지점', '이마트 자양점 /식품/비식품/푸드코트', '이마트 자양점/몰리스펫샵 이마트자양점'] 서울7호선 고속터미널역 장암 방면 6-4\n",
      "['GS25 S강남역1호점', 'REFESH COFFEE&JUICE'] Cafe Queen's Amore\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 서울 중구 을지로2가 199-74\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 스타필드 코엑스몰점\n",
      "['쟝블랑제리', '버거킹 낙성대역점'] 스타필드 코엑스몰점\n",
      "['롯데리아 월드점', '투썸플레이스 잠실롯데점', '공항철도 2220', '롯데리아 월드점', '자연별곡 잠실웰빙점'] 스타필드 코엑스몰점\n",
      "['롯데백화점 강남점 본관 /여성패션', '롯데백화점 강남점 신관 /슈즈에비뉴', '스타필드 코엑스몰점/ALDO 스타필드코엑스몰점', '스타필드 코엑스몰점/잠바주스 코엑스몰점'] 스타필드 코엑스몰점\n",
      "['MINI GOLD 돈암점'] 스타벅스 성신여대정문점\n",
      "['서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 서울역발 문산행 2-2'] 서울 강남구 삼성동 152-27\n",
      "['바르미샤브샤브 삼성역점', 'Park et Table', 'GS25 대치그린점'] 스타필드 코엑스몰점/스위트스페이스 코엑스몰점\n",
      "['IFC몰/유니클로 IFC몰점', 'IFC몰/스타벅스 여의도IFC몰(B3)점', 'IFC몰/MANGO 여의도IFC몰점', 'IFC몰/Aesop IFC서울점', '서울9호선 여의도역 개화 방면 1-1', '서울2호선 당산역 내선 3-1', '메이퓨어의원 /피부과', '서울2호선 2795', '서울7호선 대림역 장암 방면 4-4'] 스타필드 코엑스몰점 /잠바주스/안내데스크/지오다노\n",
      "['스타벅스 송파구청점', '참숯구이 황토골', '챈서리', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', 'CGV 중계점', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', '투썸플레이스 중계CGV스윗바점'] 현대시티아울렛 동대문점\n",
      "['서울8호선 암사역 모란방면 2-2', '서울2호선 종합운동장역 내선 9-1', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 안국점', '서울3호선 안국역 대화행 7-1 / 오금행 4-4', 'YES 당구장 /당구장', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 마로니에공원점', 'GS25 암사역점', '서울8호선 천호역 암사방면 2-2'] 스타벅스 수유역점\n",
      "['서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1'] 서울 중구 을지로7가 133\n",
      "['서울4호선 이촌역 오이도방면 3-1', '서울2호선 사당역 외선 7-1', 'Art Billiard Club', '깐부치킨 서초삼성타운점'] 스타필드 코엑스몰점/메가박스 코엑스몰점/매표소\n",
      "['서울9호선 노들역 종합운동장 방면 1-1', '엔제리너스 사당역점'] 서울9호선 여의도역 개화 방면 1-1\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['스타벅스 대한극장점', '스타벅스 대한극장점'] KOPITIAM\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] Cafe7gram 삼성역점\n",
      "['서울1호선 창동역 인천 신창행 9-1', '뉴욕화이트치과의원 치과', 'ARISTA COFFEE 선릉2호점', '장수가 선릉점'] 롯데백화점 잠실점 식품/푸드에비뉴\n",
      "['서울5호선 군자역 방화행 2-4 / 상일동 마천행 6-4', '투썸플레이스 여의도점', '서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3', '서울5호선 길동역 상일동행 6-4', '서울5호선 5549'] 서울9호선 고속터미널역 종합운동장 방면 2-4\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] NC백화점 송파점/코코몽키즈랜드 NC백화점송파점\n",
      "['파리바게뜨 서울적십자병원점', 'CU 강북삼성병원 2호점', 'SHILLA MYUNGGUA 신관/강북삼성병원점'] 서울4호선 회현역 당고개방면 3-1/오이도방면 8-4\n",
      "['분당선 351342', '분당선 강남구청역 수원방면 3-4'] 분당선 351441\n",
      "['햇빛병원 /내과'] 스타벅스 미아점\n",
      "['스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/메가박스 코엑스몰점', '서울9호선 봉은사역 개화 방면 2-4', '스타벅스 강남에비뉴점', '스타벅스 강남2점'] 스타필드 코엑스몰점\n",
      "['스타벅스 청담영동대로점'] 스타벅스 GS타워점\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점/BUTTER 코엑스점\n",
      "['제일제면소 서울역사점', '롯데마트 서울역점 /식품', '롯데마트 서울역점 /비식품'] 신촌세브란스병원 영상의학과\n",
      "['서울3호선 남부터미널역 대화방면 9-1', '행복한수약국', '수약국', 'NIKE 강남점', 'NIKE 강남점', 'NIKE 강남점', 'NIKE 강남점'] 서울2호선 방배역 내선 3-1\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 코스트코 양평점 /야채코너\n",
      "['서울8호선 잠실역 암사방면 4-4', 'KB국민은행 방이동지점', 'KB국민은행 방이동지점', 'GS25 잠실2점', '세븐일레븐 방이한양점', 'GS25 방배효령점', '미니스톱 방배본점'] 롯데월드몰/Weeny Beeny 롯데월드몰점\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점 /식품\n",
      "['서울6호선 공덕역 응암순환행 4-4'] 서울3호선 종로3가역 대화행 10-4 / 오금행 1-1\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 스타벅스 센트럴시티점\n",
      "['퍼스트약국', '퍼스트약국', '하나로마트 대치점', '롯데백화점 강남점 본관 /식품/식당가'] 롯데백화점 강남점 /디자이너/모피/란제리\n",
      "['파르나스몰/GS25 파르나스타워점', '서울6호선 보문역 봉화산행 4-3 / 응암순환행 5-1', '서울4호선 창동역 오이도방면 9-1', '우이신설선 성신여대입구역 신설동방면 1-1', '서울2호선 한양대역 내선 7-1'] 서울2호선 신설동역 지선 성수행 2-1\n",
      "['덕수궁피자', '할리스커피 광화문LG점', '아이파크몰 /디지털소형가전/토이하비/디지털관', '여로집 영등포본관/오징어볶음', '서울1호선 용산역 / 경의중앙선 용산역 동인천 천안급행 2-1 / 문산행 8-4'] 서울5호선 서대문역 방화행 4-4 / 상일동 마천행 4-4\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 투썸플레이스 종로구청점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 진주품은활어 영등포직영점\n",
      "json_wont\n",
      "['마돈나노래연습장', 'GS25 문래시티점'] 투썸플레이스 문래하이테크시티점\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['강가 역삼점'] 스타벅스 반포역점\n",
      "['미소야 서초점'] 불이아 역삼점\n",
      "['교보문고 강남점', '서울2호선 신림역 내선 4-4 / 외선 7-1', '미스터도넛 신논현역점', '교보문고 강남점', '교보문고 강남점', 'CU 925신논현역점', '교보문고 강남점', '교보문고 강남점', 'TONYMOLY 신논현역점', '교보문고 강남점', '교보문고 강남점', '하나투어 강남예약센터투어온점', '하나투어 강남예약센터투어온점', '하나투어 강남예약센터투어온점'] 스타필드 코엑스몰점\n",
      "['서울4호선 신용산역 당고개방면 9-1', '서울4호선 숙대입구역 당고개방면 9-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4'] 서울4호선 사당역 당고개방면 9-1\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['MAD COFFEE', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울4호선 총신대입구(이수)역 오이도행 3-1', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4'] 서울 강남구 대치동에 위치한 MAD COFFEE.\n",
      "['이디야 서울고교점'] 분당선 대모산입구역 수원방면 3-4\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타필드 코엑스몰점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점'] 스타필드 코엑스몰점\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/에잇세컨즈 IFC몰점\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 스타필드 코엑스몰점\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 스타필드 코엑스몰점\n",
      "['GS25 S강남역1호점', 'REFESH COFFEE&JUICE'] Cafe Queen's Amore\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 스타필드 코엑스몰점\n",
      "['MINI GOLD 돈암점'] 스타벅스 성신여대점\n",
      "['스타벅스 송파구청점', '참숯구이 황토골', '챈서리', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', 'CGV 중계점', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', '투썸플레이스 중계CGV스윗바점'] 현대시티아울렛 동대문점\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 서울1호선 용산역 소요산행 9-1\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] Cafe7gram 삼성역점\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] NC백화점 송파점/코코몽키즈랜드 NC백화점송파점\n",
      "['햇빛병원 /내과'] 스타벅스 미아점\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['제일제면소 서울역사점', '롯데마트 서울역점 /식품', '롯데마트 서울역점 /비식품'] 롯데슈퍼 홍제2점\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점 /식품\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 스타벅스 센트럴시티점\n",
      "['덕수궁피자', '할리스커피 광화문LG점', '아이파크몰 /디지털소형가전/토이하비/디지털관', '여로집 영등포본관/오징어볶음', '서울1호선 용산역 / 경의중앙선 용산역 동인천 천안급행 2-1 / 문산행 8-4'] 서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타필드 코엑스몰점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "tabsep\n",
      "['마돈나노래연습장', 'GS25 문래시티점'] 투썸플레이스 문래하이테크시티점\n",
      "['미자식당', '미자식당', '일신부동산', '크린업24 송파점', '뚜레쥬르 배명사거리점', '이디야 송파하비오점', 'Watsons 파크하비오점'] 스타벅스 송파아이파크점\n",
      "['강가 역삼점'] 스타벅스 반포역점\n",
      "['현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점'] 현대백화점 무역센터점\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점\n",
      "['이디야 서울고교점'] 분당선 대모산입구역 수원방면 3-4\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /원더브라/쥬스스타', '스타필드 코엑스몰점/맥도날드 코엑스점', \"스타필드 코엑스몰점/IT'S SKIN 코엑스점\", '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이'] 스타필드 코엑스몰점\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타필드 코엑스몰점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점'] 스타필드 코엑스몰점\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/에잇세컨즈 IFC몰점\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 스타필드 코엑스몰점\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 스타필드 코엑스몰점\n",
      "['베테랑 센트럴지점', '이마트 자양점 /식품/비식품/푸드코트', '이마트 자양점/몰리스펫샵 이마트자양점'] 이마트 자양점\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 스타필드 코엑스몰점\n",
      "['MINI GOLD 돈암점'] 스타벅스 성신여대점\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] Cafe7gram 삼성역점\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] NC백화점 송파점\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점/STUDIO TOMBOY', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 종합운동장역 외선 7-1'] 스타필드 코엑스몰점\n",
      "['햇빛병원 /내과'] 스타벅스 미아점\n",
      "['신세계백화점 강남점 /여성 컨템포러리', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '서울9호선 신논현역 종합운동장 방면 1-1', '서울9호선 봉은사역 개화 방면 4-4'] 신세계백화점 강남점\n",
      "['스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/메가박스 코엑스몰점', '서울9호선 봉은사역 개화 방면 2-4', '스타벅스 강남에비뉴점', '스타벅스 강남2점'] 스타필드 코엑스몰점\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['제일제면소 서울역사점', '롯데마트 서울역점 /식품', '롯데마트 서울역점 /비식품'] 롯데슈퍼 홍제2점\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] 스타필드 코엑스몰점\n",
      "['스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/cafe imt 코엑스몰점', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/예가낙지마을', '오징어세상 삼성점', '스타필드 코엑스몰점 /반하는보쌈/ABC-mart/래핑차일드', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /OYSHO/BUTTER', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /럭키슈에뜨/아메리칸이글/별마당도서관', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '오징어세상 삼성점', '서울야시장', '오징어세상 삼성점', '서울야시장', '서울야시장'] 스타필드 코엑스몰점\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 신세계백화점 강남점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2', '소래포구 성수점', '서울2호선 종합운동장역 외선 9-1', '소래포구 성수점', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/카카오프렌즈 스타필드코엑스몰점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/18번완당명가', '서울2호선 신림역 내선 2-3 / 외선 9-2'] 스타필드 코엑스몰점\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타벅스 종로구청점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "commasep\n",
      "['마돈나노래연습장', 'GS25 문래시티점'] 스타벅스 하이테크시티점\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['강가 역삼점'] 스타벅스 반포역점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울4호선 사당역 당고개방면 5-1/오이도방면 6-4\n",
      "['현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점'] 현대백화점 무역센터점\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 투썸플레이스 선정릉역점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 분당선 강남구청역\n",
      "['이디야 서울고교점'] 분당선 대모산입구역 수원방면 3-4\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /원더브라/쥬스스타', '스타필드 코엑스몰점/맥도날드 코엑스점', \"스타필드 코엑스몰점/IT'S SKIN 코엑스점\", '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이'] 스타필드 코엑스몰점\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타필드 코엑스몰점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점'] 스타필드 코엑스몰점\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/에잇세컨즈 IFC몰점\n",
      "['서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장 서대문역점'] 스타필드 코엑스몰점\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 스타필드 코엑스몰점\n",
      "['베테랑 센트럴지점', '이마트 자양점 /식품/비식품/푸드코트', '이마트 자양점/몰리스펫샵 이마트자양점'] 이마트 자양점\n",
      "['GS25 S강남역1호점', 'REFESH COFFEE&JUICE'] Cafe Queen's Amore\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 스타필드 코엑스몰점\n",
      "['MINI GOLD 돈암점'] 스타벅스 성신여대점\n",
      "['서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1'] 서울4호선 동대문역사문화공원역\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] Cafe7gram 삼성역점\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] NC백화점 송파점/코코몽키즈랜드 NC백화점송파점\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점/STUDIO TOMBOY', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 종합운동장역 외선 7-1'] 스타필드 코엑스몰점\n",
      "['햇빛병원 /내과'] 스타벅스 미아점\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['제일제면소 서울역사점', '롯데마트 서울역점 /식품', '롯데마트 서울역점 /비식품'] 롯데슈퍼 홍제2점\n",
      "['스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/cafe imt 코엑스몰점', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/예가낙지마을', '오징어세상 삼성점', '스타필드 코엑스몰점 /반하는보쌈/ABC-mart/래핑차일드', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /OYSHO/BUTTER', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /럭키슈에뜨/아메리칸이글/별마당도서관', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '오징어세상 삼성점', '서울야시장', '오징어세상 삼성점', '서울야시장', '서울야시장'] 스타필드 코엑스몰점\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점 /식품\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 스타벅스 센트럴시티점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2', '소래포구 성수점', '서울2호선 종합운동장역 외선 9-1', '소래포구 성수점', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/카카오프렌즈 스타필드코엑스몰점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/18번완당명가', '서울2호선 신림역 내선 2-3 / 외선 9-2'] 스타필드 코엑스몰점\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타벅스 종로구청점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "totext\n",
      "['곰작골나주곰탕', '강남삼계탕', '죽대통령 #역삼점', 'SMASHING BOWL /볼링펍', '이찌마이', '엔츠노래타운', '이찌마이'] The person visited 곰작골나주곰탕, 강남삼계탕, 죽대통령 #역삼점, SMASHING BOWL /볼링펍, 이찌마이, 엔츠노래타운, 분당선 351219, 분당선 수서역 수원방면 2-2, 분당선 구룡역 수원방면 2-2, 분당선 선릉역 수원방면 2-2, 분당선 351241, 분당선 개포동역 수원방면 3-4, 서울2호선 2427, 분당선 도곡역 /수원방면2-2, 분당선 선릉역 수원방면 2-2, 분당선 351221, 분당선 351220, 서울2호선 대림역 내선 9-1, 서울2호선 선릉역 내선 9-1, 서울2호선 영등포구청역 외선 5-1, 분당선 351333, 서울2호선 강남역 내선 5-1, 서울2호선 선릉역 내선 7-1, 분당선 구룡역 왕십리방면 2-2, 분당선 351333, 서울2호선 선릉역 내선 9-1, 서울2호선 선릉역 외선 3-1, 분당선 351241, 서울2호선 선릉역 내선 9-1, 분당선 선릉역 왕십리방면 5-3, 죠스떡볶이 영등포구청점, 투썸플레이스 영등포구청역점, 동성양꼬치, 타임스퀘어/플라잉볼 타임스퀘어점, 고향회집, 뽀끼뽀끼오락실 영등포1호점, 스타벅스 영등포본동점, 노랑통닭 영등포역점, and GS25 영등포로점.\n",
      "['스타벅스 잠실점', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너'] The person visited 스타벅스 잠실점 on 2017-12-25.\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['미자식당', '미자식당', '일신부동산', '크린업24 송파점', '뚜레쥬르 배명사거리점', '이디야 송파하비오점', 'Watsons 파크하비오점'] The person visited the following places on 2017-12-31: \n",
      "1. 미자식당 (Korean food restaurant)\n",
      "2. 일신부동산 (Real estate agency)\n",
      "3. 크린업24 송파점 (Laundry)\n",
      "4. 뚜레쥬르 배명사거리점 (Bakery)\n",
      "5. 이디야 송파하비오점 (Coffee shop)\n",
      "6. Watsons 파크하비오점 (Drug store)\n",
      "7. 메가박스 송파파크하비오점 (Movie theater)\n",
      "['GS25 상도터널점', '피자보이시나 중앙대본점', '열정식당', '피자보이시나 중앙대본점', '열정식당', '현대사진관', 'OUTBACK 신촌점', 'OUTBACK 신촌점', '벌툰', '벌툰', '벌툰'] The person visited the following place on 2017-12-06: GS25 상도터널점.\n",
      "['강가 역삼점'] 맥도날드 양재점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울4호선 사당역 당고개방면 5-1/오이도방면 6-4\n",
      "['분당선 351939'] 스타필드 코엑스몰점/TWORLD 코엑스점\n",
      "['현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점'] 스타벅스 대치은마사거리점\n",
      "['미소야 서초점'] The person visited the following place on 2017-12-22: \n",
      "- 미소야 서초점 (Japanese food restaurant)\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 투썸플레이스 선정릉역점\n",
      "['서울2호선 신당역 내선 5-1', '올리브영 강변역점'] 뮤직파워노래방\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['서울5호선 5756', '서울5호선 5152'] 배스킨라빈스 사당역1호점\n",
      "['이디야 서울고교점'] 서울3호선 충무로역 오금방면 5-1\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타벅스 숭실대입구역점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점\n",
      "['동명공인중개사', 'CU 역삼포스틸점', '파리바게뜨 역삼특허청점', '서울2호선 강남역 내선 5-1', 'KEEP YOUR FORK /푸드코트', '스타벅스 포도몰점', '포도몰 /남성의류', '이불나라'] IFC몰/더플레이스 여의도IFC점\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/더플레이스 IFC점\n",
      "['GS25 S강남역1호점', 'REFESH COFFEE&JUICE'] Cafe Queen's Amore\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 스타벅스 수서점\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 스타필드 코엑스몰점\n",
      "['쟝블랑제리', '버거킹 낙성대역점'] 파리바게뜨 역삼스타점\n",
      "['롯데백화점 강남점 본관 /여성패션', '롯데백화점 강남점 신관 /슈즈에비뉴', '스타필드 코엑스몰점/ALDO 스타필드코엑스몰점', '스타필드 코엑스몰점/잠바주스 코엑스몰점'] 롯데백화점 강남점 본관\n",
      "['서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 서울역발 문산행 2-2'] 스타벅스 삼성현대힐점\n",
      "['바르미샤브샤브 삼성역점', 'Park et Table', 'GS25 대치그린점'] The person visited the following place on 2017-12-18: \n",
      "- Park et Table\n",
      "['스타벅스 송파구청점', '참숯구이 황토골', '챈서리', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', 'CGV 중계점', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', '투썸플레이스 중계CGV스윗바점'] 현대시티아울렛 동대문점\n",
      "['서울4호선 이촌역 오이도방면 3-1', '서울2호선 사당역 외선 7-1', 'Art Billiard Club', '깐부치킨 서초삼성타운점'] GS25 LG유플러스 용산사옥점\n",
      "['서울9호선 노들역 종합운동장 방면 1-1', '엔제리너스 사당역점'] The person visited 서울9호선 노들역 종합운동장 방면 1-1 on 2017-12-28.\n",
      "['Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4-4', '서울2호선 잠실역 외선 3-1', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '서울1호선 신설동역 소요산행 9-1'] 스타필드 코엑스몰점\n",
      "['스타벅스 대한극장점', '스타벅스 대한극장점'] KOPITIAM\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] Cafe7gram 삼성역점\n",
      "['서울1호선 창동역 인천 신창행 9-1', '뉴욕화이트치과의원 치과', 'ARISTA COFFEE 선릉2호점', '장수가 선릉점'] 선릉점\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] 던킨도너츠 시청역점\n",
      "['스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점/STUDIO TOMBOY', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 종합운동장역 외선 7-1'] 스타필드 코엑스몰점\n",
      "['KEB하나은행 서압구정지점', '스타필드 코엑스몰점/TWORLD', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '마리아홀리기프트 /책cd'] 천주교잠원동성당\n",
      "['분당선 351342', '분당선 강남구청역 수원방면 3-4'] 분당선 강남구청역 수원방면\n",
      "['햇빛병원 /내과'] 스타벅스 미아점\n",
      "['신세계백화점 강남점 /여성 컨템포러리', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '서울9호선 신논현역 종합운동장 방면 1-1', '서울9호선 봉은사역 개화 방면 4-4'] 신세계백화점 강남점\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] The person visited THE FACE SHOP 가양역직영점 on 2017-12-30.\n",
      "['서울8호선 잠실역 암사방면 4-4', 'KB국민은행 방이동지점', 'KB국민은행 방이동지점', 'GS25 잠실2점', '세븐일레븐 방이한양점', 'GS25 방배효령점', '미니스톱 방배본점'] 롯데월드몰/BLACK\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점 /식품\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타벅스 종로구청점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n",
      "totextvisited\n",
      "['곰작골나주곰탕', '강남삼계탕', '죽대통령 #역삼점', 'SMASHING BOWL /볼링펍', '이찌마이', '엔츠노래타운', '이찌마이'] The person visited 곰작골나주곰탕 on 2017-12-30.\n",
      "['미소식품가정식백반', 'TKS CAFE'] 서울4호선 충무로역 오이도방면 7-1\n",
      "['마돈나노래연습장', 'GS25 문래시티점'] 스타벅스 하이테크시티점\n",
      "['미니스톱 신천역점', '미니스톱 신천역점', '허수아비돈까스쌀국수 대학동점'] The person visited the following places on 2017-12-29:\n",
      "1. 미니스톱 신천역점 (convenience store) located at 서울 송파구 잠실동 33, at 9 and 13.\n",
      "['스타벅스 잠실점', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너'] 홈플러스 잠실점/아티제 잠실홈플러스점\n",
      "['서울2호선 잠실나루역 내선 7-1', '서울2호선 잠실역 외선 3-1', '서울8호선 문정역 암사방면 4-4', 'GS25 소공점', '롯데백화점 본점/Paul Bassett 롯데본점', '서울2호선 잠실역 내선 3-1', '서울8호선 잠실역 모란방면 2-2'] 롯데백화점 본점 /리빙\n",
      "['커피빈 대치한티점', '분당선 복정역 수원방면 6-4', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '올바른영어 학원', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '이디야 한티역점'] 소호앤노호 대치점\n",
      "['서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2'] CU 대치예스점\n",
      "['영풍문고 강남역점', '영풍문고 강남역점', '더블트러블 #강남역 #샌드위치', 'YES24 중고서점강남점', '고씨네 강남역점 /일본카레전문', 'UNIQLO 사당파스텔점', '신분당선 강남역 광교방면 3-4', '서울3호선 양재역 오금방면 5-1', '서울3호선 양재역 오금방면 7-1'] The person visited UNIQLO 사당파스텔점 on 2017-12-29.\n",
      "['강남성결교회 /사무실', 'GS25 논현진실점', '강남성결교회 /사무실', 'GS25 논현진실점', '서울8호선 잠실역 암사방면 2-2'] 스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바\n",
      "['미자식당', '미자식당', '일신부동산', '크린업24 송파점', '뚜레쥬르 배명사거리점', '이디야 송파하비오점', 'Watsons 파크하비오점'] 스타벅스 송파아이파크점\n",
      "['GS25 상도터널점', '피자보이시나 중앙대본점', '열정식당', '피자보이시나 중앙대본점', '열정식당', '현대사진관', 'OUTBACK 신촌점', 'OUTBACK 신촌점', '벌툰', '벌툰', '벌툰'] The person visited the following places on 2017-12-06:\n",
      "1. GS25 상도터널점 (convenience store)\n",
      "2. 피자보이시나 중앙대본점 (pizza)\n",
      "3. 열정식당 (korean food restaurant)\n",
      "4. 현대사진관 (photo studio)\n",
      "5. OUTBACK 신촌점 (western food restaurant)\n",
      "6. 벌툰 (theme cafe)\n",
      "['강가 역삼점'] 스타벅스 반포역점\n",
      "['스타벅스 이수역점', '투썸플레이스 이수메가박스점', '메가박스 이수점'] 서울4호선 사당역 당고개방면 5-1/오이도방면 6-4\n",
      "['분당선 351939'] 스타필드 코엑스몰점/TWORLD 코엑스점\n",
      "['현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점'] 스타벅스 대치은마사거리점\n",
      "['미소야 서초점'] 서울 서초구 서초동 1458-6\n",
      "['하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2'] 서울2호선 강남역 내선 5-1\n",
      "['서울4호선 신용산역 당고개방면 9-1', '서울4호선 숙대입구역 당고개방면 9-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4'] 서울역\n",
      "['시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'] 스타필드 코엑스몰점/딥티크 코엑스몰점\n",
      "['연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과'] 스타필드 코엑스몰점/JUST JINNY\n",
      "['서울5호선 5756', '서울5호선 5152'] 배스킨라빈스 사당역1호점\n",
      "['MAD COFFEE', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울4호선 총신대입구(이수)역 오이도행 3-1', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4'] GS25 대치삼성점\n",
      "['분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2'] 분당선 강남구청역 왕십리방면\n",
      "['이디야 서울고교점'] 서울3호선 충무로역 오금방면 5-1\n",
      "['버거킹 시청역점', '고릴라김밥', '버거킹 시청역점'] 스타벅스 숭실대입구역점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2'] 할리스커피 종로본점\n",
      "['스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점'] 스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진\n",
      "['서울3호선 대치역 대화방면 5-1/오금방면 6-4', '서울2호선 사당역 외선 5-1', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울2호선 사당역 외선 3-1', '서울3호선 남부터미널역 오금방면 7-1', '서울5호선 오금역 방화행 4-4', '스타벅스 방이역점', '이디야 방이역점', '서울5호선 오금역 마천행 4-4', '서울5호선 오금역 방화행 4-4', '서울5호선 방이역 마천행 2-2', '서울5호선 왕십리역 방화행 6-4', '서울5호선 방이역 방화행 6-4', '서울5호선 둔촌동역 방화행 4-4', '서울5호선 올림픽공원역 방화행 2-2', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4'] 스타필드 코엑스몰점\n",
      "['동명공인중개사', 'CU 역삼포스틸점', '파리바게뜨 역삼특허청점', '서울2호선 강남역 내선 5-1', 'KEEP YOUR FORK /푸드코트', '스타벅스 포도몰점', '포도몰 /남성의류', '이불나라'] IFC몰/부츠\n",
      "['cafe DE LOOWA', '커피식스쥬스식스 구로대륭2차점', '서울2호선 대림역 내선 9-1'] 서울2호선 합정역 외선 9-1\n",
      "['신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2'] IFC몰/더플레이스 IFC점\n",
      "['창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈사람안과'] 스타필드 코엑스몰점 /샤이바나 코엑스몰점\n",
      "['GS25 S강남역1호점', 'REFESH COFFEE&JUICE'] 유가네닭갈비 강남역점\n",
      "['서울3호선 3926', '서울3호선 약수역 대화방면 5-1/오금방면 6-4', '서울3호선 3926', '서울3호선 3026', '서울3호선 3926', '서울3호선 교대역 대화방면 10-4', '서울3호선 3026'] 스타벅스 수서점\n",
      "['가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리'] 스타필드 코엑스몰점\n",
      "['예스자이엘라부동산'] 다이소 대방남부점\n",
      "['쟝블랑제리', '버거킹 낙성대역점'] 파리바게뜨 역삼스타점\n",
      "['롯데백화점 강남점 본관 /여성패션', '롯데백화점 강남점 신관 /슈즈에비뉴', '스타필드 코엑스몰점/ALDO 스타필드코엑스몰점', '스타필드 코엑스몰점/잠바주스 코엑스몰점'] 롯데백화점 강남점 본관\n",
      "['서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 서울역발 문산행 2-2'] The person visited the following places on 2018-01-05:\n",
      "1. 서울9호선 삼성중앙역 개화 방면 2-4 (subway station)\n",
      "2. 스타벅스 삼성현대힐점 (coffee shop)\n",
      "['바르미샤브샤브 삼성역점', 'Park et Table', 'GS25 대치그린점'] The person visited the following places on 2017-12-18:\n",
      "- 바르미샤브샤브 삼성역점 (Japanese food restaurant)\n",
      "- Park et Table (Korean food restaurant)\n",
      "- GS25 대치그린점 (Convenience store)\n",
      "- 면채반 삼성점 (Korean food restaurant)\n",
      "['스타벅스 송파구청점', '참숯구이 황토골', '챈서리', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', 'CGV 중계점', 'CGV 중계점', '투썸플레이스 중계CGV스윗바점', '투썸플레이스 중계CGV스윗바점'] 현대시티아울렛 동대문점\n",
      "['서울8호선 암사역 모란방면 2-2', '서울2호선 종합운동장역 내선 9-1', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 안국점', '서울3호선 안국역 대화행 7-1 / 오금행 4-4', 'YES 당구장 /당구장', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 마로니에공원점', 'GS25 암사역점', '서울8호선 천호역 암사방면 2-2'] 스타벅스 천호로데오점\n",
      "['서울4호선 이촌역 오이도방면 3-1', '서울2호선 사당역 외선 7-1', 'Art Billiard Club', '깐부치킨 서초삼성타운점'] GS25 LG유플러스 용산사옥점\n",
      "['Paul Bassett 종로1 가점', 'Paul Bassett 종로1 가점', 'Paul Bassett 종로1 가점', 'KT m&s종각직영점', 'THE FACE SHOP 9호선노량진역점'] 스타벅스 경기대점\n",
      "['서울9호선 노들역 종합운동장 방면 1-1', '엔제리너스 사당역점'] The person visited the following places on 2017-12-28:\n",
      "1. 서울9호선 노들역 종합운동장 방면 1-1 (subway station located at 서울 동작구 본동 126-6)\n",
      "2. 엔제리너스 사당역점 (coffee shop located at 서울 서초구 방배동 444-16)\n",
      "['스타벅스 대한극장점', '스타벅스 대한극장점'] Coffee DZ 숙명여대점\n",
      "['이디야 수서역점', '죠스떡볶이 수서벤처빌점'] 서울2호선 선릉역 외선 5-1\n",
      "['서울1호선 창동역 인천 신창행 9-1', '뉴욕화이트치과의원 치과', 'ARISTA COFFEE 선릉2호점', '장수가 선릉점'] 롯데백화점 잠실점\n",
      "['서울2호선 2866', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', 'GS25 행운중앙점', '서울2호선 2374', '서울2호선 2670'] 현대백화점 무역센터점\n",
      "['리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4'] 던킨도너츠 시청역점\n",
      "['스타벅스 강남구청역점', '스타벅스 삼성역점', '미니스톱 논현행운점'] 스타벅스 강남구청정문점\n",
      "['파리바게뜨 서울적십자병원점', 'CU 강북삼성병원 2호점', 'SHILLA MYUNGGUA 신관/강북삼성병원점'] 서울적십자병원점\n",
      "['신세계백화점 강남점 /여성 컨템포러리', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '서울9호선 신논현역 종합운동장 방면 1-1', '서울9호선 봉은사역 개화 방면 4-4'] 신세계백화점 강남점\n",
      "['서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4'] 스타필드 코엑스몰점\n",
      "['주민약국'] 스타필드 코엑스몰점\n",
      "['THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점 /사보텐/OYSHO', '서울9호선 봉은사역 개화 방면 1-1', '스타필드 코엑스몰점/고디바 코엑스몰점', '떼루와 까치산역점', '서울9호선 봉은사역 개화 방면 1-1', '서울9호선 노량진역 개화 방면 1-1', '서울9호선 여의도역 개화 방면 2-4', '서울5호선 여의도역 방화행 6-4', '서울5호선 신길역 방화행 4-4', '서울5호선 까치산역 방화행 6-4', '서울5호선 영등포시장역 방화행 6-4', '서울9호선 선정릉역 개화 방면 1-1'] The person visited the following places on 2017-12-30:\n",
      "1. THE FACE SHOP 가양역직영점\n",
      "2. 서울9호선 가양역 종합운동장 방면 2-4\n",
      "3. CU 907가양역점\n",
      "4. 서울9호선 봉은사역 종합운동장 방면 1-1\n",
      "5. 서울9호선 선정릉역 종합운동장 방면 1-1\n",
      "6. 스타필드 코엑스몰점 /롯데리아/사리현\n",
      "7. 스타필드 코엑스몰점 /사보텐/OYSHO\n",
      "8. 서울9호선 봉은사역 개화 방면 1-1\n",
      "9. 스타필드 코엑스몰점/고디바 코엑스몰점\n",
      "10. 떼루와 까치산역점\n",
      "11. 서울9호선 노량진역 개화 방면 1-1\n",
      "12. 서울9호선 여의도역 개화 방면 2-4\n",
      "13. 서울5호선 여의도역 방화행 6-4\n",
      "14. 서울5호선 신길역 방화행 4-4\n",
      "15. 서울5호선 영등포시장역 방화행 6-4\n",
      "16. 서울9호선 선정릉역 개화 방면 1-1\n",
      "['서울8호선 잠실역 암사방면 4-4', 'KB국민은행 방이동지점', 'KB국민은행 방이동지점', 'GS25 잠실2점', '세븐일레븐 방이한양점', 'GS25 방배효령점', '미니스톱 방배본점'] 롯데월드몰/BLACK\n",
      "['미니스톱 반포삼공점', '밀숲 반포점'] 이마트 양재점\n",
      "['분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 3-4', '엔터식스 강남점/INDI BRAND 엔터식스반포점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀'] 스타벅스 센트럴시티점\n",
      "['서울2호선 신림역 내선 2-3 / 외선 9-2', '소래포구 성수점', '서울2호선 종합운동장역 외선 9-1', '소래포구 성수점', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/카카오프렌즈 스타필드코엑스몰점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/18번완당명가', '서울2호선 신림역 내선 2-3 / 외선 9-2'] 스타필드 코엑스몰점\n",
      "['파르나스몰/GS25 파르나스타워점', '서울6호선 보문역 봉화산행 4-3 / 응암순환행 5-1', '서울4호선 창동역 오이도방면 9-1', '우이신설선 성신여대입구역 신설동방면 1-1', '서울2호선 한양대역 내선 7-1'] 스타필드 코엑스몰점/도모다찌\n",
      "['덕수궁피자', '할리스커피 광화문LG점', '아이파크몰 /디지털소형가전/토이하비/디지털관', '여로집 영등포본관/오징어볶음', '서울1호선 용산역 / 경의중앙선 용산역 동인천 천안급행 2-1 / 문산행 8-4'] The person visited the following places on 2017-12-22:\n",
      "1. 덕수궁피자\n",
      "2. 할리스커피 광화문LG점\n",
      "['서울3호선 종로3가역 대화행 10-4 / 오금행 1-1', '독도참치 #둔촌점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '메가박스 코엑스점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/MARVEL COLLECTION', '메가박스 코엑스점'] 스타필드 코엑스몰점\n",
      "['코스트코 양평점 /냉동식품코너', '코스트코 양평점 /유제품코너', '코스트코 양평점 /견과류코너', '코스트코 양평점 /가구코너', '코스트코 양평점 /냉동식품코너', '코스트코 양평점 /의류', '코스트코 양평점 /학용품', '코스트코 양평점 /서비스센터'] 코스트코 양평점\n"
     ]
    }
   ],
   "source": [
    "# oi_ask_place_dfloader_score = []\n",
    "oi_ask_place_dfloader_wont_score = []\n",
    "# ds_ask_place_json_score = []\n",
    "oi_ask_place_json_wont_score = []\n",
    "oi_ask_place_tabsep_score = []\n",
    "oi_ask_place_commasep_score = []\n",
    "oi_ask_place_totext_score = []\n",
    "oi_ask_place_totextvisited_score = []\n",
    "\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(possible_places_ans, ds_ask_place_dfloader):\n",
    "#     ds_ask_place_dfloader_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(possible_places_ans, oi_ask_place_dfloader_wont):\n",
    "    oi_ask_place_dfloader_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(possible_places_ans, ds_ask_place_json):\n",
    "#     ds_ask_place_json_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(possible_places_ans, oi_ask_place_json_wont):\n",
    "    oi_ask_place_json_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(possible_places_ans, oi_ask_place_tabsep):\n",
    "    oi_ask_place_tabsep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(possible_places_ans, oi_ask_place_commasep):\n",
    "    oi_ask_place_commasep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(possible_places_ans, oi_ask_place_totext):\n",
    "    oi_ask_place_totext_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(possible_places_ans, oi_ask_place_totextvisited):\n",
    "    oi_ask_place_totextvisited_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5d5c3d8b-2efc-47af-a181-498f6c0dde04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30357142857142855\n",
      "0.7053571428571429\n",
      "0.6875\n",
      "0.6785714285714286\n",
      "0.5892857142857143\n",
      "0.41964285714285715\n"
     ]
    }
   ],
   "source": [
    "# print(sum(ds_ask_place_dfloader_score)/user_number)\n",
    "print(sum(oi_ask_place_dfloader_wont_score)/user_number)\n",
    "# print(sum(ds_ask_place_json_score)/user_number)\n",
    "print(sum(oi_ask_place_json_wont_score)/user_number)\n",
    "print(sum(oi_ask_place_tabsep_score)/user_number)\n",
    "print(sum(oi_ask_place_commasep_score)/user_number)\n",
    "print(sum(oi_ask_place_totext_score)/user_number)\n",
    "print(sum(oi_ask_place_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27828ca8-7a30-4fea-a3ad-68f4ced3fce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 -------\n",
      "------ 1 -------\n",
      "------ 2 -------\n",
      "------ 3 -------\n",
      "------ 4 -------\n",
      "------ 5 -------\n",
      "------ 6 -------\n",
      "------ 7 -------\n",
      "------ 8 -------\n",
      "------ 9 -------\n",
      "------ 10 -------\n",
      "------ 11 -------\n",
      "------ 12 -------\n",
      "------ 13 -------\n",
      "------ 14 -------\n",
      "------ 15 -------\n",
      "------ 16 -------\n",
      "------ 17 -------\n",
      "------ 18 -------\n",
      "------ 19 -------\n",
      "------ 20 -------\n",
      "------ 21 -------\n",
      "------ 22 -------\n",
      "------ 23 -------\n",
      "------ 24 -------\n",
      "------ 25 -------\n",
      "------ 26 -------\n",
      "------ 27 -------\n",
      "------ 28 -------\n",
      "------ 29 -------\n",
      "------ 30 -------\n",
      "------ 31 -------\n",
      "------ 32 -------\n",
      "------ 33 -------\n",
      "------ 34 -------\n",
      "------ 35 -------\n",
      "------ 36 -------\n",
      "------ 37 -------\n",
      "------ 38 -------\n",
      "------ 39 -------\n",
      "------ 40 -------\n",
      "------ 41 -------\n",
      "------ 42 -------\n",
      "------ 43 -------\n",
      "------ 44 -------\n",
      "------ 45 -------\n",
      "------ 46 -------\n",
      "------ 47 -------\n",
      "------ 48 -------\n",
      "------ 49 -------\n",
      "------ 50 -------\n",
      "------ 51 -------\n",
      "------ 52 -------\n",
      "------ 53 -------\n",
      "------ 54 -------\n",
      "------ 55 -------\n",
      "------ 56 -------\n",
      "------ 57 -------\n",
      "------ 58 -------\n",
      "------ 59 -------\n",
      "------ 60 -------\n",
      "------ 61 -------\n",
      "------ 62 -------\n",
      "------ 63 -------\n",
      "------ 64 -------\n",
      "------ 65 -------\n",
      "------ 66 -------\n",
      "------ 67 -------\n",
      "------ 68 -------\n",
      "------ 69 -------\n",
      "------ 70 -------\n",
      "------ 71 -------\n",
      "------ 72 -------\n",
      "------ 73 -------\n",
      "------ 74 -------\n",
      "------ 75 -------\n",
      "------ 76 -------\n",
      "------ 77 -------\n",
      "------ 78 -------\n",
      "------ 79 -------\n",
      "------ 80 -------\n",
      "------ 81 -------\n",
      "------ 82 -------\n",
      "------ 83 -------\n",
      "------ 84 -------\n",
      "------ 85 -------\n",
      "------ 86 -------\n",
      "------ 87 -------\n",
      "------ 88 -------\n",
      "------ 89 -------\n",
      "------ 90 -------\n",
      "------ 91 -------\n",
      "------ 92 -------\n",
      "------ 93 -------\n",
      "------ 94 -------\n",
      "------ 95 -------\n",
      "------ 96 -------\n",
      "------ 97 -------\n",
      "------ 98 -------\n",
      "------ 99 -------\n",
      "------ 100 -------\n",
      "------ 101 -------\n",
      "------ 102 -------\n",
      "------ 103 -------\n",
      "------ 104 -------\n",
      "------ 105 -------\n",
      "------ 106 -------\n",
      "------ 107 -------\n",
      "------ 108 -------\n",
      "------ 109 -------\n",
      "------ 110 -------\n",
      "------ 111 -------\n"
     ]
    }
   ],
   "source": [
    "# oi_most_visited_date_pred_dfloader = []\n",
    "oi_most_visited_date_pred_dfloader_wont = []\n",
    "# oi_most_visited_date_pred_json = []\n",
    "oi_most_visited_date_pred_json_wont = []\n",
    "oi_most_visited_date_pred_tabsep = []\n",
    "oi_most_visited_date_pred_commasep = []\n",
    "oi_most_visited_date_pred_totext = []\n",
    "oi_most_visited_date_pred_totextvisited = []\n",
    "\n",
    "system_prompt = 'You only answer in the following format: year-month-day. Don\\'t answer in a sentence.'\n",
    "\n",
    "user_prompt = 'The user\\'s visit history below is delimited by three backticks. Your goal is to answer the question \\'When is the date with the most visits?\\' If you have several days, answer only one date. Look into the features of the user\\'s visit history and put emphasis on key features of the data that could be useful in answering the question.'\n",
    "\n",
    "\n",
    "   \n",
    "system_prompt_dfloader = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "1. The visit history is in the format of pandas dataframe loader.    \n",
    "2. Each column name(index, date, hour, place_name, place_category, and place_address) is indicated before each colon and values are represented in a list format after each colon.\n",
    "3. The order of values in each list is kept the same, meaning that nth value in one list and nth value in another list are both included in the person’s one specific visit log information.\n",
    "''' + system_prompt\n",
    "      \n",
    "system_prompt_json = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "1. The visit history is in the format of JSON.\n",
    "2. The number before each colon before each dictionary format indicates the index number of the visit log and the dictionary format data after each colon includes each column name( index, date, hour, place_name, place_category, and place_address) and the value corresponding to the column. \n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_tabsep = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "1. Each line contains one log of the visit history.\n",
    "2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "3. Each item that corresponds to each feature is separated by a tab.\n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_commasep = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "1. Each line contains one log of the visit history.\n",
    "2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "3. Each item that corresponds to each feature is separated by a comma.\n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_totext = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "1. The visit history is in the text(sentence) format.\n",
    "2. In the sentence, each visit log is included in order of time. \n",
    "3. Each visit log includes date, hour, place_name, place_category, and place_address. \n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_totextvisited = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "1. The visit history is in the text(sentence) format.\n",
    "2. In the sentence, for each place, its place_name, place_category, and place_address are followed by all visited dates and hours to the place. \n",
    "''' + system_prompt\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('------', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_temporal/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # print('format 1')\n",
    "    # output, tok = oi_api(system_prompt_dfloader, user_prompt, dfloader(user_log))\n",
    "    # ds_most_visited_date_pred_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    output, tok = oi_api(system_prompt_dfloader, user_prompt, dfloader_wont(user_log))\n",
    "    oi_most_visited_date_pred_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # output, tok = gpt_api(system_prompt_json, user_prompt, json(user_log))\n",
    "    # ds_most_visited_date_pred_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    output, tok = oi_api(system_prompt_json, user_prompt, json_wont(user_log))\n",
    "    oi_most_visited_date_pred_json_wont.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_tabsep, user_prompt, tabsep(user_log))\n",
    "    oi_most_visited_date_pred_tabsep.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_commasep, user_prompt, commasep(user_log))\n",
    "    oi_most_visited_date_pred_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = oi_api(system_prompt_totext, user_prompt, totext(user_log))\n",
    "    oi_most_visited_date_pred_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = oi_api(system_prompt_totextvisited, user_prompt, totextvisited(user_log))\n",
    "    oi_most_visited_date_pred_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "81644dbe-d82f-4c5b-9c16-20de5798556c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['2018-01-02', '2018-01-03'] 2017-12-30\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the 'date' column in the visit history dataframe. By analyzing the 'date' column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the results in descending order and select the date with the highest visit count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [17, 17, 18, 18, 9, 11, 14, 12, 12, 17, 15, 16, 16, 16, 16, 16, 17, 18, 19, 8, 9, 10, 10, 11, 12, 12, 18, 16, 23, 16, 17, 8, 9, 11, 10, 10, 12, 13, 17, 21],\n",
      "    'place_name': ['서울4호선 충무로역 오이도방면 7-1', '경의중앙선 서울역 서울역발 문산방면 4-4 / 서울역방면 4-4', '서울4호선 서울역 당고개방면 5-1/오이도방면 6-4', '일팔공 충무로점', '미소식품가정식백반', 'TKS CAFE', 'TKS CAFE', 'TKS CAFE', '미소식품가정식백반', 'TKS CAFE', 'TKS CAFE', '마이문화사', '신성금박인쇄', '영산인쇄사', 'TKS CAFE', '희야수퍼', 'TKS CAFE', '바닷가애서', '바닷가애서', 'TKS CAFE', '영지문화', '우진인쇄', 'TKS CAFE', 'TKS CAFE', 'TKS CAFE', '늘봄날', '반월봉투인쇄', '일팔공 충무로점', 'GS25 중구엘크루점', 'TKS CAFE', 'TKS CAFE', 'TKS CAFE', 'TKS CAFE', 'TKS CAFE', 'TKS CAFE', '미소식품가정식백반', 'Mr.Breeze coffee 충무로점', 'TKS CAFE', 'TKS CAFE', '계림마늘닭'],\n",
      "    'place_category': ['Subway Station', 'Subway Station', 'Subway Station', 'Snack Bar', 'Korean Food Restaurants', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Korean Food Restaurants', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Supermarket', 'Stationery Shop', 'Japanese Food Restaurants', 'Japanese Food Restaurants', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Korean Food Restaurants', 'Stationery Shop', 'Snack Bar', 'Convenience Store', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Stationery Shop', 'Korean Food Restaurants', 'Coffee Shop', 'Stationery Shop', 'Stationery Shop', 'Korean Food Restaurants'],\n",
      "    'place_address': ['서울 중구 필동2가 16-2', '서울 중구 봉래동2가 122-22', '서울 용산구 동자동 14-200', '서울 중구 충무로5가 36-2', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 166', '서울 중구 인현동2가 166', '서울 중구 충무로5가 22-9', '서울 중구 인현동2가 159', '서울 중구 필동2가 72-4', '서울 중구 인현동2가 159', '서울 중구 필동2가 28-6', '서울 중구 필동2가 28-6', '서울 중구 인현동2가 159', '서울 중구 인현동2가 157-1', '서울 중구 인현동2가 154-1', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 필동2가 24-3', '서울 중구 인현동2가 153', '서울 중구 충무로5가 36-2', '서울 중구 충무로5가 36-2', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 충무로3가 30-4', '서울 중구 인현동2가 159', '서울 중구 인현동2가 159', '서울 중구 충무로4가 132-12'],\n",
      "    'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "})\n",
      "\n",
      "# Group the visit history by date and count the number of visits for each date\n",
      "visit_counts = visit_history.groupby('date').size().reset_index(name='visit_count')\n",
      "\n",
      "# Sort the visit counts in descending order\n",
      "sorted_visit_counts = visit_counts.sort_values(by='visit_count', ascending=False)\n",
      "\n",
      "# Get the date with\n",
      "['2017-12-28'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and identify the date with the highest count.\n",
      "\n",
      "To do this, we can use the pandas library to group the data by the \"date\" column and then count the number of occurrences for each date. Finally, we can select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [15, 19, 22, 22, 23, 8, 11, 15, 15, 22, 22, 12, 18, 19, 19, 11, 18, 18, 22, 12, 15, 19, 20, 22, 17, 22, 12, 12, 14, 19, 19, 8, 9, 12, 21, 21, 0, 10, 8, 10],\n",
      "    'place_name': ['스타벅스 하이테크시티점', 'sweet garden', 'GS25 서초유원점', '홍루몽', '홍루몽', '서울2호선 서초역 내선 7-1', '미스터힐링 영등포구청역점', '투썸플레이스 문래하이테크시티점', 'GS25 문래시티점', '서울3호선 남부터미널역 오금방면 7-1', '서울9호선 노량진역 종합운동장 방면 2-4', '스타벅스 하이테크시티점', 'NATURE REPUBLIC 문래역점', '서울3호선 교대역 대화방면 10-4', '미도상가 /진미김밥', '대지공인중개사', '현대백화점 무역센터점 /수입부티크', '현대백화점 무역센터점 /골프/스포츠/아웃도어/트래디셔널', '서울3호선 대치역 대화방면 9-1/오금방면 2-4', 'CHAHONG ROOM', 'GS25 지에스타워점', '매드후라이치킨 역삼GS타워점', '투썸플레이스 역삼역점', 'KFC 역삼역점', '하나로마트 대치점', '투썸플레이스 신논현역점', '타임스퀘어/PRADA 타임스퀘어점', '타임스퀘어/백미당', 'GS25 문래시티점', 'NATURE REPUBLIC 문래역점', '서울3호선 교대역 대화방면 10-4', '서울3호선 양재역 대화방면 9-1', '뚜레쥬르 문래하이테크점', '신세계백화점 영등포점 /B관/아웃도어', '모퉁이집', '월매네주막', '마돈나노래연습장', 'GS25 문래시티점', '서울3호선 양재역 대화방면 10-4', 'GS25 문래시티점'],\n",
      "    'place_category': ['Coffee Shop', 'Coffee Shop', 'Convenience Store', 'Others(Restaurants)', 'Others(Restaurants)', 'Subway Station', 'Theme Cafe', 'Coffee Shop', 'Convenience Store', 'Subway Station', 'Subway Station', 'Coffee Shop', 'Cosmetics Shop', 'Subway Station', 'Outlet/ Shopping Mall', 'Real Estate Agency', 'Department Store', 'Department Store', 'Subway Station', 'Hair Salon', 'Convenience Store', 'Chicken', 'Coffee Shop', 'Burger/Sandwich', 'Supermarket', 'Coffee Shop', 'Clothing Store', 'Icecream Shop', 'Convenience Store', 'Cosmetics Shop', 'Subway Station', 'Subway Station', 'Bakery', 'Department Store', 'Snack Bar', 'Others(Alchoholic Beverages)', 'Karaoke', 'Convenience Store', 'Subway Station', 'Convenience Store'],\n",
      "    'place_address': ['서울 영등포구 문래동3가 55-20', '서울 서초구 서초동 1451-23', '서울 서초구 서초동 1586-1', '서울 서초구\n",
      "['2017-12-19', '2018-01-04', '2018-01-03'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-15', '2017-12-18', '2018-01-01', '2018-01-02', '2018-01-03'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05'],\n",
      "    'hour': [16, 18, 9, 18, 9, 11, 14, 15, 12, 12, 15, 16, 10, 11, 14, 10, 14, 15, 16, 16, 14, 15, 16, 13, 19, 20, 12, 13, 13, 14, 10, 17, 19, 21, 9, 10, 10, 17, 9, 16],\n",
      "    'place_name': ['한사랑의원 내과.소아과.이비인후과.피부과', 'GS수퍼마켓 잠실파크리오점', '크로스핏어썸', '채선당 월드마크점', '크로스핏어썸', '홈플러스 잠실점/아티제 잠실홈플러스점', '잠실눈사람안과', '한사랑의원 내과.소아과.이비인후과.피부과', '홈플러스 잠실점 /비식품코너', '홈플러스 잠실점 /식품코너', '롯데월드몰/H&M 롯데월드몰점/Women/Kids', '롯데월드몰/MUJI 롯데월드몰점', '얌샘김밥 삼성점', '코모키이비인후과', '롯데마트 월드타워점/하이마트 월드타워점', '코모키이비인후과', 'SK에너지 남성주유소', '우체국 서울잠실4동점', '홈플러스 잠실점 /비식품코너', '롯데백화점 에비뉴엘 잠실점/BAUME&MERCIER', '스타필드 코엑스몰점/브릭라이브카페', '스무디킹 도심공항점', '헬로방방 둔촌점', '스타벅스 잠실점', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너', '홈플러스 잠실점 /비식품코너', '풀잎채 두부사랑점', '홈플러스 잠실점 /비식품코너', '홈플러스 잠실점 /비식품코너', '크로스핏어썸', '연세봄치과의원', '롯데백화점 에비뉴엘 잠실점/CANADA GOOSE', '크로스핏어썸', '크로스핏어썸', '크로스핏어썸', '장미A상가', 'GS수퍼마켓 잠실파크리오점', '크로스핏어썸', '한사랑의원 내과.소아과.이비인후과.피부과'],\n",
      "    'place_category': ['Others(Hospital)', 'Supermarket', 'Physical Fitness Facility', 'Japanese Food Restaurants', 'Physical Fitness Facility', 'Others(Bakery/Desert)', 'Ophthalmic Clinic', 'Others(Hospital)', 'Discount Department Store', 'Discount Department Store', 'Clothing Store', 'Household Goods', 'Snack Bar', 'Otolaryngology Clinic', 'Electronics Shop', 'Otolaryngology Clinic', 'Gas stations', 'Post Office', 'Discount Department Store', 'Watch Store', 'Kids Cafe', 'Juice Shop', 'Kids Cafe', 'Coffee Shop', 'Korean Food Restaurants', 'Discount Department Store', 'Discount Department Store', 'Korean Food Restaurants', 'Discount Department Store', 'Discount Department Store', 'Physical Fitness Facility', 'Dental Clinic', 'Clothing Store', 'Physical Fitness Facility', 'Physical Fitness Facility', 'Physical Fitness Facility', 'Outlet/ Shopping Mall', 'Supermarket', 'Physical Fitness\n",
      "['2018-01-03'] 2017-12-27\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the 'date' column in the visit history dataframe. \n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the 'date' column and then identify the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03'],\n",
      "    'hour': [20, 21, 9, 17, 13, 17, 18, 19, 20, 21, 22, 22, 22, 10, 11, 12, 16, 19, 20, 20, 20, 19, 23, 8, 8, 12, 13, 14, 15, 15, 17, 19, 20, 23, 12, 13, 13, 16, 19, 15],\n",
      "    'place_name': ['1357철판삼겹', '1357철판삼겹', '소호앤노호 대치점', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '분당선 선릉역 왕십리방면 2-2', '서울7호선 강남구청역 부평구청 방면 4-4', '치킨버스 학동역점', '치킨버스 학동역점', '서울8호선 복정역 /암사방면3-4', '치킨버스 학동역점', '깐부치킨 학동역점', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '자연별곡 교대점', '자연별곡 교대점', '자연별곡 교대점', '자연별곡 교대점', '위담한방병원 내과', '서울8호선 복정역 /암사방면3-4', '커피빈 대치한티점', '분당선 복정역 수원방면 6-4', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '올바른영어 학원', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '위담한방병원 내과', '이디야 한티역점', '위담한방병원 내과', '위담한방병원 내과', '롯데슈퍼 대치4동점', '위담한방병원 내과', '분당선 선릉역 수원방면 3-4', '위담한방병원 내과'],\n",
      "    'place_category': ['Korean Food Restaurants', 'Korean Food Restaurants', 'Others(Others)', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Subway Station', 'Subway Station', 'Chicken', 'Chicken', 'Subway Station', 'Chicken', 'Chicken', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Internal Medicine Clinic', 'Subway Station', 'Coffee Shop', 'Subway Station', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Others(Private Institute)', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Coffee Shop', 'Internal Medicine Clinic', 'Internal Medicine Clinic', 'Supermarket', 'Internal Medicine Clinic', 'Subway Station', 'Internal Medicine Clinic'],\n",
      "    'place_address': ['서울 서초구 방배동 451-4', '서울 서초구 방배동 451-4', '서울 강남구 대치동 906-20', '서울 강남구 대치동 910-1', '서울 강남구 대치동 910-1', '서울 강남구 대치동 910-1', '서울 강남구 역삼동 802-31', '서울 강남구 논현동 279-92', '서울 강남구 논현동 209', '서울 강남구 논현동 209', '서울 송파구 장지동 596-21', '서울 강남구 논현동 209', '서울 강남구 논현동 209-1', '서울 강남구 대치동 910-1', '서울 강남구 대치동 910-1', '서울 강남구 대치동 910-1', '서울 강남구 대치동 910-1', '서울 서초구 서초동 1692-13', '서울 서초구 서초동 1692-13', '서울 서초구 서초동 1692-13', '서울 서초구 서초동 1692-13', '서울 강남구 대치동 910-1', '서울 송파구 장지동 596-21', '서울 강남구 대치동 924-9', '서울 송파구 장지동 596-21', '서울\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [8, 8, 18, 18, 21, 23, 23, 23, 23, 0, 0, 8, 19, 19, 19, 20, 11, 12, 12, 17, 18, 11, 12, 12, 12, 12, 22, 22, 23, 23, 23, 12, 12, 12, 12, 19, 9, 10, 21, 22],\n",
      "    'place_name': ['CU 대치예스점', '서울7호선 장승배기역 장암 방면 6-4', '세븐일레븐 대치본점', '스터디100도씨 학원', '스터디100도씨 학원', '분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 2-2', '분당선 한티역 왕십리방면 2-2', '서울7호선 강남구청역 부평구청 방면 4-4', '서울7호선 온수역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', 'NATURE REPUBLIC 강남구청역점', '서울7호선 고속터미널역 부평구청 방면 2-2', '서울7호선 강남구청역 부평구청 방면 2-2', '서울7호선 청담역 부평구청 방면 2-2', '서울7호선 가산디지털단지역 부평구청 방면 2-2', '서울7호선 온수역 장암 방면 6-4', '서울7호선 총신대입구(이수)역 장암 방면 2-2', '서울7호선 보라매역 부평구청 방면 2-2 / 장암 방면 7-2', 'GS25 대치중앙점', '세븐일레븐 대치본점', '서울7호선 가산디지털단지역 장암 방면 6-4', '서울7호선 남성역 장암 방면 4-4', 'NATURE REPUBLIC 강남구청역점', 'GS25 강남파로스점', 'GS25 S강남구청역점', '도미노피자 대치점', '서울7호선 강남구청역 부평구청 방면 6-4', '서울7호선 논현역 부평구청 방면 6-4', '서울7호선 대림역 부평구청 방면 6-4', '서울7호선 남구로역 부평구청 방면 6-4', '서울7호선 보라매역 부평구청 방면 2-2 / 장암 방면 7-2', 'GS25 강남파로스점', '서울7호선 장승배기역 장암 방면 4-4', '서울7호선 총신대입구(이\n",
      "['2017-12-27'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column indicates the date of each visit log.\n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then identify the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [14, 14, 14, 14, 15, 15, 17, 17, 17, 17, 18, 18, 19, 23, 23, 23, 13, 13, 14, 14, 17, 17, 18, 23, 23, 12, 13, 13, 17, 17, 22, 23, 23, 23, 14, 17, 17, 23, 14, 17],\n",
      "    'place_name': ['YES24 중고서점강남점', 'UNIQLO 사당파스텔점', '서울2호선 역삼역 내선 3-1', '스타벅스 강남오거리점', 'UNIQLO 강남점', 'UNIQLO 사당파스텔점', 'UNIQLO 사당파스텔점', 'UNIQLO 강남점', '무한숯불양꼬치 #강남역점', '바비인형 /속눈썹 왁싱', 'UNIQLO 사당파스텔점', 'UNIQLO 강남점', 'UNIQLO 사당파스텔점', '서울3호선 도곡역 오금방면 7-1', '신분당선 양재역 광교방면 3-4', '신분당선 강남역 광교방면 2-2', '신세계백화점 강남점 /화장품/잡화/해외유명브랜드', '서울3호선 도곡역 대화방면 5-1', '서울9호선 신논현역 종합운동장 방면 1-1', 'YES24 중고서점강남점', '맥도날드 강남2호점', '메가박스 씨티점', 'UNIQLO 사당파스텔점', '신분당선 강남역 광교방면 3-4', '서울3호선 양재역 오금방면 5-1', '영풍문고 강남역점', '영풍문고 강남역점', '더블트러블 #강남역 #샌드위치', 'YES24 중고서점강남점', '고씨네 강남역점 /일본카레전문', 'UNIQLO 사당파스텔점', '신분당선 강남역 광교방면 3-4', '서울3호선 양재역 오금방면 5-1', '서울3호선 양재역 오금방면 7-1', '서울2호선 선릉역 내선 5-1', '맥도날드 강남2호점', '메가박스 씨티점', '서울3호선 양재역 오금방면 7-1', 'YES24 중고서점강남점', '메가박스 씨티점'],\n",
      "    'place_category': ['Bookstore', 'Clothing Store', 'Subway Station', 'Coffee Shop', 'Clothing Store', 'Clothing Store', 'Clothing Store', 'Clothing Store', 'Chinese Food Restaurants', 'Beauty Shop', 'Clothing Store', 'Clothing Store', 'Clothing Store', 'Subway Station', 'Subway Station', 'Subway Station', 'Department Store', 'Subway Station', 'Subway Station', 'Bookstore', 'Burger/Sandwich', 'Movie Theater', 'Clothing Store', 'Subway Station', 'Subway Station', 'Bookstore', 'Bookstore', 'Burger/Sandwich', 'Bookstore', 'Japanese Food Restaurants', 'Clothing Store', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Burger/Sandwich', 'Movie Theater', 'Subway Station', 'Bookstore', 'Movie Theater'],\n",
      "    'place_address': ['서울 강남구 역삼동 816', '서울 서초구 방배동 444-3', '서울 강남구 역삼동 804', '서울 강남구 역삼동 813-17', '서울 강남구 역삼동 815-4\n",
      "['2017-12-25'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and identify the date with the highest count.\n",
      "\n",
      "To do this, we can use the pandas library to group the data by the \"date\" column and then count the number of occurrences for each date. Finally, we can select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [9, 9, 10, 15, 11, 13, 13, 14, 14, 15, 18, 5, 11, 11, 18, 5, 15, 18, 19, 5, 5, 11, 9, 11, 12, 15, 22, 5, 11, 11, 12, 5, 18, 5, 12, 12, 15, 5, 11, 19],\n",
      "    'place_name': ['스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '메가박스 코엑스점/MX관', 'GS25 논현진실점', '올리브영 학동역점', '강남성결교회 /사무실', '이디야 강남YMCA점', '강남성결교회 /사무실', '스타필드 코엑스몰점/CUBE', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '스타필드 코엑스몰점/아담 코엑스몰점', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', '강남성결교회 /사무실', '카톨릭정형외과 /정형외과', 'GS25 논현동우점', 'GS25 논현동우점', '강남성결교회 /사무실', '카톨릭정형외과 /정형외과', '커피빈 차병원사거리점', '강남성결교회 /사무실', '강남성결교회 /사무실', '강남성결교회 /사무실', '카톨릭정형외과 /정형외과', '강남성결교회 /사무실', 'GS25 논현진실점', '강남성결교회 /사무실', 'GS25 논현진실점', '서울8호선 잠실역 암사방면 2-2', '강남성결교회 /사무실', 'KB국민은행 논현동지점', '우체국 서울언주로지점', 'GS25 논현동우점', '강남성결교회 /사무실', 'GS25 논현동우점', '강남성결교회 /사무실', '카톨릭정형외과 /정형외과', 'GS25 논현동우점', '카톨릭정형외과 /정형외과', '강남성결교회 /사무실', '카톨릭정형외과 /정형외과', '아트짐휘트니스'],\n",
      "    'place_category': ['Movie Theater', 'Movie Theater', 'Convenience Store', 'Drug Store', 'Protestant Church', 'Coffee Shop', 'Protestant Church', 'Amusement Arcade', 'Outlet/ Shopping Mall', 'Leather Product Store', 'Others(Restaurants)', 'Protestant Church', 'Orthopedics', 'Convenience Store', 'Convenience Store', 'Protestant Church', 'Orthopedics', 'Coffee Shop', 'Protestant Church', 'Protestant Church', 'Protestant Church', 'Orthopedics', 'Protestant Church', 'Convenience Store', 'Protestant Church', 'Convenience Store', 'Subway Station', 'Protestant Church', 'Bank', 'Post Office', 'Convenience Store', 'Protestant Church', 'Convenience Store', 'Protestant Church', 'Orthopedics', 'Convenience Store', 'Orthopedics', 'Protestant Church', 'Orthopedics', 'Physical Fitness Facility'],\n",
      "    'place_address': ['서울 강남구 삼성\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. \n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [13, 18, 19, 18, 20, 18, 18, 13, 18, 18, 18, 20, 18, 18, 16, 16, 16, 17, 17, 18, 18, 19, 15, 15, 16, 18, 19, 20, 20, 15, 13, 9, 18, 19, 10, 11, 19, 18, 18, 20],\n",
      "    'place_name': ['달콤커피 삼성점', '진부령황태명가', '삼성한방삼계탕', '진부령황태명가', '인어스휘트니스', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '이디야 강남역지하상가점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점/D.QUEENS 코엑스몰점', '진부령황태명가', '진부령황태명가', '인어스휘트니스', '진부령황태명가', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', '스타필드 코엑스몰점/KFC 코엑스몰점', '스타필드 코엑스몰점 /코나이비인후과/헌혈의집', '파리바게뜨 삼성풍림점', '진부령황태명가', '삼성한방삼계탕', '삼성한방삼계탕', '서울2호선 2521', '서울9호선 봉은사역 종합운동장 방면 2-4', '최미삼순대국', '진부령황태명가', '진부령황태명가', '진부령황태명가', '삼성한방삼계탕', 'NATURE REPUBLIC 청담역점', '파리바게뜨 삼성풍림점', '아셈내과의원', '인어스휘트니스', '삼성한방삼계탕', '박병익내과의원 내과', '스타벅스 삼성도심공항점', '진부령황태명가', '삼성한방삼계탕', '진부령황태명가', '삼성한방삼계탕'],\n",
      "    'place_category': ['Coffee Shop', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Physical Fitness Facility', 'Movie Theater', 'Outlet/ Shopping Mall', 'Coffee Shop', 'Outlet/ Shopping Mall', 'Western Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Physical Fitness Facility', 'Korean Food Restaurants', 'Outlet/ Shopping Mall', 'Others(Restaurants)', 'Burger/Sandwich', 'Outlet/ Shopping Mall', 'Bakery', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Subway Train', 'Subway Station', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Cosmetics Shop', 'Bakery', 'Internal Medicine Clinic', 'Physical Fitness Facility', 'Korean Food Restaurants', 'Internal Medicine Clinic', 'Coffee Shop', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants'],\n",
      "    'place_address': ['서울 강남구 삼성동 168-16', '서울 강남구 삼성동 107-1', '서울 강남구 삼성동 107', '서울 강남구 삼성동 107-1', '서울 강남구 삼성동 107', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159-9', '서\n",
      "['2017-12-26', '2017-12-31'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-06'] The key feature that could be useful in answering the question is the 'date' column in the visit history. By analyzing the 'date' column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the 'date' column and then identify the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-03', '2017-12-04', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-06', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31'],\n",
      "    'hour': [20, 17, 3, 14, 14, 15, 15, 15, 20, 21, 21, 22, 23, 21, 10, 16, 16, 17, 17, 9, 20, 21, 21, 21, 21, 13, 18, 19, 19, 13, 14, 20, 21, 22, 17, 18, 0, 1, 2, 3],\n",
      "    'place_name': ['CGV 상암점/스낵테이블', '도미노피자 상도점', 'GS25 상도터널점', '피자보이시나 중앙대본점', '열정식당', '피자보이시나 중앙대본점', '열정식당', '현대사진관', 'OUTBACK 신촌점', 'OUTBACK 신촌점', '벌툰', '벌툰', '벌툰', '상도갈비', '정동병원 종합병원', '서교피아노', '피아노카페', '피아노카페', '서교피아노', '공항철도 김포공항역 / 서울9호선 김포공항역 인천국제공항방면 6-4', '아이파크몰/마시찜 용산아이파크몰점', '아이파크몰/마시찜 용산아이파크몰점', '아이파크몰/CGV 용산아이파크몰점/씨네샵/서관', '아이파크몰/커피빈', '아이파크몰/아이파크백화점/탑텐 아이파크몰점/패션관', 'Cafe Jibob', '월남국수', '월남국수', '땡초호프', '다밀원 봉평막국수&숯불닭바베큐', '다밀원 봉평막국수&숯불닭바베큐', '벌툰', '맥도날드 서울시청점', '맥도날드 서울시청점', '롯데리아 응암점', '월남국수', '밀짚모자', '밀짚모자', '밀짚모자', '밀짚모자'],\n",
      "    'place_category': ['Movie Theater', 'Pizza', 'Convenience Store', 'Pizza', 'Korean Food Restaurants', 'Pizza', 'Korean Food Restaurants', 'Photo Studio', 'Western Food Restaurants', 'Western Food Restaurants', 'Theme Cafe', 'Theme Cafe', 'Theme Cafe', 'Korean Food Restaurants', 'General Hospital', 'Music Education', 'Coffee Shop', 'Coffee Shop', 'Music Education', 'Subway Station', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Movie Theater', 'Coffee Shop', 'Department Store', 'Coffee Shop', 'Others(Restaurants)', 'Others(Restaurants)', 'Bar', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Theme Cafe', 'Burger/Sandwich', 'Burger/Sandwich', 'Burger/Sandwich', 'Others(Restaurants)', 'Bar', 'Bar', 'Bar', 'Bar'],\n",
      "    'place_address': ['서울 마포구 성산동 515-3', '서울 동작구 상도동 159-9', '서울 동작구 상도1동 622', '서울 동작구 흑석동 190-5', '서울 동작구 흑석동 190-5', '서울 동작구 흑석동 190-5', '서울 동작구 흑석동 190-5', '서울 동작구 흑석동 183-5', '서울 서대문구 창천동 2-89', '서울 서대문구 창천동 2-89', '서울 마포구 서교동 395-18', '서울 마포구 서교동 395-18', '서울 마포구 서교동 395-18', '서울 동작구 상도1동 526', '서울 동작구 상도1동 614-1', '서울 마포구 서교동 342-15', '서울 마포구 서교동 342-15', '서울 마포구 서교동 342-15', '서울 마포구 서교동 342-15', '서울 강서구 방화동 886-8', '서울 용산구 한강로3가 40-999', '서울 용산구 한강로3가 40-999', '서울 용산구 한강로3가 40-999', '서울 용산구 한강로3가 40\n",
      "['2017-12-30'] The key feature in the provided visit history data is the \"date\" column. We need to find the date with the most visits. To do this, we can count the occurrences of each date and select the date with the highest count.\n",
      "\n",
      "Based on the provided data, the date with the most visits is \"2017-12-30\".\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To do this, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. Finally, we can find the date with the maximum number of visits.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-11', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-15', '2017-12-16', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04'],\n",
      "    'hour': [12, 16, 16, 18, 17, 18, 22, 21, 22, 22, 13, 12, 18, 19, 19, 12, 13, 18, 10, 14, 16, 17, 20, 20, 21, 21, 23, 17, 17, 17, 20, 14, 15, 16, 18, 14, 12, 12, 13, 15],\n",
      "    'place_name': ['HANS 반포점', '서울2호선 교대역 외선 7-1', '서울3호선 고속터미널역 대화방면 9-1', '서울2호선 2070', '현해', '스타벅스 반포역점', '스타벅스 반포역점', 'ZARA 가로수길점', '스타벅스 가로수길점', '스타벅스 가로수길점', '강가 역삼점', '맥도날드 양재점', '스타필드 코엑스몰점/AGRA 코엑스점', '스타필드 코엑스몰점/다이소 코엑스몰점', '스타필드 코엑스몰점/Weeny Beeny 코엑스스타필드점', '경희현한의원', '서울3호선 신사역 오금방면 3-1', '서울3호선 고속터미널역 대화방면 5-1', '압구정길약국', '서울2호선 을지로3가역 내선 7-1', '서울2호선 역삼역 내선 3-1', '서울3호선 고속터미널역 대화방면 5-1', 'IFC몰/와세다야 여의도IFC점', 'IFC몰/장사랑 IFC몰점', 'IFC몰/커피빈 여의도 IFC몰1호점', 'IFC몰/ALO 여의도IFC몰점', 'CU 압구정JJ미성점', '못된VR게임장', 'SHOOPEN 점프밀라노 강남점', '더달달 카페 /초콜릿 전문', 'SHOOPEN 점프밀라노 강남점', '봉추찜닭 가로수길점', '올리브영 강남본점', 'Nature collection 강남점', '다이소 강남대로점', '천주교성당 압구정', '롯데슈퍼 잠실3동점', '서울3호선 교대역 오금방면 7-1', '서울3호선 고속터미널역 대화방면 5-1', '권홍디자이너샵'],\n",
      "    'place_category': ['Others(Bakery/Desert)', 'Subway Station', 'Subway Station', 'Subway Train', 'Others(Restaurants)', 'Coffee Shop', 'Coffee Shop', 'Clothing Store', 'Coffee Shop', 'Coffee Shop', 'Others(Restaurants)', 'Burger/Sandwich', 'Others(Restaurants)', 'Household Goods', 'Others(Bakery/Desert)', 'Oriental Medical Clinic', 'Subway Station', 'Subway Station', 'Pharmacy', 'Subway Station', 'Subway Station', 'Subway Station', 'Japanese Food Restaurants', 'Korean Food Restaurants', 'Coffee Shop', 'Optical Store', 'Convenience Store', 'Claw Machine Arcade', 'Shoe Store', 'Coffee Shop', 'Shoe Store', 'Korean Food Restaurants', 'Drug Store', 'Cosmetics Shop', 'Household Goods', 'Catholic Church', 'Supermarket', 'Subway Station', 'Subway Station', 'Hair Salon'],\n",
      "    'place_address': ['서울 서초구 반포동 1053', '서울 서초구 서초동 1748-22', '서울 서초구 반포동 118-2', '서울 중구 봉래동2가 122-21', '서울 강남구 논현동 92', '서울 서초구 반포동 118-3', '서울 서\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-22', '2017-12-23', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [15, 5, 14, 5, 16, 9, 18, 18, 14, 18, 20, 21, 12, 13, 13, 14, 14, 5, 5, 14, 14, 14, 5, 14, 15, 11, 12, 13, 13, 16, 17, 17, 18, 19, 5, 15, 16, 15, 17, 17],\n",
      "    'place_name': ['서울5호선 5033', '서울5호선 5127', '하나로마트 서대문점', '서울5호선 충정로역 방화행 2-4 / 상일동 마천행 6-4', '스타벅스 문화일보점', '서울5호선 5317', '서울5호선 목동역 상일동 마천행 6-4', '서울5호선 5276', 'KT 목동네거리점', '신세계백화점 강남점 /신세계 푸드마켓/푸드홀', '서울3호선 고속터미널역 대화방면 9-1', '서울3호선 잠원역 대화방면 5-1', '박종근과자점', '현대백화점 신촌점 /영플라자/대행사장', '현대백화점 신촌점 /문화센터', '현대백화점 신촌점 /식품', 'IBK기업은행 신촌지점', '서울5호선 5229', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '현대백화점 신촌점 /문화센터', 'GS25 종로행촌점', '올리브영 홍대입구역점', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '올리브영 목동역점', '서울5호선 5708', 'Paul Bassett 동부이촌점', '아이파크몰/아이파크백화점 /여성복/패션관', '이마트 용산점 /비식품', '아이파크몰/올리브영 아이파크몰점', '아이파크몰/EYE AVENUE 용산아이파크점/동관', '서울1호선 서울역 소요산행 9-1 / 인천 신창행 3-1', '서울1호선 용산역 소요산행 9-1', '커피베이 종로광화문점', '파리바게뜨 광화문점', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '스타벅스 목동오목로점', '서울5호선 여의나루역 방화방면 6-4', 'Paul Bassett 코리아나호텔점', '빚은 정동점', '세븐일레븐 종로사직점'],\n",
      "    'place_category': ['Subway Train', 'Subway Train', 'Supermarket', 'Subway Station', 'Coffee Shop', 'Subway Train', 'Subway Station', 'Subway Train', 'Mobile Phone Shop', 'Department Store', 'Subway Station', 'Subway Station', 'Bakery', 'Department Store', 'Department Store', 'Department Store', 'Bank', 'Subway Train', 'Subway Station', 'Department Store', 'Convenience Store', 'Drug Store', 'Subway Station', 'Drug Store', 'Subway Train', 'Coffee Shop', 'Department Store', 'Discount Department Store', 'Drug Store', 'Optical Store', 'Subway Station\n",
      "['2017-12-11', '2017-12-12'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-11', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-20', '2017-12-20', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [12, 14, 14, 14, 18, 19, 20, 14, 15, 15, 15, 22, 22, 22, 14, 14, 15, 15, 15, 8, 21, 21, 21, 12, 21, 21, 21, 13, 13, 13, 20, 13, 12, 14, 14, 15, 21, 12, 13, 21],\n",
      "    'place_name': ['스타칼리휘트니스', '분당선 수서역 수원방면 2-2', '분당선 351029', '서울3호선 오금역 대화방면 5-1', '분당선 351210', 'Innisfree 선릉직영점', '분당선 351125', '스타칼리휘트니스', '서울3호선 오금역 대화방면 5-1', '분당선 수서역 수원방면 2-2', '분당선 351030', '서울3호선 수서역 오금방면 9-1', '분당선 351032', '서울3호선 수서역 오금방면 7-1', '우리은행 서울역환전센터점', 'KFC 서울역점', '분당선 351028', '분당선 수서역 수원방면 2-2', '서울3호선 오금역 대화방면 5-1', '분당선 351115', '분당선 351002', '분당선 351220', '서울3호선 수서역 오금방면 9-1', '분당선 수서역 수원방면 2-2', '분당선 351220', '서울3호선 수서역 오금방면 9-1', '분당선 351222', '분당선 수서역 수원방면 2-2', '분당선 351138', '서울3호선 오금역 대화방면 5-1', '분당선 351141', '분당선 351939', '현대백화점 무역센터점 /남성패션', '스타필드 코엑스몰점/TWORLD 코엑스점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '분당선 수서역 수원방면 2-2', '분당선 351020', '서울3호선 오금역 대화방면 5-1', '분당선 351321', '분당선 351216'],\n",
      "    'place_category': ['Physical Fitness Facility', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Cosmetics Shop', 'Subway Train', 'Physical Fitness Facility', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Station', 'Bank', 'Burger/Sandwich', 'Subway Train', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Train', 'Department Store', 'Mobile Phone Shop', 'Outlet/ Shopping Mall', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Train'],\n",
      "    'place_address': ['서울 송파구 가락동 8', '서울 강남구 수서동 728', '서울 중구 봉래동2가 122-21', '서울 송파구 오금동 34-2', '서울 중구 봉래동2가 122-21', '서울 강남구 역삼동 705-26', '서울 중구 봉래동2가 122-21', '서울 송파구 가락동 8', '서울 송파구 오금동 34-2', '서울 강남구 수서동 728', '서울 중구 봉래동2가 122-21', '서울 강남구 수서동 728', '서울 중구 봉래동2가 122-21', '서울 강남구 수서동 719', '서울 중구 봉래동2가 122-21', '서울 용산구 동자동 43-205', '서울 중구 봉래동2가 122-21', '서울 강남구 수서동 728', '서울 송파구 오금동 34-2', '서울 중구 봉래동2가 122-21', '서울 중구 봉래동2가 122-21', '서울 중구 봉래동\n",
      "['2017-12-18'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the following code:\n",
      "\n",
      "``` python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({date : ['2017-12-12', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27'],hour : [19, 15, 19, 22, 14, 17, 22, 15, 15, 18, 19, 15, 16, 22, 15, 15, 15, 15, 16, 16, 17, 17, 17, 16, 17, 17, 17, 14, 17, 14, 17, 14, 18, 19, 17, 21, 14, 17, 17, 21],place_name : ['3POP PC #116055#서울#강남구#대치동', '스타벅스 대치은마사거리점', '3POP PC #116055#서울#강남구#대치동', '포메인 대치점', 'GS25 세종대광개토관점', '3POP PC #116055#서울#강남구#대치동', '롯데슈퍼 대치점', '코스트코 양재점 /식품', '코스트코 양재점 /식품', '버거킹 대치점', '3POP PC #116055#서울#강남구#대치동', '서울7호선 청담역 장암 방면 6-4', '3POP PC CAFE #110995#서울#광진구#군자동', '버거킹 대치점', '현대백화점 무역센터점 /수입부티끄', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /여성캐주얼', '현대백화점 무역센터점 /럭셔리부티크', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점 /이코복스/비비안라이브/스타카토', '스타필드 코엑스몰점/딥티크 코엑스몰점', '코스트코 양재점 /비식품', '코스트코 양재점 /식품', '코스트코 양재점 /식품', '코스트코 양재점 /식품', '스타벅스 대치은마사거리점', '3POP PC #116055#서울#강남구#대치동', '스타벅스 대치은마사거리점', '3POP PC #116055#서울#강남구#대치동', '스타벅스 대치은마사거리점', '스타벅스 대치은마사거리점', '탑플레이스 #114324#서울#강남구#대치동', '스타벅스 대치은마사거리점', '3POP PC #116055#서울#강남구#대치동', '스타벅스 대치은마사거리점', '3POP PC #116055#서울#강남구#대치동', '스타벅스 대치은마사거리점', '3POP PC #116055#서울#강남구#대치동'],place_category : ['PC Cafe', 'Coffee Shop', 'PC Cafe', 'Others(Restaurants)', 'Convenience Store', 'PC Cafe', 'Supermarket', 'Discount Department Store', 'Discount Department Store', 'Burger/Sandwich', 'PC Cafe', 'Subway Station', 'PC Cafe', 'Burger/Sandwich', 'Department Store', 'Department Store', 'Department Store', 'Department Store', 'Department Store', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Cosmetics Shop', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Coffee Shop\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [11, 18, 19, 20, 17, 15, 17, 14, 14, 15, 15, 17, 22, 19, 19, 19, 23, 18, 19, 23, 12, 18, 23, 17, 23, 23, 23, 20, 15, 16, 19, 22, 16, 16, 18, 19, 17, 22, 18, 23],\n",
      "    'place_name': ['서울2호선 종합운동장역 내선 3-1', '불이아 역삼점', '불이아 역삼점', '서울2호선 종합운동장역 외선 3-1', '미소야 서초점', '서울2호선 잠실역 내선 3-1', '스타벅스 예술의전당점', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '현대백화점 무역센터점 /식품/행사장', '현대백화점 무역센터점 /해외패션/화장품/잡화', '서울3호선 남부터미널역 대화방면 9-1', '서울2호선 종합운동장역 내선 3-1', '서울3호선 교대역 오금방면 9-1', '부산아지매국밥 BC카드점', '서울2호선 교대역 외선 7-1', '전주식당', 'PREPER', '서울3호선 남부터미널역 대화방면 9-1', '포메인 양재역점', '미소야 서초점', '서울3호선 남부터미널역 대화방면 9-1', '부산아지매국밥 BC카드점', '서울2호선 교대역 외선 7-1', '서울2호선 삼성역 내선 7-3 / 외선 4-2', '서울3호선 남부터미널역 대화방면 9-1', '스타벅스 서울아트센터점', '서울2호선 종합운동장역 내선 5-1', '올리브영 남부터미널점', '부산아지매국밥 BC카드점', '서울2호선 역삼역 외선 5-1', '서울2호선 2694', '서울5호선 5509', 'IFC몰/스타벅스 여의도IFC몰(B3)점', '서울5호선 여의도역 상일동 마천행 / 6-4', '천진포자 파미에스테이션점', '스타벅스 남부터미널2점', '미소야 서초점', '서울3호선 남부터미널역 대화방면 9-1'],\n",
      "    'place_category': ['Subway Station', 'Others(Restaurants)', 'Others(Restaurants)', 'Subway Station', 'Japanese Food Restaurants', 'Subway Station', 'Coffee Shop', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Department Store', 'Department Store', 'Subway Station', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Subway Station', 'Korean Food Restaurants', 'Coffee Shop', 'Subway Station', 'Others(Restaurants)', 'Japanese Food Restaurants', 'Subway Station', 'Korean Food Restaurants', 'Subway Station', 'Subway Station', 'Sub\n",
      "['2017-12-28'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column indicates the date of each visit log. \n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and identify the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04'],\n",
      "    'hour': [9, 13, 14, 17, 17, 17, 17, 18, 14, 14, 15, 16, 17, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 10, 11, 12, 19, 19, 19, 19, 19, 17, 17, 17, 17, 17, 18, 18, 18, 10],\n",
      "    'place_name': ['서울2호선 선릉역 외선 7-1', '투썸플레이스 선정릉역점', '투썸플레이스 선정릉역점', '서울2호선 강남역 내선 5-1', '분당선 선릉역 수원방면 2-2', '하루방', '서울2호선 2574', '신분당선 강남역 광교방면 2-2', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', 'NATURE REPUBLIC 잠실지하점', '롯데월드몰/아쿠아리움 /매표소', '롯데월드몰/SEOUL SKY /전망대', '롯데백화점 에비뉴엘 잠실점 /화장품/구두', '롯데마트 월드타워점 /비식품코너', '롯데월드몰/반디앤루니스 롯데월드몰점', '신분당선 양재시민의숲역 광교방면 2-2', '신분당선 강남역 광교방면 2-2', '롯데월드몰/SOFTREE 롯데월드몰점', '서울2호선 역삼역 내선 7-1', '엔제리너스 잠실롯데월드타워B1점', '서울2호선 강남역 내선 7-1', '채빛퀴진', 'GS25 한강세빛섬점', '스타벅스 선정릉역점', '스타벅스 선정릉역점', '미니스톱 삼성플러스원점', '분당선 351002', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '신분당선 양재시민의숲역 광교방면 2-2', '신분당선 강남역 광교방면 2-2', '하루방', '서울2호선 선릉역 내선 7-1', '분당선 선정릉역 수원방면 3-4', '서울2호선 강남역 내선 7-1', '분당선 351115', '신분당선 강남역 광교방면 3-4', '신분당선 양재역 광교방면 2-2', '신분당선 강남역 광교방면 2-2', '투썸플레이스 선정릉역점'],\n",
      "    'place_category': ['Subway Station', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Others(Restaurants)', 'Subway Train', 'Subway Station', 'Department Store', 'Cosmetics Shop', 'Aquarium', 'Others(Others)', 'Department Store', 'Discount Department Store', 'Bookstore', 'Subway Station', 'Subway Station', 'Icecream Shop', 'Subway Station', 'Coffee Shop', 'Subway Station', 'Others(Restaurants)',\n",
      "['2017-12-22'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. \n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences for each date and then select the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-06', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-09', '2017-12-09', '2017-12-09', '2017-12-09', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2018-01-06'],\n",
      "    'hour': [21, 8, 8, 8, 1, 1, 14, 14, 20, 21, 8, 8, 19, 14, 17, 19, 11, 18, 20, 20, 8, 15, 15, 16, 8, 20, 20, 20, 20, 18, 18, 19, 19, 19, 19, 19, 23, 23, 15, 0],\n",
      "    'place_name': ['뮤직파워노래방', '서울5호선 을지로4가역 방화행 3-1 / 상일동 마천행 6-4', '서울5호선 을지로4가역 방화행 7-4 / 상일동 마천행 2-1', '서울5호선 5160', 'NATURE REPUBLIC 가로수길점', '망고식스 신사점', '서울2호선 서울대입구역 내선 9-2 / 외선 2-3', '서울2호선 신림역 내선 9-3 / 외선 2-2', '서울2호선 신당역 내선 5-1', '올리브영 강변역점', '서울5호선 5048', '서울5호선 을지로4가역 방화행 7-4 / 상일동 마천행 2-1', '롯데마트 강변점 /식품/비식품', '대림창고 /유통/저장', '채움통증의학과 마취통증의학과', '골목 참숯불갈비', 'Mad for Garlic 광화문D타워점', '스타벅스 이마빌딩점', '서울5호선 광화문역 /방화방면8-4', '서울5호선 5074', '서울2호선 동대문역사문화공원역 외선 5-1', '서울2호선 신도림역 내선 3-1 / 외선 8-4', '서울2호선 영등포구청역 외선 3-1', '스타벅스 구로디지털타워점', '서울5호선 5108', '서울2호선 신당역 내선 5-1', '서울5호선 5033', '서울5호선 광화문역 /방화방면8-4', '서울2호선 뚝섬역 내선 5-1', '서울5호선 광화문역 /상일동마천방면2-2', '서울5호선 광화문역 /방화방면8-4', '이마트 자양점 /식품/비식품/푸드코트', '롯데백화점 스타시티점 /식품 외', '롯데백화점 스타시티점 /식품 외', '서울8호선 잠실역 모란방면 2-2', '이마트 자양점/몰리스펫샵 이마트자양점', '서울8호선 가락시장역 암사방면 4-4', '서울2호선 잠실역 외선 3-1', '오세홍턱사랑치과 ㅊㅣ과', '서울2호선 종합운동장역 외선 3-1'],\n",
      "    'place_category': ['Karaoke', 'Subway Station', 'Subway Station',\n",
      "['2017-12-27'] The key feature in the user's visit history that could be useful in answering the question is the \"date\" column. \n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences for each date and then select the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-27\".\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-07', '2017-12-07', '2017-12-07', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-15', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29'],\n",
      "    'hour': [13, 13, 19, 11, 11, 18, 18, 19, 20, 22, 19, 17, 11, 12, 16, 11, 11, 14, 10, 10, 12, 19, 19, 19, 12, 22, 11, 16, 17, 20, 20, 12, 12, 13, 13, 13, 16, 16, 16, 16],\n",
      "    'place_name': ['스타필드 코엑스몰점/딥티크 코엑스몰점', '스타필드 코엑스몰점/다이소 코엑스몰점', '현대백화점 무역센터점 /식품/행사장', '이도건강약국', '서브웨이 삼성점', '스타벅스 삼성도심공항점', 'GS25 삼성무역점', '쟌슨빌부대찌개 삼성본점', '쟌슨빌부대찌개 삼성본점', '스타필드 코엑스몰점/딥티크 코엑스몰점', '이도건강약국 m타워', '분당선 선릉역 수원방면 2-2', '스타벅스 삼성도심공항점', '육대장 삼성점', '본도시락 삼성점', '스타필드 코엑스몰점/ZARA HOME 코엑스점', '스타필드 코엑스몰점/미스터순두부 코엑스몰점/도심공항타워', 'GS25 삼성무역점', 'GS25 삼성무역점', '이도건강약국 m타워', '김명자굴국밥', '스타필드 코엑스몰점 /소풍/쭈불&쭈불/포베이', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '파르나스몰/환공어묵베이커리', '이자카야탄', '파르나스몰 /밀레피오리/폴리스', '서브웨이 삼성점', 'GS25 무역센타점', 'GS25 무역센타점', '한탕', '종로김밥 삼성점', '시추안하우스 삼성점', '스타필드 코엑스몰점/CUBE', '스타벅스 삼성도심공항점', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /블랙마틴싯봉/세라넥스트도어', '파르나스몰 /왓슨스', '파르나스몰 /샤토레제/18번완당명가', '파르나스몰 /코벳블랑/스테이피플/올세인츠'],\n",
      "    'place_category': ['Cosmetics Shop', 'Household Goods\n",
      "['2018-01-05'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and identify the date with the highest count.\n",
      "\n",
      "To do this, we can use the pandas library to manipulate and analyze the data. We will group the data by the \"date\" column and then count the number of occurrences for each date. Finally, we will select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-21', '2017-12-21', '2017-12-23', '2017-12-24', '2017-12-26', '2017-12-26', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-31', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [17, 17, 17, 17, 17, 17, 17, 18, 19, 21, 15, 16, 16, 13, 7, 19, 14, 10, 12, 19, 12, 16, 12, 20, 17, 7, 19, 18, 18, 19, 19, 20, 20, 21, 21, 21, 22, 22, 22, 23],\n",
      "    'place_name': ['스타필드 코엑스몰점/JUST JINNY', '스타필드 코엑스몰점/adidas 오리지날 코엑스몰점', '스타필드 코엑스몰점 /리바이스/자라홈', '스타필드 코엑스몰점/CONVERSE 코엑스몰점', '스타필드 코엑스몰점/NIKE 코엑스몰점', '스타필드 코엑스몰점/브릭라이브카페', '스타필드 코엑스몰점/NIKE 코엑스몰점', '스타필드 코엑스몰점/브릭라이브 /레고등', '스타필드 코엑스몰점 /메가박스/클로리스', 'GS25 서초네이처힐점', '연세곰돌이소아청소년과의원 소아청소년과', '곰돌이스타약국', '연세곰돌이소아청소년과의원 소아청소년과', '이삭토스트 강남점', 'ARISTA COFFEE 삼성물산점', '화로사랑 서초삼성타운점', 'GS25 서초네이처힐점', 'GS25 서초네이처힐점', '리샨', '송탄부대찌개보쌈', 'SWEET BUNS 서초삼성타운점', 'CU 삼성전자본점', 'ARISTA COFFEE 삼성타운점', 'GS25 서초네이처힐점', '이마트 에브리데이 우면점', 'ARISTA COFFEE 삼성타운점', '일일향', '시호반', '마리안느', '시호반', '마리안느', '시호반', '마리안느', '마리안느', '시호반', '김밥천국 우성점', '마리안느', '시호반', 'KFC 서초우성점', 'KFC 서초우성점'],\n",
      "    'place_category': ['Shoe Store', 'Clothing Store', 'Outlet/ Shopping Mall', 'Shoe Store', 'Clothing Store', 'Kids Cafe', 'Clothing Store', 'Game/Toy Store', 'Outlet/ Shopping Mall', 'Convenience Store', 'Others(Hospital)', 'Pharmacy', 'Others(Hospital)', 'Burger/Sandwich', 'Coffee Shop', 'Korean Food Restaurants', 'Convenience Store', 'Convenience Store', 'Chinese Food Restaurants', 'Korean Food Restaurants', 'Western Food Restaurants', 'Convenience Store', 'Coffee Shop', 'Convenience Store', 'Supermarket', 'Coffee Shop', 'Chinese Food Restaurants', 'Japanese Food Restaurants', 'Clothing Store', 'Japanese Food Restaurants', 'Clothing Store', 'Japanese Food Restaurants', 'Clothing Store', 'Clothing Store', 'Japanese Food Restaurants', 'Snack Bar', 'Clothing Store', 'Japanese Food Restaurants', 'Burger/Sandwich', 'Burger/Sandwich'],\n",
      "    'place_address': ['서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159-9', '서울 서초구 우면동 720', '서울 서초구 방배동 812-2', '서울 서초구 방배동 812-2', '서울 서초구 방배동 812-2', '서울 서초구 서초동 1327', '서울 서\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the data by date and then count the number of visits for each date. We can then sort the results in descending order and select the date with the highest visit count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-07', '2017-12-07', '2017-12-08', '2017-12-11', '2017-12-11', '2017-12-12', '2017-12-13', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-04'],\n",
      "    'hour': [21, 22, 8, 7, 22, 8, 8, 19, 13, 13, 15, 21, 22, 12, 19, 20, 21, 12, 16, 21, 23, 23, 13, 13, 14, 17, 18, 19, 20, 22, 20, 17, 18, 19, 10, 18, 17, 18, 21, 18],\n",
      "    'place_name': ['배스킨라빈스 사당역1호점', '서울5호선 5070', '서울5호선 5009', '서울5호선 5756', '서울5호선 5152', '서울5호선 5072', '서울5호선 5121', '서울5호선 5769', '스타벅스 을지로한국빌딩점', '서울2호선 을지로입구역 외선 7-1', '롯데백화점 본점 /골프/레져/트레디셔널', '봄마다푸름', '서울5호선 영등포구청역 방화행 6-4', '스타벅스 충정로역점', '롯데백화점 본점 /남성패션', '닭한마리 영등포본점', '역전우동0410 화곡역점', 'NC백화점 불광점/반궁 불광점', '서울3호선 홍제역 대화행 8-4 / 오금행 3-1', '스타필드 코엑스몰점 /하동관/JAJU', '서울5호선 광화문역 /상일동마천방면2-2', '서울5호선 을지로4가역 방화행 7-4 / 상일동 마천행 2-1', '서울5호선 애오개역 방화행 2-2', '서울9호선 여의도역 개화 방면 2-4', '베뉴지', '서울5호선 신길역 방화행 4-4', '홍콩반점0410 화곡역점', '메가박스 화곡점', '흑돈연가', '서울1호선 용산역 인천 신창행 9-2', 'CAFE de CONCERT', '서울9호선 가양역 개화 방면 1-1', '글라스스토리 발산역점', '서울5호선 발산역 상일동 마천행 4-4', '서울9호선 여의도역 개화 방면 2-4', 'VIPS CJ푸드월드점', '문어부인삼교비 신도림점', '서울6호선 공덕역 봉화산행 8-4', '서울5호선 공덕역 방화행 3-1 / 상일동 마천행 6-3', '서울5호선 충정로역 방화행 7-3 / 상일동 마천행 2-1'],\n",
      "    'place_category': ['Icecream Shop', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Coffee Shop', 'Subway Station', 'Department Store', 'Coffee Shop', 'Subway Station', 'Coffee Shop', 'Department Store', 'Others(Restaurants)', 'Japanese Food Restaurants', 'Korean Food Restaurants', 'Subway Station', 'Outlet/ Shopping Mall', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Wedding Service', 'Subway Station', 'Chinese Food Restaurants', 'Movie Theater', 'Others(Restaurants)', 'Subway Station', 'Coffee Shop', 'Sub\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31'],\n",
      "    'hour': [14, 13, 13, 14, 17, 20, 15, 9, 9, 18, 19, 20, 20, 22, 19, 19, 20, 22, 22, 9, 10, 11, 11, 11, 11, 15, 15, 19, 19, 20, 20, 20, 22, 22, 23, 19, 22, 14, 18, 15],\n",
      "    'place_name': ['애니벅스 애니학원 강남본점', '서울8호선 가락시장역 암사방면 4-4', 'NATURE REPUBLIC 잠실지하점', '닭도리탕1987', '서울2호선 종합운동장역 외선 3-1', '콩코스PC방 #102052#서울#강남구#대치동', '포그네PC #115129#서울#강남구#일원동', '서울3호선 일원역 대화방면 3-1', '서울3호선 일원역 대화방면 5-1', '서울3호선 양재역 대화방면 7-1', '애니벅스 애니학원 강남본점', '에스프레소 퍼블릭', '애니벅스 애니학원 강남본점', '서울3호선 양재역 오금방면 5-1', '서울8호선 가락시장역 암사방면 6-4', '서울3호선 수서역 오금방면 3-1', '서울8호선 송파역 암사방면 6-4', '서울3호선 수서역 대화방면 9-1', '서울8호선 몽촌토성역 모란방면 5-3', '원종민훼밀리의원 소아과/내과', '서울3호선 일원역 오금방면 5-1', '서울8호선 잠실역 암사방면 4-4', '서울8호선 가락시장역 암사방면 6-4', '서울8호선 가락시장역 암사방면 2-2', '서울8호선 송파역 암사방면 6-4', '서울3호선 가락시장역 대화방면 9-1', 'ARITAUM 신천역점', '분당선 대모산입구역 왕십리방면 3-4', '분당선 수서역 왕십리방면 5-3', '서울7호선 건대입구역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'GS25 S건대입구역점', '서울7호선 건대입구역 부평구청 방면 2-2', '서울7호선 뚝섬유원지역 부평구청 방면 2-2', '맥도날드 강남구청점', '애니벅스 애니학원 강남본점', '서울2호선 2123', '애니벅스 애니학원 강남본점', '서울2호선 2123', '스타필드 코엑스몰점/록시땅 코엑스몰점'],\n",
      "    'place_category\n",
      "['2017-12-10'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. \n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-05', '2017-12-06', '2017-12-07', '2017-12-07', '2017-12-07', '2017-12-07', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-09', '2017-12-09', '2017-12-09', '2017-12-09', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-12', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14'],\n",
      "    'hour': [21, 19, 10, 19, 19, 19, 9, 9, 18, 21, 22, 22, 11, 12, 18, 20, 12, 12, 14, 15, 16, 16, 16, 19, 20, 20, 20, 9, 18, 19, 23, 23, 9, 9, 9, 14, 18, 19, 20, 19],\n",
      "    'place_name': ['분당선 강남구청역 왕십리방면 6-4', '경의중앙선 왕십리역 문산방면 2-2/지평방면 7-3', '분당선 351010', '분당선 351023', '경의중앙선 왕십리역 문산방면 2-2/지평방면 7-3', '경의중앙선 왕십리역 문산방면 1-1/지평방면 8-4', '분당선 강남구청역 수원방면 2-2', '분당선 351012', '분당선 351025', '서울2호선 서초역 외선 5-1', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '분당선 왕십리역 수원방면 6-2', '사랑의치과', '박준뷰티랩 왕십리점', '엔터식스 파크에비뉴한양대점/헬로키티 미치코런던', '아트 PC방 #99935#서울#성동구#행당동', '현대백화점 무역센터점/송', '분당선 351016', '커피빈 공항터미널앞점', '커피빈 공항터미널앞점', '스타필드 코엑스몰점/CUBE', '스타필드 코엑스몰점 /메가박스/씨스페이스/서울무역센터우체국', '스타필드 코엑스몰점/LG유플러스 코엑스몰점', '커피빈 선릉로86길점', '분당선 선릉역 왕십리방면 5-3', '경의중앙선 왕십리역 문산방면 1-1/지평방면 8-4', '분당선 선정릉역 왕십리방면 5-3', '분당선 351033', '뽕나무쟁이족발 대치점', '뽕나무쟁이족발 선릉', '분당선 선릉역 왕십리방면 5-3', '커피빈 선릉로86길점', '분당선 강남구청역 수원방면 2-2', '분당선 351016', '분당선 왕십리역 수원방면 2-2', '현대자동차 언주로대리점', '깐부치킨 강남구청역3번출구점', '탐앤탐스 강남구청역사거리점', '분당선 강남구청역 왕십리방면 5-3', '현대자동차 언주로대리점'],\n",
      "    'place_category': ['Subway Station',\n",
      "['2018-01-02'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column represents the date of each visit log.\n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then identify the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-10', '2017-12-10', '2017-12-11', '2017-12-12', '2017-12-16', '2017-12-17', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-22', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [13, 14, 21, 17, 18, 12, 15, 17, 20, 18, 13, 14, 14, 16, 15, 20, 20, 15, 14, 15, 17, 10, 14, 17, 15, 16, 18, 19, 14, 14, 15, 17, 18, 18, 18, 19, 12, 16, 17, 19],\n",
      "    'place_name': ['파리바게뜨 카페강남중앙점', '서울2호선 강남역 내선 3-1', '롯데슈퍼 대치청실점', '더원학원 학원', '이디야 대치역점', '서울3호선 대치역 대화방면 9-1/오금방면 2-4', '이디야 대치역점', '더원학원 학원', '서울3호선 양재역 오금방면 7-1', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '서울2호선 강남역 내선 3-1', '하나로마트 대치점', '서울3호선 교대역 오금방면 3-1', '이디야 대치역점', '이디야 대치역점', '서울3호선 도곡역 오금방면 5-1', '서울2호선 강남역 내선 3-1', '맥도날드 삼성역점', '메가엠디 강남PEET종합반 전용관', 'CU 강남센타점', '이디야 대치역점', '서울3호선 대치역 대화방면 3-1/오금방면 8-4', '세븐일레븐 대치은마사거리점', '이디야 대치역점', '스타벅스 한티역점', '스타벅스 한티역점', '스타벅스 한티역점', '스타벅스 한티역점', '이디야 대치역점', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점 /원더브라/쥬스스타', '스타필드 코엑스몰점/맥도날드 코엑스점', \"스타필드 코엑스몰점/IT'S SKIN 코엑스점\", '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '이디야 대치역점', '스타필드 코엑스몰점/이마트24 리저브2호점', '현대백화점 무역센터점 /식품/행사장', 'GS25 강남쥬비스점'],\n",
      "    'place_category': ['Bakery', 'Subway Station', 'Supermarket', 'Others(Private Institute)', 'Coffee Shop', 'Subway Station', 'Coffee Shop', 'Others(Private Institute)', 'Subway Station', 'Outlet/ Shopping Mall', 'Subway Station', 'Supermarket', 'Subway Station', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Burger/Sandwich', 'Others(Private Institute)', 'Convenience Store', 'Coffee Shop', 'Subway Station', 'Con\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To do this, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. Finally, we can find the date with the maximum number of visits.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-09', '2017-12-09', '2017-12-10', '2017-12-11', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-16', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [11, 11, 8, 13, 13, 14, 15, 12, 19, 19, 20, 15, 18, 18, 12, 20, 12, 19, 12, 14, 16, 13, 14, 13, 20, 21, 21, 16, 17, 9, 12, 18, 7, 11, 17, 22, 7, 16, 18, 18],\n",
      "    'place_name': ['할리스커피 종로본점', '올리브영 종로YBM점', '서울2호선 신림역 내선 2-3 / 외선 9-2', '공차 시청점', '서내과 내과', '서울2호선 신림역 내선 4-4 / 외선 7-1', '이마트 영등포점/일렉트로마트 영등포점', '할리스커피 세종로점', '서울2호선 잠실역 내선 3-1', 'ASHLEY 서울대입구점', '페리카나 흑석동점', '서울2호선 사당역 외선 3-1', '파르나스몰/아프리카 삼성파르나스몰점', '교동전선생 서소문점', 'COFFE & MORE', 'ARITAUM 서울대역점', '공차 시청점', 'Paul Bassett 코리아나호텔점', '할리스커피 세종로점', '사랑의교회', '서울2호선 사당역 내선 3-1', 'NESCAFE 조선일보점', '이디야 봉천역점', 'Paul Bassett 코리아나호텔점', '스타벅스 서소문로점', '서울2호선 신촌역 외선 9-1', '서울2호선 시청역 내선 3-2 / 외선 8-3', '올리브영 태평로1가점', 'CU 코리아나호텔점', '이디야 세종로점', '커피빈 서울시청뒤남강빌딩점', '서울2호선 시청역 내선 9-1 / 외선 2-4', '서울2호선 신대방역 내선 3-1', '올리브영 세종로점', '올리브영 태평로1가점', '서울2호선 충정로역 내선 4-1 / 외선 7-4', '서울2호선 신림역 내선 2-3 / 외선 9-2', '올리브영 태평로1가점', '서울2호선 시청역 내선 5-2 / 외선 6-3', '서울2호선 아현역 외선 7-1'],\n",
      "    'place_category': ['Coffee Shop', 'Drug Store', 'Subway Station', 'Teahouse', 'Internal Medicine Clinic', 'Subway Station', 'Electronics Shop', 'Coffee Shop', 'Subway Station', 'Western Food Restaurants', 'Chicken', 'Subway Station', 'Optical Store', 'Bar', 'Coffee Shop', 'Cosmetics Shop', 'Teahouse', 'Coffee Shop', 'Coffee Shop', 'Protestant Church', 'Subway Station', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Drug Store', 'Convenience Store', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Drug Store', 'Drug Store', 'Subway Station', 'Subway Station', 'Drug Store', 'Subway Station', 'Subway Station'],\n",
      "    'place_address': ['서울 종로구 종로2가 75-2', '서울 종로구 종로2가 55-1', '서울 관악구 신림동 1467-10', '서울 중구 을지로1가 37', '서울 관악구 청룡동 927-21', '서울 관악구 신림동 1467-10\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the values in this column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the data by date and then count the number of visits for each date. We can then sort the results in descending order and select the date with the highest visit count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({date : ['2017-12-09', '2017-12-09', '2017-12-09', '2017-12-09', '2017-12-11', '2017-12-11', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-12', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04'],hour : [18, 18, 19, 22, 8, 9, 14, 15, 16, 16, 11, 13, 10, 11, 11, 18, 10, 12, 17, 18, 21, 14, 11, 12, 18, 18, 19, 19, 14, 15, 16, 16, 20, 20, 8, 13, 13, 13, 13, 8],place_name : ['서울1호선 영등포역 동인천 천안급행 2-4', '롯데백화점 영등포점 /핸드백구두악세서리보석', 'CU 노량진미도점', '미정국수0410 노량진점', '스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/우리은행 무역센터금융센터점', 'Floravello /꽃/커피', '스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/다이소 코엑스몰점', '스타필드 코엑스몰점/우리은행 무역센터금융센터점', '스타필드 코엑스몰점/우리은행 무역센터금융센터점', '스타필드 코엑스몰점/맥도날드 코엑스점', '서울9호선 노량진역 개화 방면 1-1', '공항철도 김포공항역 / 서울9호선 김포공항역 서울역방면 3-4/종합운동장방면 2-4', '공항철도 김포공항역 / 서울9호선 김포공항역 서울역방면 5-3/종합운동장방면 4-3', '서울9호선 노량진역 종합운동장 방면 2-4', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점/맥도날드 코엑스점', '스타필드 코엑스몰점 /리바이스/MIXXO', '스타필드 코엑스몰점/BUTTER 코엑스점', '파리바게뜨 중앙대점', '마\n",
      "['2017-12-16'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-13', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26'],\n",
      "    'hour': [13, 14, 13, 22, 23, 23, 23, 4, 5, 5, 6, 16, 17, 17, 17, 17, 17, 17, 18, 18, 20, 6, 7, 7, 7, 21, 14, 17, 13, 13, 13, 14, 14, 13, 23, 23, 13, 14, 14, 18],\n",
      "    'place_name': ['히든코인싱어노래연습장', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '분당선 351136', 'NATURE REPUBLIC 강남구청역점', '탐앤탐스 강남구청역사거리점', '던킨도너츠 강남구청역점', '팔당닭발 강남본점/오픈형', '분당선 강남구청역 왕십리방면 5-3', '분당선 351102', '서울2호선 왕십리역 외선 9-1', '서울2호선 아현역 내선 7-1', '현대백화점 무역센터점 /식품/행사장', '스타필드 코엑스몰점/TWORLD 코엑스점', '스타필드 코엑스몰점 /스무디킹/HANS', '스타필드 코엑스몰점 /OYSHO/BUTTER', '스타필드 코엑스몰점 /유니클로/VIVIEN', '파르나스몰 /곤트란쉐리에/지올리띠/파이공장', '스타필드 코엑스몰점 /지오지아/바디프랜드/고디센', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '분당선 선릉역 왕십리방면 3-4', '분당선 강남구청역 왕십리방면 5-3', '분당선 왕십리역 수원방면 6-2', '서울2호선 동대문역사문화공원역 외선 3-1', '서울2호선 왕십리역 외선 3-1', '맥도날드 신촌점', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '버거킹 #연세로점', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '갤러리피시방 #108970#서울#서대문구#창천동', '버거킹 연세로점', '홍콩반점0410 신촌2호점', '히든코인싱어노래연습장', '히든코인싱어노래연습장', '히든코인싱어노래연습장'],\n",
      "    'place_category': ['Karaoke',\n",
      "['2017-12-29', '2017-12-31'] The date with the most visits is 2017-12-31.\n",
      "['2018-01-05'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and determine the date with the highest count.\n",
      "\n",
      "To do this, we can use the pandas groupby function to group the data by the \"date\" column and then use the size() function to count the number of occurrences for each date. Finally, we can use the idxmax() function to find the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [15, 16, 16, 14, 17, 17, 17, 18, 17, 17, 17, 16, 18, 22, 22, 17, 17, 19, 21, 21, 22, 22, 22, 9, 9, 10, 14, 14, 14, 14, 15, 10, 11, 14, 14, 15, 18, 19, 20, 21],\n",
      "    'place_name': ['맥도날드 염창DT점', '서울5호선 김포공항역 방화행 6-4', '서울5호선 5604', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데백화점 김포공항점 /진/유니섹스/스포츠/델리', '롯데백화점 김포공항점 /가정점행사장사은품증정', '롯데몰 김포공항점/올리브영 김포공항점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '서울5호선 김포공항역 상일동 마천행 2-2', '공항철도 김포공항역 / 서울9호선 김포공항역 인천국제공항방면 6-4', '서울5호선 김포공항역 방화행 4-4', '롯데몰 김포공항점/O.S.T 롯데백화점김포공항점', '롯데몰 김포공항점/H&M 롯데백화점김포공항점', 'GS25 방화샤르망점', '서울5호선 5667', 'GS25 방화샤르망점', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/CLUB CLIO 롯데김포몰클럽', '롯데몰 김포공항점/THE BODY SHOP 롯데백화점김포공항점', '롯데\n",
      "['2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] The key feature in the user's visit history that could be useful in answering the question is the \"date\" column. \n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences for each date and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# User's visit history\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [21, 14, 15, 19, 21, 21, 7, 7, 13, 16, 17, 18, 18, 19, 19, 19, 20, 20, 20, 20, 21, 7, 12, 12, 13, 16, 17, 21, 21, 22, 7, 12, 16, 17, 18, 18, 18, 19, 20, 20],\n",
      "    'place_name': ['서울8호선 가락시장역 모란방면 2-2', 'KB국민은행 먹골역지점', '우리은행 태릉역지점', '짬뽕타임 이수점', '서울5호선 5419', '서울7호선 남성역 장암 방면 4-4', '서울7호선 군자역 장암 방면 4-4', '서울5호선 5223', '이디야 묵동자이점', '서울1호선 종로5가역 인천 신창행 5-1', '서울1호선 대방역 인천 신창행 5-1 / 용산급행 6-4', '타임스퀘어/Saint AUGUSTIN 타임스퀘어점', '파리바게뜨 영등포점', '이마트 영등포점 /비식품', '타임스퀘어/UNIQLO 타임스퀘어점', '이마트 영등포점 /식품 외', '세븐일레븐 서초사당역점', '서울2호선 신도림역 출근선 잠실방면 7-1', 'UNIQLO 사당파스텔점', '파리바게뜨 사당파스텔시티점', '서울8호선 잠실역 모란방면 2-2', '서울5호선 아차산역 방화행 6-4', '서울7호선 먹골역 장암 방면 6-4', '롯데리아 먹골역점', '서울6호선 태릉입구역 응암순환행 4-4', '서울1호선 대방역 인천 신창행 5-1 / 용산급행 6-4', '서울6호선 동묘앞역 봉화산행 8-3 / 응암순환행 1-2', '서울4호선 삼각지역 오이도방면 9-1', '서울6호선 한강진역 응암순환행 4-4', '분당선 강남구청역 수원방면 5-3', '서울5호선 5269', '서울6호선 태릉입구역 응암순환행 4-4', '서울1호\n",
      "['2017-12-29'] 2017-12-28\n",
      "['2017-12-21'] The key features of the data that could be useful in answering the question are the 'date' column and the number of visits on each date.\n",
      "\n",
      "To find the date with the most visits, we can group the data by the 'date' column and count the number of occurrences for each date. Then, we can find the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history data\n",
      "visit_history = pd.DataFrame({date : ['2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-25', '2017-12-30'],hour : [14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 16, 14, 14, 9, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 18],place_name : ['스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /빨라쪼/CJFOODWOTLD', '스타필드 코엑스몰점/고디바 코엑스몰점', '스타필드 코엑스몰점/빨라쪼 코엑스몰점', '스타필드 코엑스몰점 /테이스팅룸/봉은사역/카페마미스', '스타필드 코엑스몰점 /Thesimpletable/CJFOODWOTLD', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', 'NATURE REPUBLIC 청담역점', '서울1호선 용산역 소요산행 10-4', '서울1호선 용산역 소요산행 7-1', 'NATURE REPUBLIC 청담역점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/이노아이', '스타필드 코엑스몰점/제너럴반점 코엑스몰점', '스타필드 코엑스몰점/커피빈 도심공항타워점', '스타필드 코엑스몰점/가득드림 코엑스몰점', '스타필드 코엑스몰점/소노야 코엑스몰점', \"스타필드 코엑스몰점/Auntie Anne's 코\n",
      "['2017-12-24'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the following code:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({date : ['2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2018-01-04'],hour : [13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 16, 22, 22, 11, 11, 11, 12, 9, 15, 8, 9, 9, 9, 12, 12, 12, 12, 20, 21, 9, 13, 14, 14, 14, 14, 9],place_name : ['IFC몰/DESIGN SKIN IFC몰점', 'IFC몰/HOT-T 여의도점', 'IFC몰/에잇세컨즈 IFC몰점', 'IFC몰/에잇세컨즈 IFC몰점', 'IFC몰/더플레이스 IFC점', 'IFC몰/장사랑 IFC몰점', 'IFC몰/시마스시 여의도점', 'IFC몰/THE BODY SHOP IFC몰점', 'IFC몰 North Artrium', 'IFC몰/MANGO 여의도IFC몰점', 'IFC몰/FRISBEE 여의도IFC몰점', 'IFC몰/NATURE REPUBLIC 여의도 lFC점', 'IFC몰/오가다 IFC몰점', '공차 여의도역점', 'IFC몰/에잇세컨즈 IFC몰점', 'IFC몰/다름수선 IFC몰점', 'IFC몰 홀', 'IFC몰/커피빈 여의도 IFC몰1호점', 'IFC몰/다름수선 IFC몰점', 'IFC몰/NIKE IFC몰점', 'IFC몰/ALDO IFC몰점', '서울7호선 내방역 부평구청 방면 4-4', '서울7호선 신풍역 장암 방면 4-4', '신한은행 방배중앙지점', '서울7호선 내방역 장암 방면 2-2', '서울7호선 강남구청역 장암 방면 2-2', 'CGV 군자점', '서울7호선 건대입구역 부평구청 방면 2-2', 'CGV 군자점', '서울7호선 군자역 부평구청 방면 2-2', '이마트24 방배레드점', 'GS25 방배제일점', 'GS25 방배제일점', '서울7호선 내방역 부평구청 방면 6-4', '맥도날드 양천구청점', '서울7호선 장승배기역 장암 방면 4-4', 'MISSHA 내방역점', '서울7호선 신풍역 장암 방면 4-4', 'NATURE REPUBLIC 이수역2호점', '벤츠 방배전시장점'],place_category : ['Others(Retail)', 'Shoe Store', 'Clothing Store', 'Clothing Store', 'Western Food Restaurants', 'Korean Food Restaurants', 'Japanese Food Restaurants', 'Cosmetics Shop', 'Outlet/ Shopping Mall', 'Clothing Store', 'Electronics Shop', 'Cosmetics Shop', 'Coffee Shop', 'Teahouse', 'Clothing Store', 'Others(Retail)', 'Outlet/ Shopping Mall', 'Coffee Shop', 'Others(Retail)', 'Clothing Store', 'Shoe Store', 'Subway Station', 'Subway Station', 'Bank', 'Subway Station', 'Subway Station', 'Movie Theater', 'Subway Station', 'Movie Theater', 'Subway Station', 'Convenience Store', 'Convenience Store', 'Convenience Store', 'Subway Station', 'Burger/Sandwich', 'Subway Station', 'Cosmetics Shop', 'Subway Station', 'Cosmetics Shop', 'Automotive Shop'],place_address : ['서울 영등포구 여의도동 23-10', '서울 영등포구 여의도동 23-1', '서울 영등포구 여의도동 23-1', '서울 영등포구 여의도동 23-1', '서울 영등포구 여의도동 23', '서울 영등포구 여의도동 23', '서울 영등포구 여의도동 23-1', '서울\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-23'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [15, 16, 17, 18, 20, 14, 16, 17, 18, 18, 19, 20, 21, 15, 19, 19, 17, 18, 19, 20, 21, 21, 14, 14, 15, 17, 20, 21, 12, 16, 18, 20, 15, 15, 20, 15, 18, 19, 23, 23],\n",
      "    'place_name': ['서울2호선 잠실역 외선 3-1', '서울2호선 종합운동장역 내선 3-1', '8seconds 강남역점', '서울2호선 강남역 외선 7-1', '분당선 복정역 왕십리방면 5-3', '분당선 351331', '서울8호선 복정역 /암사방면2-2', '롯데월드몰/8seconds 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', 'NC백화점 송파점 /선물세트', '서울8호선 장지역 모란방면 4-4', '분당선 351338', '분당선 351224', '분당선 선릉역 수원방면 3-4', '서울8호선 복정역 /암사방면2-2', '롯데월드몰/8seconds 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '롯데월드몰/UNIQLO 롯데월드몰점', '스타필드 코엑스몰점 /자라/아르마니진', '스타필드 코엑스몰점 /플러스에스큐/TNGT/칼하트', '분당선 351327', '서울8호선 복정역 /암사방면2-2', '롯데마트 송파점 /비식품코너', '롯데월드몰/8seconds 롯데월드몰점', '롯데월드몰/ZARA 롯데월드몰점', '분당선 복정역 왕십리방면 5-3', '서울8호선 문정역 모란방면 4-4', 'NC백화점 송파점 /식품관', '분당선 351332', '분당선 351208', '서울8호선 복정역 /암사방면2-2', '서울8호선 복정역 /암사방면3-4', '분당선 복정역 왕십리방면 5-3', '서울8호선 복정역 /암사방면3-4', '서울8호선 가락시장역 모란방면 4-4', '서울8호선 복정역 암사방면 5-3', '서울8호선 가락시장역 모란방면 4-4', '분당선 복정역 왕십리방면 5-3'],\n",
      "    'place_category': ['Subway Station', 'Subway Station', 'Clothing Store', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', 'Clothing Store', 'Clothing Store', 'Clothing Store', 'Clothing Store', 'Department Store', 'Subway Station', 'Subway Train', 'Subway Train', 'Subway Station', 'Subway Station', 'Clothing Store\n",
      "['2017-12-25'] The key feature in the user's visit history that could be useful in answering the question is the \"date\" column. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the data by date and then count the number of occurrences for each date. Finally, we can use the idxmax function to find the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-21', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03'],\n",
      "    'hour': [14, 14, 20, 20, 13, 14, 14, 14, 14, 15, 16, 16, 16, 21, 21, 21, 21, 22, 16, 16, 16, 16, 16, 16, 19, 14, 14, 14, 19, 19, 19, 19, 2, 21, 10, 11, 12, 12, 12, 13],\n",
      "    'place_name': ['서울1호선 가산디지털단지역 신창방면 7-1', '서울1호선 금천구청역 신창방면 9-1', '아이파크몰/롯데리아 용산역사점', '서울2호선 311299', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점 /뽕신/아티제/더플레이스', '스타필드 코엑스몰점/아티제 코엑스몰점', '스타필드 코엑스몰점/포베이 코엑스점', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /D.QUEENS/SAYCHEESE', '서울2호선 교대역 내선 7-1', '스타필드 코엑스몰점/해리메이슨 코엑스몰점', '파르나스몰 /왓슨스', '서울2호선 신림역 내선 9-3 / 외선 2-2', 'KB국민은행 신림9동자동화점', '서울5호선 5129', '서울5호선 영등포구청역 상일동 마천행 2-2', '서울5호선 여의도역 상일동 마천행 / 6-4', '서울2호선 대림역 내선 9-1', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '정관장\n",
      "['2017-12-17'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the following code:\n",
      "\n",
      "``` python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({date : ['2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29'],hour : [13, 17, 17, 17, 13, 15, 15, 16, 16, 16, 16, 16, 16, 16, 18, 19, 11, 12, 21, 12, 21, 14, 14, 14, 14, 14, 15, 15, 14, 15, 8, 8, 13, 12, 18, 19, 20, 21, 23, 13],place_name : ['두꺼비부대찌개', 'GS25 상공회의소점', '정담 상공회의소점', '요나끼 상공회의소점', '루드블랑', '투썸플레이스 강남역중앙점', '투썸플레이스 강남역중앙점', '강남역지하쇼핑센터/CU 서울메트로강남역점', '강남역지하쇼핑센터/오렌즈 강남역 지하쇼핑센터점', 'Vin Prime 강남역점', 'SECRET CODE 깅남본점', 'Vin Prime 강남역점', '투썸플레이스 강남역중앙점', '투썸플레이스 강남역중앙점', 'cafe MAMAS 강남역점', 'cafe MAMAS 강남역점', '벨라프라하 서소문점', '벨라프라하 서소문점', '올리브영 신대방역점', '신한은행 PWMPrivilege서울센터점', 'GS25 신림석류점', '홈플러스 합정점 /식품', '홈플러스 합정점 /비식품', '홈플러스 합정점 /식품', '홈플러스 합정점 /식품', '홈플러스 합정점 /식품', '홈플러스 합정점 /비식품', '홈플러스 합정점 /식품', '보노보노 삼성점', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', '명동분식', 'GS25 상공회의소점', '명동분식', 'GS25 상공회의소점', '예송부대찌개', '예송부대찌개', '예송부대찌개', '예송부대찌개', '노래타운', 'GS25 상공회의소점'],place_category : ['Korean Food Restaurants', 'Convenience Store', 'Coffee Shop', 'Korean Food Restaurants', 'Wedding Service', 'Coffee Shop', 'Coffee Shop', 'Convenience Store', 'Optical Store', 'Clothing Store', 'Theme Cafe', 'Clothing Store', 'Coffee Shop', 'Coffee Shop', 'Western Food Restaurants', 'Western Food Restaurants', 'Coffee Shop', 'Coffee Shop', 'Drug Store', 'Bank', 'Convenience Store', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Discount Department Store', 'Others(Restaurants)', 'Outlet/ Shopping Mall', 'Snack Bar', 'Convenience Store', 'Snack Bar', 'Convenience Store', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Karaoke', 'Convenience Store'],place_address : ['서울 중구 태평로2가 318-1', '서울 중구 남대문로4가 45', '서울 중구 남대문로4가 45', '서울 중구 남대문로4가 45', '서울 종로구 중학동 14', '서울 강남구 역삼동 818-15', '서울 강남구 역삼동 818-15', '서울 강남구 역삼동 858', '서울 강남구 역삼동 858', '서울 강남구 역삼동 820-1', '서울 강남구 역삼동 825-1', '서울 강남구 역삼동 820-1', '서울 강남구 역삼동 818-15', '서울 강남구 역삼동 818-15', '서울 서초구 서초동 1321-6', '서울 서초구 서초동 1321-6', '서울 중구 서소문동 120-11', '서울 중구 서소문동 120-11', '서울 관악구 신림동 518-56', '서울 중구 남대문로4가 45', '서울\n",
      "['2017-12-28', '2018-01-03'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. \n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({date : ['2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04'],hour : [15, 9, 10, 14, 14, 9, 12, 14, 17, 17, 17, 18, 20, 20, 20, 12, 14, 14, 12, 13, 14, 14, 17, 9, 9, 9, 9, 11, 8, 11, 12, 12, 12, 12, 15, 15, 15, 16, 11, 22],place_name : ['롯데마트 잠실점 /비식품코너', '대신 저축은행 잠실', '연치과의원 치과', '잠실눈사람안과', '죠샌드위치 잠실엘스점', '엘스3층약국', '스타벅스 아시아선수촌점', '잠실눈사람안과', '서울3호선 교대역 오금방면 9-1', '서울2호선 강남역 내선 7-1', '서울3호선 교대역 오금방면 7-1', '리앤채움 피부과', '서울2호선 교대역 외선 9-1', '서울3호선 압구정역 오금방면 3-1', '서울3호선 잠원역 오금방면 3-1', '롯데리아 잠실신천점', '상쾌한이비인후과의원 이비인후과', '스타벅스 신천역점', '스타필드 코엑스몰점/THE PLACE 코엑스점', '스타필드 코엑스몰점/THE PLACE 코엑스점', '스타필드 코엑스몰점/브릭라이브카페', '스타필드 코엑스몰점/별마당도서관', '이철헤어커커 잠실신천1호점', '스타필드 코엑스몰점/딥티크 코엑스몰점', '스타필드 코엑스몰점 /씨스페이스/서울무역센터우체국', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '스타필드 코엑스몰점 /빨라쪼/CJ푸드월드/케르반', '천호낙지', '창고43 삼성점', '스타필드 코엑스몰점/샤이바나 코엑스몰점', '스타필드 코엑스몰점 /브릭라이브/아디다스오리지널/아디다스포퍼먼스', '스타필드 코엑스몰점 /나이키/컨버스/리복', '스타필드 코엑스몰점 /아티제/크리스핏도넛/뽕신', '스타필드 코엑스몰점 /고객센터', '잠실눈사람안과', 'CU 서울메트로역삼역점', '서울2호선 역삼역 외선 9-1', '잠실눈\n",
      "['2017-12-08'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-08', '2017-12-11', '2017-12-11', '2017-12-11', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-26', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [12, 13, 14, 15, 16, 17, 18, 18, 21, 22, 22, 22, 16, 16, 16, 8, 10, 9, 10, 8, 20, 8, 9, 12, 21, 17, 8, 11, 14, 15, 16, 18, 9, 10, 10, 11, 19, 8, 11, 23],\n",
      "    'place_name': ['유가네닭갈비 강남역점', \"Cafe Queen's Amore\", \"Cafe Queen's Amore\", \"Cafe Queen's Amore\", \"Cafe Queen's Amore\", '태평성대', '태평성대', '서울1호선 시청역 인천 신창행 5-1', '주전부리', '서울9호선 여의도역 개화 방면 4-4', '서울9호선 당산역 개화방면 2-2/종합운동장방면 3-3', '서울9호선 노량진역 개화 방면 4-4', '서울9호선 선정릉역 개화 방면 1-1', '서울9호선 신논현역 개화 방면 1-1', '서울9호선 봉은사역 개화 방면 1-1', '서울2호선 강남역 외선 9-1', '포시즌플러스', '꽃마을 치과 /치과', '꽃마을 치과 /치과', 'GS25 S강남역1호점', 'REFESH COFFEE&JUICE', '서울2호선 강남역 외선 9-1', '우리부동산', '파스쿠찌 신분당강남역점', '강남역지하쇼핑센터/O-LENS 강남역지하쇼핑센터점', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 강남역 외선 9-1', '포시즌플러스', '김한성성형외과', '서울2호선 교대역 외선 9-1', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '한탕 홍대본점', '서울2호선 서울대입구역 내선 5-2 / 외선 6-2', '디에이 성형외과 피부과 /성형외과 /피부과', '디에이성형외과 성형외과/피부과', '디에이 성형외과 피부과 /성형외과 /피부과', '아셈한의원 한의원', '서울2호선 강남역 외선 9-1', '포시즌플러스', '서울2호선 삼성역 내선 3-1 / 외선 8-4'],\n",
      "    'place_category': ['Korean Food Restaurants', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Subway Station', 'Others(Alchoholic Beverages)', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Dental Clinic', 'Dental Clinic', 'Convenience Store', 'Coffee Shop', 'Subway Station', 'Real Estate Agency', 'Coffee Shop', 'Optical Store', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Plastic Surgery Clinic', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Subway Station', 'Plastic Surgery Clinic', 'Plastic Surgery Clinic', 'Plastic Surgery Clinic', 'Oriental Medical Clinic', 'Subway Station', 'Korean Food Restaurants', 'Subway Station'],\n",
      "    'place_address': ['서울 강남구 역삼동\n",
      "['2017-12-22'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date in the \"date\" column and identify the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-20', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [14, 15, 16, 17, 13, 11, 12, 13, 13, 14, 15, 16, 17, 14, 15, 16, 17, 14, 15, 16, 17, 11, 12, 12, 13, 14, 11, 13, 14, 15, 16, 17, 10, 11, 12, 13, 14, 15, 10, 11],\n",
      "    'place_name': ['스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '투썸플레이스 차병원사거리점', '스타벅스 신천역점', '스타벅스 신천역점', '투썸플레이스 잠실신천점', '스타벅스 신천역점', '투썸플레이스 잠실신천점', '투썸플레이스 잠실신천점', '투썸플레이스 잠실신천점', '투썸플레이스 잠실신천점', '할리스커피 교대역점', '할리스커피 교대역점', '할리스커피 교대역점', '할리스커피 교대역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '헤어그라피 센트럴시티점', '스타벅스 센트럴시티점', '헤어그라피 센트럴시티점', '스타벅스 센트럴시티점', '스타벅스 센트럴시티점', '이디야 종합운동장역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '스타벅스 신천역점', '이디야 종합운동장역점', '이디야 종합운동장역점'],\n",
      "    'place_category': ['Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Hair Salon', 'Coffee Shop', 'Hair Salon', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop'],\n",
      "    'place_address': ['서울 송파구 잠실동 181', '서울 송파구 잠실동 181', '서울 송파구 잠실동 181', '서울 송파구 잠실동 181', '서울 강남구 논현동 234-28', '서울 송파구 잠실동 181', '서울 송파구 잠실동 181', '서울 송파구 잠실동 177-3', '서울 송파구 잠실동 181', '서울 송파구 잠실동 177-3', '서울 송파구 잠실동 177-3', '서울 송파구 잠실동 177-3', '서울 송파구 잠실동 177-3', '서울 서초구 서초동 1573-14번지', '서울 서\n",
      "['2018-01-04'] 2017-12-31\n",
      "['2017-12-21'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-29', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [11, 12, 18, 20, 21, 12, 9, 12, 22, 22, 11, 11, 12, 14, 19, 20, 12, 15, 21, 22, 1, 5, 13, 12, 16, 9, 11, 11, 9, 13, 13, 19, 21, 9, 12, 20, 9, 19, 20, 22],\n",
      "    'place_name': ['뉴코아아울렛 강남점 2관/Cafe Lugo 반포점', '로봇김밥 삼성동점', '청주본가 삼성점/왕갈비탕', '대청마루I', '청솔오리', '삼성한방삼계탕', '서울3호선 동대입구역 대화방면 5-1/오금방면 6-4', '스타필드 코엑스몰점/메이 코엑스몰점', '국화 /분식', '서울3호선 압구정역 대화방면 9-1', '우체국 서울무역센터우체국', '현대백화점 무역센터점 /럭셔리부티크', '스타필드 코엑스몰점/포베이 코엑스점', '올리브영 봉은사역점', '스타필드 코엑스몰점 /고객센터', '스타필드 코엑스몰점/탑텐 코엑스몰점', '가츠몽 삼성점', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '청솔오리', '청솔오리', '코인노래연습장', '신선설농탕 이태원점', '서울9호선 동작역 개화행 2-2', '스타필드 코엑스몰점/켈리포니아키친 코엑스점', '아이파크몰/롯데리아 용산역사점', '서울9호선 신논현역 종합운동장 방면 2-4', '스타벅스 동대입구역점', '돈돈돈까스', '서울3호선 동대입구역 대화방면 5-1/오금방면 6-4', '스타필드 코엑스몰점/대가집 코엑스몰점/도심공항타워', '롯데마이슈퍼 코엑스점', '가츠몽 삼성점', '서울3호선 고속터미널역 대화방면 5-1', '서울3호선 동대입구역 대화방면 5-1/오금방면 6-4', '스타필드 코엑스몰점 /라에스키모/GODIVA', '서울3호선 고속터미널역 대화방면 5-1', '서울3호선 옥수역 대화방면 3-1', '서울9호선 봉은사역 개화 방면 4-4', '썸ing', '강남역지하쇼핑센터/Golden Bell'],\n",
      "    'place_category': ['Coffee Shop', 'Sn\n",
      "['2017-12-17', '2017-12-23'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the dataframe by the \"date\" column and then count the number of occurrences for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-14', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-25'],\n",
      "    'hour': [19, 9, 6, 10, 12, 14, 14, 15, 17, 18, 19, 6, 11, 11, 12, 21, 19, 20, 20, 21, 22, 22, 5, 2, 12, 4, 7, 11, 12, 18, 19, 3, 6, 17, 18, 18, 18, 19, 17, 17],\n",
      "    'place_name': ['다이소 대방남부점', '예스자이엘라부동산', '예스자이엘라부동산', '예스자이엘라부동산', '예스자이엘라부동산', '서울1호선 대방역 소요산행 9-1', 'IFC몰/CGV 여의도점/4,7관입구', 'IFC몰/CGV 여의도점/8-9관입구', 'IFC몰/올리브마켓 여의도IFC몰점', '칸느치킨', '칸느치킨', '서울1호선 대방역 소요산행 7-1', '정관장 트윈타워점', 'GS25 트윈타워점', 'GS25 트윈타워점', 'GS25 여의도자이점', '은행골 영등포점/초밥참치', '은행골 영등포점/초밥참치', '마더스연세치과', '은행골 영등포점/초밥참치', 'TWORLD PS&M영등포역점', '다이소 영등포본점', '예스자이엘라부동산', '예스자이엘라부동산', 'GS25 트윈타워점', '예스자이엘라부동산', '서울1호선 대방역 소요산행 7-1', 'GS25 트윈타워점', 'GS25 트윈타워점', '서울1호선 대방역 소요산행 7-1', '예스자이엘라부동산', '예스자이엘라부동산', '예스자이엘라부동산', '서울1호선 대방역 인천 신창행 6-4 / 용산급행 5-1', '서울2호선 신도림역 내선 4-4 / 외선 7-1', '서울1호선 신도림역 인천•신창방면 3-1(급행)/소요산방면 10-2(급행)', '서울1호선 311148', '서울1호선 대방역 동인천 천안급행 5-1', 'LG유플러스 영등포직영점', 'LG유플러스 영등포직영점'],\n",
      "    'place_category': ['Household Goods', 'Real Estate Agency', 'Real Estate Agency', 'Real Estate Agency', 'Real Estate Agency', 'Subway Station', 'Movie Theater', 'Movie Theater', 'Grocery Store', 'Chicken', 'Chicken', 'Subway Station', 'Health Additive Food Store', 'Convenience Store', 'Convenience Store', 'Convenience Store', 'Others(Restaurants)', 'Others(Restaurants)', 'Dental Clinic', 'Others(Restaurants)', 'Mobile Phone Shop', 'Household Goods', 'Real Estate Agency', 'Real Estate Agency', 'Convenience Store', 'Real Estate Agency', 'Subway Station', 'Convenience Store', 'Convenience Store', 'Subway Station', 'Real Estate Agency', 'Real Estate Agency', 'Real Estate Agency', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', '\n",
      "['2017-12-10', '2017-12-26'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the following code:\n",
      "\n",
      "``` python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the visit history dataframe\n",
      "visit_history = pd.DataFrame({date : ['2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-12', '2017-12-13', '2017-12-14', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05'],hour : [19, 19, 22, 22, 12, 12, 19, 19, 23, 19, 8, 12, 13, 13, 20, 8, 8, 15, 18, 18, 15, 8, 8, 19, 19, 8, 8, 8, 20, 15, 16, 16, 16, 8, 22, 8, 8, 20, 20, 8],place_name : ['파르나스몰/18번완당명가', '스타필드 코엑스몰점/TWEE 코엑스몰점', '서울2호선 낙성대역 외선 9-2', '서울3호선 교대역 오금방면 5-1', '육족장', '복숭아꽃살구꽃', '서울2호선 교대역 내선 5-1', '서울2호선 신도림역 출근선 잠실방면 5-1', '삼우숯불바베큐', '제오헤어 서울대입구역점', '서울2호선 서울대입구역 내선 9-2 / 외선 2-3', '파파이스 역삼점', '스타벅스 구역삼사거리점', '소마로 역삼점', 'NB story Hair', '서울2호선 서울대입구역 내선 9-2 / 외선 2-3', '더뮤즈', '푸룬PC클럽 /88669/서울/관악구/봉천동', '왕돈가스왕냉면', '휴대폰 똥값', '서울2호선 사당역 내선 3-1', '서울2호선 서울대입구역 내선 3-2 / 외선 8-2', '세븐일레븐 역삼프레스티점', '서브웨이 서울대점', '서울2호선 강남역 내선 3-1', '서울2호선 사당역 외선 3-1', '파리바게뜨 역삼스타점', '서울2호선 서울대입구역 내선 9-2 / 외선 2-3', '장호왕곱창 역삼점', '서울2호선 강남역 내선 7-1', '롯데시네마 서울대입구점', '쟝블랑제리', '버거킹 낙성대역점', '서울2호선 서울대입구역 내선 9-2 / 외선 2-3', '디초콜릿커피앤드 논현역점', '서울2호선 서울대입구역 내선 9-2 / 외선 2-3', '서울2호선 강남역 외선 3-1', '서울2호선 서울대입구역 내선 5-2 / 외선 6-2', '서브웨이 서울대점', '강남역지하쇼핑센터/배스킨라빈스 강남역사점'],place_category : ['Snack Bar', 'Clothing Store', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Bar', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Hair Salon', 'Subway Station', 'Burger/Sandwich', 'Coffee Shop', 'Korean Food Restaurants', 'Hair Salon', 'Subway Station', 'Clothing Store', 'PC Cafe', 'Korean Food Restaurants', 'Mobile Phone Shop',\n",
      "['2017-12-27'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to find the date with the most visits.\n",
      "\n",
      "To determine the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then find the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-17', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [13, 19, 19, 8, 13, 19, 9, 12, 14, 23, 23, 11, 14, 15, 16, 19, 16, 16, 19, 19, 19, 20, 20, 20, 12, 16, 18, 19, 9, 9, 9, 12, 12, 13, 18, 23, 23, 19, 20, 22],\n",
      "    'place_name': ['롯데리아 월드점', '스타필드 코엑스몰점/가득드림 코엑스몰점', '스타필드 코엑스몰점 /본우리밥상/스시한판/흑백홍', 'CU 대치플러스점', 'MMTH COFFEE 포스코사거리점', '스타필드 코엑스몰점 /본우리밥상/스시한판/흑백홍', '메가박스 강남점', 'ASHLEY 강남2호점', 'MISSHA 강남역점', 'GS25 청담삼익점', '영동순대국', 'VIPS 청담점', '도미노피자 청담점', '영동순대국', 'GS25 대치대명점', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점', '파리바게뜨 삼성카페점', 'GS25 대치대명점', 'GS25 오크우드점', '스타필드 코엑스몰점/메이 코엑스몰점', '스타필드 코엑스몰점/가득드림 코엑스몰점', '스타필드 코엑스몰점/메이 코엑스몰점', '스타필드 코엑스몰점/쇼군라멘', '스타필드 코엑스몰점/테이스팅룸 코엑스몰', '투썸플레이스 포스코사거리점', 'NATURE REPUBLIC 잠실역사점', '석기정 삼성점', '스타필드 코엑스몰점/가득드림 코엑스몰점', '롯데리아 월드점', '투썸플레이스 잠실롯데점', '공항철도 2220', '롯데리아 월드점', '자연별곡 잠실웰빙점', '교동전선생 삼성2호점', '스타노래연습장', '부산아지매국밥 포스코사거리점', '스타노래연습장', 'VIPS 청담점', '복만루', 'GS25 청담삼익점'],\n",
      "    'place_category': ['Burger/Sandwich', 'Others(Restaurants)', 'Outlet/ Shopping Mall', 'Convenience Store', 'Coffee Shop', 'Outlet/ Shopping Mall', 'Movie Theater', 'Western Food Restaurants', 'Cosmetics Shop', 'Convenience Store', 'Korean Food Restaurants', 'Western Food Restaurants', 'Pizza', 'Korean Food Restaurants', 'Convenience Store', 'Others(Restaurants)', 'Bakery', 'Convenience Store', 'Convenience Store', 'Juice Shop', 'Others(Restaurants)', 'Juice Shop', 'Japanese Food Restaurants', 'Western Food Restaurants', 'Coffee Shop', 'Cosmetics Shop', 'Korean Food Restaurants', 'Others(Restaurants)', 'Burger/Sandwich', 'Coffee Shop', 'Subway Train', 'Burger/Sandwich', 'Korean Food Restaurants', 'Bar', 'Karaoke', 'Korean Food Restaurants', 'Karaoke', 'Western Food Restaurants', 'Others(Restaurants)', 'Convenience Store'],\n",
      "    'place_address': ['서울 송파구 잠실동 40-1번지', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159-9', '서울 강남구 대치동 943-8', '서울 강남구 대치동 942-17', '서울 강남구 삼성동 159\n",
      "['2017-12-15', '2017-12-16', '2017-12-23', '2017-12-26', '2017-12-29'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column indicates the date of each visit log.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history data, the date with the most visits is \"2017-12-23\".\n",
      "['2017-12-31', '2018-01-02', '2018-01-05'] The date with the most visits is 2017-12-31.\n",
      "['2018-01-05'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column indicates the date of each visit log. \n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history data, the date with the most visits is \"2018-01-05\".\n",
      "['2017-12-29'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column indicates the date of each visit log.\n",
      "\n",
      "To find the date with the most visits, we can count the number of visits for each date and then identify the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-22', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [19, 0, 10, 10, 10, 10, 22, 22, 22, 9, 10, 10, 22, 22, 22, 10, 10, 19, 9, 10, 10, 10, 17, 18, 18, 19, 10, 11, 11, 22, 22, 10, 22, 10, 16, 22, 22, 10, 22, 22],\n",
      "    'place_name': ['미성양꼬치 삼성점', 'GS25 봉천낙성점', '서울2호선 역삼역 외선 5-1', '분당선 선릉역 왕십리방면 6-4', 'GS25 S9삼성중앙역점', '서울9호선 선정릉역 종합운동장 방면 2-4', '서울9호선 삼성중앙역 개화 방면 2-4', '서울2호선 선릉역 내선 5-1', '경의중앙선 수색역 서울역발 문산행 2-2', '서울2호선 사당역 외선 7-1', '분당선 선릉역 왕십리방면 6-4', '서울9호선 선정릉역 종합운동장 방면 1-1', '서울2호선 선릉역 내선 5-1', '서울9호선 삼성중앙역 개화 방면 2-4', '경의중앙선 수색역 지평방면 6-4', '서울9호선 선정릉역 종합운동장 방면 1-1', '분당선 선릉역 왕십리방면 6-4', '진대감 삼성점', '서울2호선 사당역 외선 7-1', 'GS25 S9삼성중앙역점', '분당선 선릉역 왕십리방면 6-4', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드 코엑스몰점/OYSHO', '파르나스몰 /코나야/토마틸로/더플라잉팬', '파르나스몰/GIORDANO WOMEN', '스타벅스 스타필드코엑스몰점', '서울2호선 낙성대역 외선 7-1', '분당선 선릉역 왕십리방면 6-4', '서울9호선 선정릉역 종합운동장 방면 2-4', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 사당역 내선 3-1', '서울2호선 교대역 외선 7-1', '서울9호선 종합운동장역 (완행)종합운동장 방면 1-1 / 개화 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타벅스 삼성현대힐점', '분당\n",
      "['2017-12-30', '2017-12-19'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the data by date and then count the number of visits for each date. We can then sort the results in descending order and select the date with the highest visit count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-17', '2017-12-18', '2017-12-18', '2017-12-20', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05'],\n",
      "    'hour': [11, 19, 21, 19, 13, 14, 16, 19, 21, 13, 13, 15, 16, 12, 15, 16, 17, 18, 18, 18, 20, 21, 11, 12, 17, 18, 21, 15, 15, 17, 20, 21, 13, 13, 15, 17, 17, 17, 22, 17],\n",
      "    'place_name': ['cafe MAMAS 청계천점', '메이퓨어의원 /피부과', '서울2호선 2086', '메이퓨어의원 /피부과', '서울2호선 2003', '스타필드 코엑스몰점 /잠바주스/안내데스크/지오다노', '스타필드 코엑스몰점 /잠바주스/안내데스크/지오다노', '스타필드 코엑스몰점 /뽕신/더플레이스/잠바주스', '서울2호선 2018', '서울2호선 2069', '메이퓨어의원 /피부과', '서울2호선 2092', '서울1호선 311669', 'IFC몰/유니클로 IFC몰점', 'IFC몰/스타벅스 여의도IFC몰(B3)점', 'IFC몰/MANGO 여의도IFC몰점', 'IFC몰/Aesop IFC서울점', '서울9호선 여의도역 개화 방면 1-1', '서울2호선 당산역 내선 3-1', '메이퓨어의원 /피부과', '서울2호선 2795', '서울7호선 대림역 장암 방면 4-4', '서울1호선 311065', '서울4호선 4513', '움트', '메이퓨어의원 /피부과', '서울2호선 2464', '서울7호선 7010', '서울1호선 311117', '서울1호선 311087', '현대백화점 디큐브시티점 /유플렉스 외', '현대백화점 디큐브시티점 /식품관 외', '메이퓨어의원 /피부과', 'Paul Bassett 홍대입구역점', 'Paul Bassett 홍대입구역점', '서울1호선 311314', '서울7호선 7537', '서울2호선 2063', '서울2호선 2684', '서울1호선 311455'],\n",
      "    'place_category': ['Western Food Restaurants', 'Dermatology Clinic', 'Subway Train', 'Dermatology Clinic', 'Subway Train', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Subway Train', 'Subway Train', 'Dermatology Clinic', 'Subway Train', 'Subway Train', 'Clothing Store', 'Coffee Shop', 'Clothing Store', 'Soap/Perfumery Store', 'Subway Station', 'Subway Station', 'Dermatology Clinic', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Train', 'Coffee Shop', 'Dermatology Clinic', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Department Store', 'Department Store', 'Dermatology Clinic', 'Coffee Shop', 'Coffee Shop', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train'],\n",
      "    'place_address': ['서울 중구 수하동 67', '서울 마포구 동교동 158-1', '서울 중구 봉래동2가 122-21', '서울 마포구 동교동 158-1', '서울 중구 봉래동2가 122-21', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159-9', '서울 강남구 삼성동 159-9', '서울 중구 봉래동2가 122-21', '서울 중구 봉래동2가 122-21', '서울 마포구 동교동 158\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-29'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column represents the date of each visit log.\n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then identify the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-23', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [14, 13, 16, 13, 14, 21, 12, 15, 16, 18, 12, 16, 12, 15, 17, 7, 7, 10, 13, 14, 14, 18, 22, 23, 23, 12, 13, 15, 18, 14, 15, 15, 17, 12, 13, 17, 20, 20, 11, 18],\n",
      "    'place_name': ['THE PLACE 서울스퀘어점', '헤어메이드', '스타벅스 수유역점', '스타필드 코엑스몰점/CJ푸드월드 코엑스몰점/방콕9/비비고/차이나팩토리/제일제면소/투썸플레이스', '스타필드 코엑스몰점/스타벅스 코엑스몰점', '스타벅스 천호로데오점', 'YES 당구장 /당구장', 'KB국민은행 서초남지점', '복돈이부추삼겹살 사당본점', 'YES 당구장 /당구장', '서초공업사 /현대자동차수리점', '서울8호선 잠실역 암사방면 2-2', 'YES 당구장 /당구장', 'YES 당구장 /당구장', '스타벅스 남부터미널2점', '서울8호선 암사역 모란방면 2-2', '서울2호선 종합운동장역 내선 9-1', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 안국점', '서울3호선 안국역 대화행 7-1 / 오금행 4-4', 'YES 당구장 /당구장', '서울3호선 남부터미널역 대화방면 5-1', '스타벅스 마로니에공원점', 'GS25 암사역점', '서울8호선 천호역 암사방면 2-2', 'CGV 하계점', '스타벅스 신당역사거리점', '충무아트홀 대극장', '투썸플레이스 강변CGV점', '독도쭈꾸미 본점', '이마트 천호점', '스타벅스 천호로데오점', '백두산사우나', '롯데마트 강변점 /식품/비식품', '투썸플레이스 강변CGV점', '양촌리', '서울8호선 천호역 암사방면 2-2', '서울5호선 길동역 방화행 2-2', 'CGV 강변점', 'NATURE REPUBLIC 잠실지하점'],\n",
      "    'place_category': ['Western Food Restaurants', 'Hair Salon', 'Coffee Shop', 'Others(Restaurants)', 'Coffee Shop', 'Coffee Shop', 'Billiard', 'Bank', 'Korean Food Restaurants', 'Billiard', 'Others(Retail)', 'Subway Station', 'Billiard', 'Billiard', 'Coffee Shop', 'Subway Station', 'Subway Station', 'Subway Station', 'Coffee Shop', 'Subway Station', 'Billiard', 'Subway Station', 'Coffee Shop', 'Convenience Store', 'Subway Station', 'Movie Theater', 'Coffee Shop', 'Others(Art Performing Center)', 'Coffee Shop', 'Korean Food Restaurants', 'Discount Department Store', 'Coffee Shop', 'Others(Retail)', 'Discount Department Store', 'Coffee Shop', 'Others(Restaurants)', 'Subway Station', 'Subway Station', 'Movie Theater', 'Cosmetics Shop'],\n",
      "    'place_address': ['서울 중구 남대문로5가 541', '서울 강동구 암사동 502-5', '서울 강북구 번동 418-18', '서울 강남구 삼성동159', '서울 강남구 삼성동 159', '서울 강동구 천호동 453-14', '서울 서초구 서초동 1579-6', '서울 서초구 서초동 1532-9', '서울 관악구 남현동 1061-12', '서울 서초구 서\n",
      "['2017-12-26'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the \"date\" column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and then identify the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-16', '2017-12-16', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04'],\n",
      "    'hour': [12, 13, 18, 18, 18, 18, 18, 19, 21, 21, 22, 23, 23, 23, 23, 23, 10, 17, 16, 17, 17, 13, 13, 13, 13, 15, 9, 13, 13, 13, 13, 14, 15, 15, 15, 15, 11, 16, 16, 16],\n",
      "    'place_name': ['공항철도 공덕역 인천국제공항방면 2-2', '공항철도 공덕역 인천국제공항방면 3-4', '서울4호선 동대문역사문화공원역 당고개방면 5-1/오이도방면 6-4', '서울5호선 5765', '서울5호선 신금호역 방화행 2-2', '서울4호선 삼각지역 오이도방면 7-1', '동호상회', '동호상회', '스타벅스 사당역점', '동호상회', '스타벅스 사당역점', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울4호선 사당역 당고개방면 9-1/오이도방면 2-4', '서울5호선 5338', '서울5호선 청구역 방화행 7-2 / 상일동 마천행 2-2', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '분당선 351422', '경의중앙선 용산역 지평행 4-4', '스타벅스 왕십리역점', '스타벅스 왕십리역점', '김밥사랑', 'CJ푸드월드 제일제당센터점', '서울5호선 5003', '서울5호선 동대문역사문화공원역 방화행 4-4 / 상일동 마천행 5-1', '서울5호선 동대문역사문화공원역 방화행 7-3 / 상일동 마천행 2-2', '뚜레쥬르 제일제당사옥점', '더킹스', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '스타필드 코엑스몰점/OYSHO', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /OYSHO/BUTTER', '현대백화점 무역센터점 /식당가/에메랄드홀', '현대백화점 무역센터점 /식품/행사장', '현대백화점 무역센터점 /해외패션/화장품/잡화', '경의중앙선 왕십리역 문산방면 4-3/지평방면 5-2', '파르나스몰 /마리메꼬/곤트란쉐리에', '대풍약국', '참다한 행당\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-13', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2018-01-02', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05'],\n",
      "    'hour': [11, 8, 8, 19, 21, 8, 8, 8, 11, 21, 15, 15, 16, 18, 21, 0, 17, 19, 1, 18, 18, 19, 21, 18, 19, 21, 22, 0, 12, 14, 14, 14, 20, 20, 19, 11, 22, 22, 23, 11],\n",
      "    'place_name': ['GS25 LG유플러스 용산사옥점', '서울9호선 염창역 개화 방면 1-1', '서울9호선 고속터미널역 개화 방면 2-4', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '라스키친', '서울9호선 염창역 개화 방면 1-1', '서울3호선 양재역 대화방면 5-1', '서울9호선 고속터미널역 개화 방면 2-4', 'LG유플러스 증미역직영점', '통속으로', '서울6호선 삼각지역 봉화산행 7-1 / 응암순환행 2-4', '서울6호선 공덕역 응암순환행 2-2', '마포진짜원조최대포', '다락방화로구이', '깐부치킨 삼성점', '청담이상 삼성점', '서울2호선 사당역 외선 7-1', '꿀잼코믹스 만화카페', '스타벅스 역삼포스코점', '경의중앙선 망우역 문산방면 6-4', '서울9호선 선정릉역 개화 방면 1-1', '강남부동산', 'hans어학원', '서울4호선 이촌역 오이도방면 3-1', '서울2호선 사당역 외선 7-1', 'Art Billiard Club', '깐부치킨 서초삼성타운점', '신분당선 강남역 광교방면 2-2', '현대백화점 디큐브시티점 /리빙 외', '현대백화점 디큐브시티점 /화장품패션잡화SPA', '서울1호선 신도림역 소요산방면 10-4', '현대백화점 디큐브시티점 /화장품 외', '서울1호선 신도림역 소요산방면 10-4', '홈플러스 신도림점 /식품 외', '손문 대구막창갈매기살 용산점', 'GS25 LG유플러스 용산사옥점', '서울4호선 이촌역 오이도방면 5-1', '서울2호선 사당역 외선 7-1', '신분당선 양재역 광교방면 6-4', 'GS25 LG유플러스 용산사옥점'],\n",
      "    'place_category': ['Convenience Store', 'Subway Station', 'Subway Station', 'Movie Theater', 'Bar', 'Subway Station', 'Subway Station', 'Subway Station', 'Mobile Phone Shop', 'Others(Alchoholic Beverages)', 'Subway Station', 'Subway Station', 'Korean\n",
      "['2017-12-25'] 2017-12-24\n",
      "['2017-12-27'] 2017-12-19\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and identify the date with the highest count.\n",
      "\n",
      "To solve this, we can use the pandas library to group the data by the \"date\" column and then count the number of occurrences for each date. Finally, we can select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [18, 19, 15, 15, 15, 19, 17, 9, 9, 9, 9, 16, 11, 12, 13, 14, 20, 10, 17, 17, 11, 16, 11, 19, 10, 12, 15, 21, 17, 17, 17, 9, 10, 15, 19, 19, 19, 15, 21, 22],\n",
      "    'place_name': ['파리바게뜨 신도림역점', '파리바게뜨 신도림역점', '서울9호선 여의도역 종합운동장 방면 1-1', '서울4호선 동작역 오이도행 9-1', '서울9호선 국회의사당역 개화 방면 4-4 / 종합운동장 방면 1-1', '서울4호선 사당역 당고개방면 5-1/오이도방면 6-4', '서울1호선 동대문역 소요산행 7-1', '서울1호선 동대문역 인천 신창행 3-1', '서울5호선 광화문역 /방화방면8-4', '서울1호선 종로3가역 인천 신창행 5-1', '서울5호선 종로3가역 방화행 7-1 / 상일동 마천행 2-3', '서울1호선 동대문역 소요산행 5-1', '우리게임장', '미스터피자 대학로점', '스타벅스 대명거리점', '스위트카페 안암점', 'RedCups 고대점', '서울9호선 여의도역 개화 방면 1-1', '서울9호선 노들역 종합운동장 방면 1-1', '엔제리너스 사당역점', '더닥향기 김명자굴국밥', '서울9호선 국회의사당역 개화 방면 4-4 / 종합운동장 방면 1-1', '서울4호선 동대문역 당고개방면 4-1/오이도방면 7-3', '서울2호선 용답역 지선 신설동행 1-4', '서울5호선 5222', '이태리가구 흙&돌침대', '통툰', '고른햇살', '서울1호선 신도림역 인천/신창방면 7-1', '서울2호선 신도림역 내선 4-4 / 외선 7-1', '서울9호선 당산역 개화방면 4-4/종합운동장방면 1-1', '서울1호선 동대문역 인천 신창행 3-1', '서울9호선 국회의사당역 개화 방면 1-1 / 종합운동장 방면 4-4', '서울2호선 신도림\n",
      "['2018-01-01'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the data by date and then count the number of occurrences for each date. We can then sort the results in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02'],\n",
      "    'hour': [23, 23, 16, 18, 19, 19, 19, 20, 18, 18, 19, 19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 0, 17, 18, 18, 18, 19, 19, 20, 20, 20, 20, 21, 21, 22, 15, 15, 15, 15, 15],\n",
      "    'place_name': ['서울1호선 용산역 소요산행 9-1', '서울1호선 동대문역 소요산행 8-4', '서울1호선 311090', '서울4호선 이촌역 당고개방면 5-1', 'BEE CHENG HIANG', '서울4호선 명동역 당고개방면 7-1/오이도방면 4-4', 'Innisfree 명동2가점', '금강한의원', '서울2호선 신설동역 지선 성수행 2-1', '서울2호선 용두역 지선 성수행 2-1', '서울9호선 봉은사역 개화 방면 4-4', '서울9호선 종합운동장역 (급행)김포공항 방면 2-4/ 종합운동장 방면 2-4', '스타필드 코엑스몰점 /뮤젤/아쿠아리움/한얼공예', '흑돈가 삼성점', '스타필드 코엑스몰점 /위니비니/아쿠아리움/온오프', '흑돈가 삼성점', '스타필드 코엑스몰점 /재동/메이/홍대돈부리', '서울9호선 봉은사역 개화 방면 4-4', '서울9호선 노량진역 개화 방면 4-4', '스타필드 코엑스몰점 /스타벅스/명동칼국수/쇼군라멘', '커피빈 종로YMCA점', 'Innisfree 종로점', '서울2호선 신설동역 지선 성수행 4-1', '파르나스몰 /커피빈(CBTL)/센트럴라운지', '서울2호선 신설동역 지선 성수행 2-1', '파르나스몰 /코나야/더플라잉팬', '파르나스몰/GS25 파르나스타워점', '파르나스몰/MUJI 파르나스몰점', '스타필드 코엑스몰점 /재동/메이/고와꽃방', '롯데월드몰/SEOUL SKY /전망대', '서울2호선 종합운동장역 외선 3-1', '서울9호선 봉은사역 종합운동장 방면 4\n",
      "['2018-01-03', '2018-01-05'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and identify the date with the highest count.\n",
      "['2018-01-03', '2018-01-05'] The key feature in the provided visit history data is the \"date\" column. To find the date with the most visits, we need to count the occurrences of each date and determine the date with the highest count.\n",
      "\n",
      "To do this, we can use the pandas groupby function to group the data by the \"date\" column and then use the size() function to count the number of occurrences for each date. Finally, we can use the idxmax() function to find the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [8, 8, 10, 16, 17, 9, 11, 14, 14, 9, 10, 20, 21, 9, 18, 20, 9, 10, 11, 18, 15, 15, 16, 17, 10, 19, 20, 9, 9, 10, 20, 20, 20, 10, 9, 10, 11, 13, 19, 21],\n",
      "    'place_name': ['현대백화점 무역센터점 /영캐주얼', '서울2호선 2170', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '서울2호선 2129', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '파르나스몰/코나야 삼성파르나스몰점', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '서울2호선 2961', '서울2호선 2861', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '서울2호선 2889', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '파스쿠찌 골든타워점', '스타필드 코엑스몰점/판도라 코엑스몰점', '스타필드 코엑스몰점/이마트24 리저브2호점', 'GS25 강남동원점', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '서울2호선 2577', '서울2호선 2866', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', 'GS25 행운중앙점', '서울2호선 2374', '서울2호선 2670', '형이비인후과 이비인후과', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '현대백화점 무역센터점 /영캐주얼', '현대백화\n",
      "['2017-12-29'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column indicates the date of each visit log. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas library to group the data by date and count the number of occurrences for each date. Then, we can sort the results in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the dataframe from the provided data\n",
      "df = pd.DataFrame({\n",
      "    'date': ['2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [7, 7, 8, 9, 10, 10, 10, 8, 8, 8, 8, 9, 17, 19, 20, 21, 8, 8, 9, 15, 15, 15, 15, 23, 22, 23, 23, 8, 8, 8, 9, 16, 16, 19, 19, 12, 12, 12, 13, 18],\n",
      "    'place_name': ['서울9호선 고속터미널역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울3호선 수서역 오금방면 9-1', '서울3호선 가락시장역 대화방면 7-1', '서울9호선 고속터미널역 개화 방면 2-4', 'THE FACE SHOP 신세계강남점', '서울3호선 고속터미널역 대화방면 5-1', '서울9호선 증미역 종합운동장 방면 2-4', '서울9호선 신논현역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울9호선 봉은사역 종합운동장 방면 2-4', '서울9호선 종합운동장역 (급행)김포공항 방면 1-1/ 종합운동장 방면 1-1', '왓포마사지 성내1호점', '스타벅스 길동사거리점', '스타벅스 길동사거리점', '이마트 가양점 /식품/비식품', '서울9호선 증미역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울9호선 신논현역 종합운동장 방면 2-4', '서울2호선 교대역 내선 7-1', '서울2호선 서초역 내선 7-1', '서울2호선 잠실역 내선 7-1', '서울2호선 종합운동장역 내선 7-1', '애플짐휘트니스클럽', '애플짐휘트니스클럽', '애플짐휘트니스클럽', '부에노커피', '서울9호선 증미역 종합운동장 방면 2-4', '서울9호선 여의도역 종합운동장 방면 2-4', '서울9호선 선유도역 종합운동장 방면 2-4', '서울9호선 종합운동장역 (급행)김포공항 방면 1-1/ 종합운동장 방면 1-1', '서울2호선 강남역 내선 5-1', '강남역지하\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-21', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04'],\n",
      "    'hour': [13, 14, 9, 9, 10, 16, 17, 18, 19, 13, 13, 13, 15, 21, 11, 11, 13, 22, 16, 19, 10, 10, 11, 16, 17, 18, 19, 19, 11, 15, 16, 22, 22, 23, 6, 12, 14, 20, 18, 21],\n",
      "    'place_name': ['던킨도너츠 시청역점', '이얼싼중국문화원', '삼백집 잠실직영점', '라뷰티폼', 'E1LPG 홍익에너지', 'NC백화점 송파점/코코몽키즈랜드 NC백화점송파점', 'NC백화점 송파점/코코몽키즈랜드 NC백화점송파점', 'NC백화점 송파점/코코몽키즈랜드 NC백화점송파점', '다이소 송파파크하비오점', '맛있는집기사식당', '오키즈랜드', 'P문어세상', '오키즈랜드', 'LG유플러스 문정역점', '망고식스 신사점', '서울3호선 대청역 대화방면 3-1', '서울3호선 양재역 오금방면 5-1', '서울3호선 대청역 오금방면 7-1', '우체국 서울강남점', '이마트 에브리데이 개포점', '도르라스피닝', '서울3호선 수서역 오금방면 9-1', '도르라스피닝', '롯데마트 잠실점 /비식품코너', '자연별곡 잠실웰빙점', '자연별곡 잠실웰빙점', 'GS25 S종합운동장역점', 'CU 서울매트로종합운동장역점', '롯데리아 언더랜드점', 'NC백화점 송파점 /영캐주얼', 'NC백화점 송파점 /엔씨픽스', '윤호프', '성실부동산', '서울플라워', 'CU 송파한화1호점', '리바트 강동전시장점', '우체국 서울강남점', '서울3호선 대청역 오금방면 10-4', '타이어프로 석촌점', '세븐일레븐 롯데월드테마광장점'],\n",
      "    'place_category': ['Others(Bakery/Desert)', 'Foreign Language institute', 'Korean Food Restaurants', 'Hair Salon', 'Gas stations', 'Kids Cafe', 'Kids Cafe', 'Kids Cafe', 'Household Goods', 'Korean Food Restaurants', 'Kids Cafe', 'Korean Food Restaurants', 'Kids Cafe', 'Mobile Phone Shop', 'Juice Shop', 'Subway Station', 'Subway Station', 'Subway Station', 'Post Office', 'Supermarket', 'Others(Sports Academy)', 'Subway Station', 'Others(Sports Academy)', 'Discount Department Store', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Convenience Store', 'Convenience Store', 'Burger/Sandwich', 'Department Store', 'Department Store', 'Bar', 'Real Estate Agency', 'Flower Shop', 'Convenience Store', 'Furniture Shop', 'Post Office', 'Subway Station', 'Auto Repair Shop', 'Convenience Store'],\n",
      "    'place_address': ['서울 중구 태평로2가 360-1', '서울 중구 태평로2가 360-1', '서울 송파구 석촌동 183-9', '서울 송파구 송파동 7-1', '서울 송파구 석촌동 183-1', '서울 송파구 문정동 634', '서울 송파구 문정동 634', '서울 송\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the \"date\" column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the results in descending order and select the date with the highest visit count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-19', '2017-12-19', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [12, 12, 17, 18, 19, 19, 10, 20, 9, 9, 18, 18, 19, 19, 10, 16, 18, 18, 19, 19, 21, 21, 10, 10, 18, 18, 19, 9, 9, 9, 9, 10, 20, 20, 10, 16, 16, 21, 21, 21],\n",
      "    'place_name': ['서울4호선 노원역 오이도방면 3-1', '롯데백화점 노원점 /식품', '스타필드 코엑스몰점 /에잇세컨즈/스튜디오톰보이', '스타필드 코엑스몰점/STUDIO TOMBOY', '서울2호선 삼성역 내선 3-1 / 외선 8-4', '서울2호선 종합운동장역 외선 7-1', '빽다방 서울교대점', '서울3호선 교대역 오금방면 7-1', '서울3호선 고속터미널역 오금방면 5-1', '서울7호선 고속터미널역 부평구청 방면 2-2', 'KT 교대역점', '서울3호선 교대역 대화방면 3-1', '서울7호선 고속터미널역 장암 방면 4-4', '서울3호선 고속터미널역 대화방면 7-1', 'CU 메트로교대점', '서울3호선 교대역 오금방면 9-1', '망고식스 강남파이낸스센터점', '버거킹 강남파이낸스점', '서울2호선 역삼역 외선 3-1', '서울2호선 종합운동장역 외선 3-1', '서울7호선 건대입구역 장암 방면 4-4', '서울7호선 건대입구역 장암 방면 6-4', '서울7호선 군자역 부평구청 방면 2-2', '서울7호선 중곡역 부평구청 방면 2-2', '서울3호선 교대역 오금방면 7-1', '서울3호선 교대역 대화방면 5-1', '서울7호선 고속터미널역 장암 방면 6-4', '서울7호선 건대입구역 부평구청 방면 2-2', '서울7호선 상봉역 부평구청 방면 5-1', '서울7호선 반포역 부평구청 방면 2-2', '서울7호선 면목역 부평구청 방면 4-4', '맥도날드 서울교대점', '서울3호선 고속\n",
      "['2018-01-02'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the counts in descending order and select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-24', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [0, 12, 13, 8, 17, 18, 21, 11, 13, 22, 21, 22, 11, 15, 18, 12, 13, 14, 15, 16, 19, 11, 15, 18, 19, 9, 13, 15, 16, 20, 21, 10, 11, 12, 13, 10, 14, 21, 11, 12],\n",
      "    'place_name': ['커피래브러토리 건대본점', '하나로마트 청담점', '올리브영 가로수길점', '스타벅스 삼성현대힐점', '투썸플레이스 강남도산점', '세븐일레븐 압구정로데오점', '뚜레쥬르 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', 'CGV 청담씨네시티점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '죠스떡볶이 학동사거리점', '분당선 강남구청역 수원방면 2-2', '파리바게뜨 센트럴시티점', '스타벅스 강남구청역점', '분당선 선릉역 수원방면 2-2', '교보문고 강남점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '롯데월드몰/수하동 롯데월드몰점', '롯데월드몰/반디앤루니스 롯데월드몰점', '스타벅스 강남구청역점', '스타벅스 삼성역점', '뚜레쥬르 강남구청역점', 'ZADIG&VOLTAIRE 청담점', '스타벅스 강남구청정문점', '스타벅스 강남구청정문점', '박승철헤어스투디오 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '스타벅스 강남구청역점', '스타벅스 삼성역점', '미니스톱 논현행운점', '스타벅스 강남구청역점', '스타벅스 강남구청역점'],\n",
      "    'place_category': ['Coffee Shop', 'Supermarket', 'Drug Store', 'Coffee Shop', 'Coffee Shop', 'Convenience Store', 'Bakery', 'Coffee Shop', 'Coffee Shop', 'Movie Theater', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Snack Bar', 'Subway Station', 'Bakery', 'Coffee Shop', 'Subway Station', 'Bookstore', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Korean Food Restaurants', 'Bookstore', 'Coffee Shop', 'Coffee Shop', 'Bakery', 'Clothing Store', 'Coffee Shop', 'Coffee Shop', 'Hair Salon', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Convenience Store', 'Coffee Shop', 'Coffee Shop'],\n",
      "    'place_address': ['서울 광진구 화양동 7-\n",
      "['2017-12-23'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. \n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-11', '2017-12-11', '2017-12-11', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2018-01-02', '2018-01-05'],\n",
      "    'hour': [18, 19, 23, 15, 18, 8, 14, 15, 16, 17, 20, 21, 14, 16, 8, 8, 11, 12, 14, 14, 14, 18, 19, 19, 19, 20, 20, 21, 22, 13, 17, 18, 19, 8, 16, 18, 18, 18, 16, 18],\n",
      "    'place_name': ['서울4호선 회현역 당고개방면 3-1/오이도방면 8-4', '서울2호선 2968', '서울7호선 어린이대공원역 부평구청 방면 4-4', '서울4호선 4908', '서울4호선 4403', '서울4호선 4915', '서울6호선 6002', '교보문고 합정점', '서울6호선 6326', '버거킹 여의도점', '채선당 이수역점', '홈플러스 익스프레스 방배점', '버거킹 강남파이낸스점', '노아베이커리 역삼gfc점', '서울4호선 4025', '서울4호선 4812', '세븐일레븐 반포서래점', '버거킹 여의도점', '서울5호선 5605', '서울5호선 여의도역 상일동 마천행 / 6-4', '공항철도 공덕역 서울역방면 3-4', '스타필드 코엑스몰점 /SKINBAND/MIXXO', '스타필드 코엑스몰점/KOSNEY 코엑스도심공항점', '스타필드 코엑스몰점 /라템/더프트앤도프트', '스타필드 코엑스몰점 /롯데리아/사리현', '스타필드 코엑스몰점/사틴헤어 코엑스점', '스타필드 코엑스몰점 /공수간/CJFOODWOTLD', '스타필드 코엑스몰점/TWORLD', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '천주교방배동성당', '미스터피자 청계광장점', '스타벅스 종각점', '명동성당 /명동대성당', '서울4호선 4102', '서울1호선 311953', '파리바게뜨 서울적십자병원점', 'CU 강북삼성병원 2호점', 'SHILLA MYUNGGUA 신관/강북삼성병원점', '서울1호선 311972', '서울2호선 2619'],\n",
      "    'place_category': ['Subway Station', 'Subway Train', 'Subway Station', 'Subway Train', 'Subway Train', 'Subway Train', 'Subway Train', 'Bookstore', 'Subway Train', 'Burger/Sandwich', 'Others(Restaurants)', 'Supermarket', 'Burger/Sandwich', 'Bakery', 'Subway Train', 'Subway Train', 'Convenience Store', 'Burger/Sandwich', 'Subway Train', 'Subway Station', 'Subway Station', 'Outlet/ Shopping Mall', 'Interior Decoration', 'Outlet/ Shopping Mall', 'Outlet/ Shopping Mall', 'Hair Salon', 'Outlet/ Shopping Mall', 'Mobile Phone Shop', 'Movie Theater', 'Catholic Church', 'Pizza', 'Coffee Shop', 'Catholic Church', 'Subway Train', 'Subway Train', 'Bakery', 'Convenience Store', 'Bakery', 'Subway Train', 'Subway Train'],\n",
      "    'place_address': ['서울 중구 회현동1가 194-69', '서울 중구 봉래동2가 122-21', '서울 광진구 능동 463-1', '서울 중구 봉래동2가 122-21', '서울 중구 봉래동2가 122-21', '서울 중구\n",
      "['2017-12-16'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the \"date\" column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05', '2018-01-06'],\n",
      "    'hour': [12, 18, 12, 13, 13, 16, 16, 16, 5, 13, 5, 5, 5, 5, 14, 5, 18, 8, 18, 18, 18, 5, 5, 13, 5, 10, 10, 11, 14, 15, 5, 22, 19, 5, 5, 10, 13, 5, 5, 5],\n",
      "    'place_name': ['천주교잠원동성당', '천주교잠원동성당', 'KEB하나은행 서압구정지점', '스타필드 코엑스몰점/TWORLD', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '스타필드 코엑스몰점/Quiznos 코엑스점', '스타필드 코엑스몰점/메가박스 코엑스몰점/스낵바', '마리아홀리기프트 /책cd', '천주교잠원동성당', '서울3호선 잠원역 오금방면 5-1', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '아이파크몰/이화수전통육개장 용산아이파크점', '천주교잠원동성당', '뉴코아아울렛 강남점 1관 /킴스푸드스트리트', '뉴코아아울렛 강남점 3관/킴스클럽 강남점', '뉴코아아울렛 강남점 2관/킴스클럽 강남점', '천주교잠원동성당', '천주교잠원동성당', '열린성모이비인후과의원 이비인후과', '천주교잠원동성당', 'Monsieur', '사자헤어', '버거킹 압구정로데오점', '누베베한의원 /한의원', '서울3호선 교대역 대화방면 3-1', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당', '파리바게뜨 잠원역점', '천주교잠원동성당', '천주교잠원동성당', '천주교잠원동성당'],\n",
      "    'place_category': ['Catholic Church', 'Catholic Church', 'Bank', 'Mobile Phone Shop', 'Movie Theater', 'Burger/Sandwich', 'Movie Theater', 'Others(Retail)', 'Catholic Church', 'Subway Station', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Korean Food Restaurants', 'Catholic Church', 'Outlet/ Shopping Mall', 'Supermarket', 'Supermarket', 'Catholic Church', 'Catholic Church', 'Otolaryngology Clinic', 'Catholic Church', 'Clothing Store', 'Hair Salon', 'Burger/Sandwich', 'Oriental Medical Clinic', 'Subway Station', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Catholic Church', 'Bakery', 'Catholic Church', 'Catholic Church', 'Catholic Church'],\n",
      "    'place_address': ['서울 서초구 잠원동 65-7', '서울 서초구 잠원동 65-7', '서울 강남구 신사동 579', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159', '서울 강남구 삼성동 159', '서울 강남구 청담동 76', '서울 서초구 잠원동 65-7', '서울 서초구 잠원동 100-1', '서울 서초구 잠원동 65-7', '서울 서초구 잠원동 65\n",
      "['2017-12-18'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the \"date\" column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-14', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-17', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [19, 8, 17, 11, 13, 13, 14, 7, 7, 18, 19, 8, 18, 19, 7, 18, 18, 14, 15, 15, 15, 17, 18, 14, 14, 14, 7, 7, 7, 19, 7, 7, 18, 7, 19, 19, 7, 7, 19, 20],\n",
      "    'place_name': ['분당선 351441', '서울8호선 석촌역 모란방면 4-4', '분당선 351235', '연세크리스마스치과 치과', '스타벅스 방배역점', '맥도날드 방배점', \"O'Fete 방배점\", '분당선 도곡역 /수원방면3-4', '분당선 선릉역 수원방면 2-2', '분당선 351432', '서울2호선 선릉역 내선 5-1', '분당선 대모산입구역 수원방면 2-2', '분당선 351431', '서울2호선 선릉역 내선 7-1', '분당선 선릉역 수원방면 2-2', '서울2호선 선릉역 내선 5-1', '분당선 351428', '너랑나랑즉석떡볶이', '삼성디지털프라자 방배점', '홈플러스 익스프레스 방배2점', '분당선 선정릉역 왕십리방면 5-3', '갤러리아백화점 명품관WEST/정관장 갤러리아백화점명품관WEST점', '투썸플레이스 청담CGV점', '던킨도너츠 방배역점', '다이소 방배점', '서울2호선 신림역 내선 4-4 / 외선 7-1', '분당선 개포동역 수원방면 5-3', '분당선 선릉역 수원방면 2-2', '분당선 대모산입구역 수원방면 2-2', '분당선 351329', '분당선 선릉역 수원방면 2-2', '분당선 선릉역 수원방면 2-2', '서울2호선 강남역 내선 5-1', '분당선 선릉역 왕십리방면 6-4', '서울2호선 교대역 내선 5-1', '서울2호선 선릉역 내선 5-1', '서울2호선 신림역 내선 9-3 / 외선 2-2', '분당선 선릉역 왕십리방면 6-4', '분당선 351342', '분당선 강남구청역 수원방면 3-4'],\n",
      "    'place_category': ['Subway Train', 'Subway Station', 'Subway Train', 'Dental Clinic', 'Coffee Shop', 'Burger/Sandwich', 'Others(Bakery/Desert)', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Train', 'Snack Bar', 'Electronics Shop', 'Supermarket', 'Subway Station', 'Health Additive Food Store', 'Coffee Shop', 'Others(Bakery/Desert)', 'Household Goods', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Train', 'Subway Station'],\n",
      "    'place_address': ['서울 중구 봉래동2가 122-21', '서울 송파구\n",
      "['2017-12-26'] 2017-12-29\n",
      "['2017-12-16'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-25', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-06'],\n",
      "    'hour': [17, 17, 17, 21, 12, 12, 13, 13, 14, 14, 15, 9, 22, 17, 18, 20, 9, 9, 9, 9, 10, 10, 16, 14, 15, 13, 13, 13, 14, 11, 11, 11, 12, 12, 15, 9, 9, 22, 22, 7],\n",
      "    'place_name': ['신세계백화점 강남점 /여성 컨템포러리', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '서울9호선 신논현역 종합운동장 방면 1-1', '서울9호선 봉은사역 개화 방면 4-4', '신세계백화점 강남점 /남성 정장/남성캐주얼', '신세계백화점 강남점 /여성 클래식', '신세계백화점 강남점 /생활', '신세계백화점 강남점 /남성 정장/남성캐주얼', '뉴코아아울렛 강남점 2관/설빙 서울강남이코아점', '뉴코아아울렛 강남점 1관/모던하우스 강남점', '뉴코아아울렛 강남점 2관/Cafe Lugo 반포점', '서울9호선 동작역 개화행 1-1', '서울9호선 당산역 개화방면 2-2/종합운동장방면 3-3', '신세계백화점 강남점 /영 캐주얼 핸드백', '신세계백화점 강남점/MOYNAT 신세계백화점 강남점', '스타벅스 센트럴시티점', '코스트코 양재점 /주류', '코스트코 양재점 /비식품', '코스트코 양재점 /식품', '코스트코 양재점 /비식품', '코스트코 양재점 /식품', '코스트코 양재점 /식품', '신세계백화점 강남점 /여성컨템포러리', '신세계 백화점 강남점/밀화', '신세계백화점 강남점 /전문식당가', '신세계 백화점 강남점/밀화', '신세계 백화점 강남점/평양면옥', '신세계백화점 강남점 /리틀신세계/\n",
      "['2017-12-23', '2018-01-04'] The key feature in the provided visit history data that could be useful in answering the question is the \"date\" column. This column represents the date of each visit log. \n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then identify the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-21', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05'],\n",
      "    'hour': [12, 16, 20, 8, 10, 14, 15, 16, 16, 17, 19, 19, 0, 18, 8, 8, 12, 20, 20, 12, 21, 18, 21, 8, 11, 16, 17, 18, 12, 18, 19, 20, 22, 17, 17, 18, 18, 20, 21, 17],\n",
      "    'place_name': ['SUPER COFFEE 선릉로점', 'CAFÉ des VERTS 선릉점', '아비꼬카레 신천점', 'CGV 천호점/매표소', 'CGV 천호점/매표소', '롯데백화점 잠실점 /식당가 외', '롯데백화점 잠실점 /식당가/금융센터', '롯데백화점 잠실점 /영케쥬얼 외', '롯데마트 잠실점/토이저러스 잠실점', '버거킹 송파구청점', \"롯데월드몰/KIEHL'S 롯데월드몰점\", '롯데시네마 잠실점/스낵', '하나미', '서울2호선 선릉역 외선 7-1', '서울2호선 종합운동장역 내선 5-1', 'CAFÉ des VERTS 선릉점', 'SUPER COFFEE 선릉로점', '스타필드 코엑스몰점/스타벅스 코엑스몰점', '스타필드 코엑스몰점 /헤지스/드코닝/더바디샵', 'SUPER COFFEE 선릉로점', '투썸플레이스 강남역중앙점', '롯데백화점 잠실점 /식품/푸드에비뉴', '멘야하나비 서울본점', '서울2호선 잠실새내역 내선 5-1', '장수가 선릉점', 'CAFÉ des VERTS 선릉점', 'JT친애저축은행 본점', '롯데마트 월드타워점 /비식품코너', '커피빈 테헤란로비젼타워점', '신순남부뚜막매운갈비찜', '신순남부뚜막매운갈비찜', '코리아당구클럽', '스타타워커피 석촌호수점', 'JT친애저축은행 본점', '서울2호선 선릉역 외선 7-1', '롯데마트 월드타워점 /비식품코너', '롯데마트 월드타워점 /식품코너/비식품코너', '장미B상가', 'CU 잠실장미점', 'CAFÉ des VERTS 선릉점'],\n",
      "    'place_category': ['Coffee Shop', 'Coffee Shop', 'Japanese Food Restaurants', 'Movie Theater', 'Movie Theater', 'Department Store', 'Department Store', 'Department Store', 'Game/Toy Store', 'Burger/Sandwich', 'Cosmetics Shop', 'Movie Theater', 'Others(Alchoholic Beverages)', 'Subway Station', 'Subway Station', 'Coffee Shop', 'Coffee Shop', 'Coffee Shop', 'Outlet/ Shopping Mall', 'Coffee Shop', 'Coffee Shop', 'Department Store', 'Japanese Food Restaurants', 'Subway Station', 'Korean Food Restaurants', 'Coffee Shop', 'Bank', 'Discount Department Store', 'Coffee Shop', 'Korean Food Restaurants', 'Korean Food Restaurants', 'Billiard', 'Coffee Shop', 'Bank', 'Subway Station', 'Discount Department Store', 'Discount Department Store', '\n",
      "['2017-12-15'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the solution:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-09', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-10', '2017-12-11', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-17', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-22', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-01'],\n",
      "    'hour': [11, 17, 18, 18, 19, 17, 17, 17, 17, 17, 17, 19, 21, 22, 22, 22, 7, 15, 15, 17, 14, 17, 15, 16, 16, 17, 17, 13, 19, 20, 15, 16, 17, 13, 16, 17, 12, 14, 15, 17],\n",
      "    'place_name': ['맥도날드 사당역점', '다이소 명동본점', '서울5호선 충정로역 방화행 2-4 / 상일동 마천행 6-4', '롯데영플라자 명동점/라인프렌즈 롯데백화점영플라자명동점', '이디야 마포경찰서점', 'YES24 강남점', 'YES24 강남점', 'YES24 강남점', '알라딘중고서점 강남점', '서울2호선 사당역 외선 3-1', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/메가박스 코엑스몰점', '서울9호선 봉은사역 개화 방면 2-4', '스타벅스 강남에비뉴점', '스타벅스 강남2점', '서울2호선 강남역 내선 3-1', '스타필드 코엑스몰점 /메가박스/클로리스/롭스', '스타필드 코엑스몰점/테라로사커피 코엑스몰', '분당선 선릉역 수원방면 2-2', '영락교회', '서울3호선 교대역 대화방면 5-1', '서울2호선 서울대입구역 내선 5-2 / 외선 6-2', '알라딘중고서점 강남점', '배스킨라빈스 강남역점', '배스킨라빈스 강남역점', '알라딘중고서점 강남점', '서울2호선 서울대입구역 내선 5-2 / 외선 6-2', '올리브영 강남본점', '스타벅스 가락시장역점', '서울2호선 서울대입구역 내선 5-2 / 외선 6-2', '서울4호선 사당역 당고개방면 7-1/오이도방면 4-4', '서울2호선 낙성대역 외선 9-2', '이디야 서울대중앙점', 'TWORLD PS&M1대리점', 'YES24 중고서점강남점', '서울2호선 신도림역 내선 4-4 / 외선 7-1', '스타벅스 명동미래점', '스타벅스 명동메트로점', '분당선 351237'],\n",
      "    'place_category': ['Burger/Sandwich', 'Household Goods', 'Subway Station', 'Stationery Shop', 'Coffee Shop', 'Bookstore', 'Bookstore', 'Bookstore', 'Bookstore', 'Subway Station', 'Movie Theater', 'Movie Theater', 'Movie Theater', 'Subway Station', 'Coffee Shop', 'Coffee Shop', 'Subway Station', 'Outlet/ Shopping Mall', '\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. We can then sort the results in descending order and select the date with the highest visit count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-09', '2017-12-09', '2017-12-11', '2017-12-12', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2018-01-01', '2018-01-01', '2018-01-02', '2018-01-02', '2018-01-05'],\n",
      "    'hour': [20, 23, 19, 16, 16, 12, 18, 19, 16, 17, 17, 19, 14, 22, 19, 19, 23, 15, 18, 16, 16, 17, 19, 14, 18, 19, 19, 22, 22, 11, 12, 22, 23, 19, 21, 19, 22, 20, 21, 22],\n",
      "    'place_name': ['설빙 성신여대점', '뚜레쥬르 종암점', 'SOOSA 미아사거리역점', '서울4호선 창동역 당고개방면 3-1', '서울1호선 도봉산역 소요산행 5-1', '서울1호선 도봉산역 소요산행 5-1', '엣지코인노래', '맥도날드 종암SK점', '미니스톱 고대원룸점', 'nanacake 성신여대점', '슈퍼보드', '미니스톱 고대원룸점', '서울1호선 도봉산역 소요산행 5-1', '미니스톱 종암아이파크점', '뚜레쥬르 종암점', '엣지코인노래', 'CU 종암행복점', '교보문고 수유바로드림센터점', '교보문고 수유바로드림센터점', '엣지코인노래', 'O.S.T 성신여대점', '락큐포켓볼', 'KFC 돈암동1호점', '맥도날드 종암SK점', '교보문고 광화문점', '서울4호선 동대문역사문화공원역 당고개방면 9-1/오이도방면 2-4', '엣지코인노래', '엣지코인노래', 'ARTBOX 성신여대점', 'KB국민은행 종암동지점', '맥도날드 종암SK점', '서울6호선 신당역 봉화산행 5-2 / 응암순환행 4-3', '미니스톱 고대원룸점', '엣지코인노래', 'KFC 돈암동1호점', 'KB국민은행 종암동지점', 'GS25 종암파크점', '피자스쿨 종암점', '맥도날드 종암SK점', '미니스톱 종암아이파크점'],\n",
      "    'place_category': ['Icecream Shop', 'Bakery', 'Japanese Food Restaurants', 'Subway Station', 'Subway Station', 'Subway Station', 'Karaoke', 'Burger/Sandwich', 'Convenience Store', 'Others(Bakery/Desert)', 'Theme Cafe', 'Convenience Store', 'Subway Station', 'Convenience Store', 'Bakery', 'Karaoke', 'Convenience Store', 'Bookstore', 'Bookstore', 'Karaoke', 'Jewellery Accessory Store', 'Billiard', 'Burger/Sandwich', 'Burger/Sandwich', 'Bookstore', 'Subway Station', 'Karaoke', 'Karaoke', 'Stationery Shop', 'Bank', 'Burger/Sandwich', 'Subway Station', 'Convenience Store', 'Karaoke', 'Burger/Sandwich', 'Bank', 'Convenience Store', 'Pizza', 'Burger/Sandwich', 'Convenience Store'],\n",
      "    'place_address': ['서울 성북구 동선동1가 26', '서울 성북구 종암동 25-28', '서울 강북구 미아동 1364', '서울 도봉구 창동 20', '서울 도봉구 도봉동 305-3', '서울 도봉구 도봉동 305-3', '서울 성북구 동선동1가 4-3', '서울 성북구 종암동 10-15번지', '서울 성북구 종암동 24-20', '서울 성북구 동선동2가 12', '서울\n",
      "['2017-12-24'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. To find the date with the most visits, we need to count the number of visits for each date and then identify the date with the highest count.\n",
      "['2017-12-13'] The key feature that could be useful in answering the question is the \"date\" column in the visit history dataframe. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can use the value_counts() function on the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-23', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-05'],\n",
      "    'hour': [9, 9, 10, 10, 10, 11, 12, 17, 17, 18, 7, 18, 18, 12, 14, 18, 11, 13, 7, 19, 19, 7, 7, 20, 11, 11, 19, 10, 10, 13, 19, 20, 20, 6, 6, 20, 13, 20, 21, 19],\n",
      "    'place_name': ['스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점/메가박스 코엑스몰점/매표소', '스타필드 코엑스몰점/헌혈의집 코엑스몰점', '스타필드 코엑스몰점 /메가박스/아담/영풍문고', '스타필드 코엑스몰점/영풍문고 스타필드코엑스몰점', '스타필드 코엑스몰점 /아그라/영풍문고/케르반', '스타필드 코엑스몰점 /럭키슈에뜨/아메리칸이글/별마당도서관', '이마트 마포점 /식품', '서울5호선 충정로역 방화행 7-3 / 상일동 마천행 2-1', '이마트 마포점 /식품', '서울6호선 공덕역 응암순환행 4-4', '서울5호선 영등포시장역 상일동 마천행 2-2', '서울5호선 영등포구청역 상일동 마천행 4-4', '충무식품', '마니마니슈퍼 삼각지점', '서울5호선 영등포구청역 상일동 마천행 6-4', '서울4호선 삼각지역 당고개방면 3-1', '서울6호선 삼각지역 봉화산행 7-1 / 응암순환행 2-4', '서울2호선 합정역 외선 3-1', '서울5호선 여의도역 상일동 마천행 / 2-2', '이마트 마포점 /식품', '서울6호선 공덕역 응암순환행 2-2', '서울2호선 합정역 외선 3-1', '서울5호선 여의도역 상일동 마천행 / 4-4', '서울6호선 효창공원앞역 봉화산행 3-1 / 응암순환행 6-4',\n",
      "['2017-12-15'] 2017-12-14\n",
      "['2018-01-04', '2017-12-29'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to find the date with the most visits.\n",
      "\n",
      "To determine the date with the most visits, we can count the number of occurrences of each date in the \"date\" column. We can then find the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-07', '2017-12-08', '2017-12-09', '2017-12-12', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-17', '2017-12-17', '2017-12-17', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-01', '2018-01-01', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-04'],\n",
      "    'hour': [17, 11, 15, 12, 18, 13, 13, 15, 10, 11, 13, 17, 19, 19, 17, 14, 14, 15, 14, 17, 17, 11, 14, 11, 13, 17, 12, 16, 16, 16, 19, 19, 20, 11, 18, 11, 12, 13, 13, 17],\n",
      "    'place_name': ['신촌세브란스병원 영상의학과', '천주교무악재성당', '천주교무악재성당', '한신약국', '롯데슈퍼 홍제2점', '롯데슈퍼 홍제2점', '한신약국', '은화실', '신촌세브란스병원 당일입원실A/B', '신촌세브란스병원 당일입원실A/B', '신촌세브란스병원 당일입원실A/B', '제일제면소 서울역사점', '롯데마트 서울역점 /식품', '롯데마트 서울역점 /비식품', '은화실', '빽다방/역전우동0410 동대문역점', '브라더상사', '서울3호선 종로3가역 대화행 3-2 / 오금행 8-3', '스타필드 코엑스몰점 /JUNO/Agreat cafe/도심공항타워', '서울2호선 잠실역 외선 3-1', '스타필드 코엑스몰점/별마당도서관', '스타벅스 구의역점', '서울3호선 안국역 대화행 5-1 / 오금행 6-4', '바오차이', '롯데슈퍼 홍제2점', '서울3호선 압구정역 대화방면 9-1', '오지현소아과의원 소아과', '오지현소아과의원 소아과', '한신약국', '롯데슈퍼 홍제2점', '롯데마트 서울역점 /비식품', '계절밥상 서울역사점', '롯데마트 서울역점 /비식품', '참좋은치과의원 치과', 'GS25 중구중림점', 'NC백화점 불광점 /문화센터소극장', '신촌세브란스병원 당뇨병센터', '우리은행 세브란스병원영업점', '신촌세브란스병원 알르레기천식센터', '롯데슈퍼 홍제2점'],\n",
      "    'place_category': ['General Hospital', 'Catholic Church', 'Catholic Church', 'Pharmacy', 'Supermarket', 'Supermarket', 'Pharmacy', 'Fine Arts Education', 'General Hospital', 'General Hospital', 'General Hospital', 'Korean Food Restaurants', 'Discount Department Store', 'Discount Department Store', 'Fine Arts Education', 'Japanese Food Restaurants', 'Others(Retail)', 'Subway Station', 'Outlet/ Shopping Mall', 'Subway Station', 'Library', 'Coffee Shop', 'Subway Station', 'Others(Restaurants)', 'Supermarket', 'Subway Station', 'Pediatric Hospital', 'Pediatric Hospital', 'Pharmacy', 'Supermarket', 'Discount Department Store', 'Korean Food Restaurants', 'Discount Department Store', 'Dental Clinic', 'Convenience Store', 'Department Store', 'General Hospital', 'Bank', 'General Hospital', 'Supermarket'],\n",
      "    'place_address': ['서울 서대문구 신촌동 134', '서울 서대문구 홍제2동 19', '서울 서대문구 홍제2동 19', '서울 서대문구 홍제동 469', '서울 서대문구 홍제동 469', '서울 서대문구 홍제동 469', '서울 서대문구 홍제동 469', '서울 서대문구 홍제동 459', '서울 서대문구 신촌동 134', '서울 서대문구 신촌동 134', '서울 서대문구 신촌동 134', '서울 중구 봉래동2가 122-21', '서울 중구 봉래동2가 122', '서울 중구 봉\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To do this, we can use the pandas groupby function to group the visit history by date and then count the number of visits for each date. Finally, we can find the date with the maximum number of visits.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-13', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-24', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2017-12-31', '2018-01-02', '2018-01-03', '2018-01-04'],\n",
      "    'hour': [19, 11, 21, 21, 16, 16, 0, 6, 6, 20, 16, 17, 20, 9, 9, 9, 19, 19, 7, 18, 12, 12, 15, 22, 16, 17, 17, 17, 18, 20, 21, 9, 9, 10, 12, 16, 17, 16, 16, 14],\n",
      "    'place_name': ['서울2호선 교대역 내선 3-1', '서울2호선 방배역 내선 3-1', '서울2호선 신도림역 내선 3-1 / 외선 8-4', '서울2호선 신림역 내선 9-3 / 외선 2-2', '서울4호선 동작역 당고개행 5-1', '참숯갈비', '서울2호선 사당역 외선 7-1', '서울2호선 방배역 내선 3-1', '서울1호선 신도림역 인천/신창방면 5-1', '서울2호선 신도림역 내선 8-4 / 외선 3-1', '파리바게뜨 방배역점', '서울3호선 교대역 대화방면 7-1', '황태와쭈꾸미 #본점', '아티제 중앙일보점', '서울4호선 사당역 당고개방면 3-1/오이도방면 8-4', '아티제 중앙일보점', '서울2호선 충정로역 내선 9-4 / 외선 2-1', '세븐일레븐 롯데월드테마광장점', '서울2호선 방배역 외선 9-1', '스타필드 코엑스몰점/HAZZYS 코엑스몰점', '신세계백화점 강남점 /남성 정장/남성캐주얼', '신세계백화점 강남점 /골프 아웃도어', '고마워케이크 센트럴시티점', '서울2호선 강변역 외선 5-1', '서울3호선 남부터미널역 대화방면 9-1', '행복한수약국', '수약국', 'NIKE 강남점', 'NIKE 강남점', 'NIKE 강남점', 'NIKE 강남점', '서울2호선 교대역 외선 7-1', '서울2호선 방배역 외선 9-1', '롯데시네마 월드타워점', '서울2호선 잠실역 내선 9-1', 'CU 서울메트로역삼역점', '신세계백화점 강남점 /남성 정장/남성캐주얼', '파리바게뜨 사당역점', '서울3호선 남부터미널역 대화방면 9-1', '허기훈내과'],\n",
      "    'place_category': ['Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Korean Food Restaurants', 'Subway Station', 'Subway Station', 'Subway Station', 'Subway Station', 'Bakery', 'Subway Station', 'Korean Food Restaurants', 'Others(Bakery/Desert)', 'Subway Station', 'Others(Bakery/Desert)', 'Subway Station', 'Convenience Store\n",
      "['2017-12-30'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the frequency of each date, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-22', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-23', '2017-12-25', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-28', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-01', '2018-01-03'],\n",
      "    'hour': [17, 15, 16, 16, 9, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 21, 17, 17, 17, 17, 16, 16, 16, 17, 17, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 13, 20],\n",
      "    'place_name': ['코스트코 양평점 /야채코너', '두리이비인후과 이비인후과', '갈릭화로 우장산점', '파리바게뜨 우장산역점', '세븐일레븐 화곡원룸점', '롯데몰 김포공항점/안스베이커리 롯데백화점김포공항점', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점/토이저러스 롯데백화점김포공항점', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /토이저러스 외', '롯데몰 김포공항점/봉추찜닭 김포롯데몰점', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /식품/세제/주방용품/청소용품/침구', '롯데마트 김포공항점 /토이저러스 외', '뚜레쥬르 우장산역점', '서울5호선 오목교역 방화행 6-4', '서울5호선 까치산역 방화행 6-4', 'ARITAUM 오목교역점', 'JY FITNESS', 'THE FACE SHOP 가양역직영점', '서울9호선 가양역 종합운동장 방면 2-4', 'CU 907가양역점', '서울9호선 봉은사역 종합운동장 방면 1-1', '서울9호선 선정릉역 종합운동장 방면 1-1', '스타필드\n",
      "['2018-01-03'] 2017-12-20\n",
      "['2017-12-14'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. By analyzing the \"date\" column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the \"date\" column and then select the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-11', '2017-12-11', '2017-12-12', '2017-12-12', '2017-12-13', '2017-12-13', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-14', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15', '2017-12-15'],\n",
      "    'hour': [11, 12, 14, 18, 11, 12, 11, 11, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 20, 20, 21, 22, 11, 11, 11, 12, 12, 13, 13, 13, 19, 19, 22, 23],\n",
      "    'place_name': ['스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', 'SEVEN MONKEYS COFFEE', '스타필드 코엑스몰점 /ZARA/A', '브루클린더버거조인트 삼성점', '브루클린더버거조인트 삼성점', '스타필드 코엑스몰점 /KERVAN/CJFOODWOTLD', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/cafe imt 코엑스몰점', '스타필드 코엑스몰점/Le Saigon 코엑스몰점', '스타필드 코엑스몰점/예가낙지마을', '오징어세상 삼성점', '스타필드 코엑스몰점 /반하는보쌈/ABC-mart/래핑차일드', '스타필드 코엑스몰점 /ZARA/A', '스타필드 코엑스몰점 /케이스겔러리/지오다노/초계국수', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /OYSHO/BUTTER', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /럭키슈에뜨/아메리칸이글/별마당도서관', '스타필드 코엑스몰점/UNIQLO 코엑스점', '스타필드 코엑스몰점 /베나코앤폰타나/트위/아르마니진', '스타필드 코엑스몰점 /토니모리/원더브라/올리브영', '오징어세상 삼성점', '서울야시장', '오징어세상 삼성점', '서울야시장', '서울야시장', '스타필드 코엑스몰점 /KFC/TableStar', '스타필드 코엑스몰점 /아그라/영풍문고/케르반', '스타필드 코엑스\n",
      "['2018-01-03'] 2017-12-18\n",
      "['2018-01-03'] The date with the most visits is 2017-12-27.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-20', '2018-01-03'] The key feature that could be useful in answering the question is the 'date' column in the visit history. By analyzing the 'date' column, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the occurrences of each date in the 'date' column and then identify the date with the highest count.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-15', '2017-12-15', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-16', '2017-12-18', '2017-12-18', '2017-12-19', '2017-12-19', '2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-22', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-29', '2017-12-30', '2017-12-30', '2017-12-30', '2017-12-31', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-02', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-03', '2018-01-04', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [10, 14, 9, 19, 19, 20, 9, 14, 10, 14, 18, 12, 15, 15, 15, 16, 9, 9, 9, 9, 9, 11, 12, 13, 9, 14, 19, 18, 9, 14, 17, 19, 9, 14, 16, 16, 16, 12, 9, 14],\n",
      "    'place_name': ['퍼스트약국', '퍼스트약국', '퍼스트약국', '롯데백화점 강남점 /여성패션', '롯데백화점 강남점 본관 /스포츠/수영복/점행사장', '롯데백화점 강남점 /디자이너/모피/란제리', '퍼스트약국', '퍼스트약국', '퍼스트약국', '퍼스트약국', '그 안에 맛있는  이탈리안', '롯데백화점 강남점 /해외패션/화장품/보석', '롯데백화점 강남점 본관 /남성패션', '롯데백화점 강남점 본관 /남성패션', '롯데백화점 강남점 /디자이너/모피/란제리', '롯데백화점 강남점 본관 /생활가전/서비스라운지', '퍼스트약국', '퍼스트약국', '퍼스트약국', '퍼스트약국', '연세up성형외과 성형외과', '연세up성형외과 성형외과', '하나로마트 대치점', '퍼스트약국', '퍼스트약국', '파낙스약국', '퍼스트약국', '스타필드 코엑스몰점/KERVAN 코엑스몰점', '퍼스트약국', '퍼스트약국', '하나로마트 대치점', '롯데백화점 강남점 본관 /식품/식당가', '퍼스트약국', '퍼스트약국', '파리바게뜨 대치역점', '공차 대치점', '퍼스트약국', 'NEW WAVE PILATES', '퍼스트약국', '퍼스트약국'],\n",
      "    'place_category': ['Pharmacy', 'Pharmacy', 'Pharmacy', 'Department Store', 'Department Store', 'Department Store', 'Pharmacy', 'Pharmacy', 'Pharmacy', 'Pharmacy', 'Others(Restaurants)', 'Department Store', 'Department Store', 'Department Store', 'Department Store', 'Department Store', 'Pharmacy', 'Pharmacy', 'Pharmacy', 'Pharmacy', 'Surgical Hospital', 'Surgical Hospital', 'Supermarket', 'Pharmacy', 'Pharmacy', 'Pharmacy', 'Pharmacy', 'Western Food Restaurants', 'Pharmacy', 'Pharmacy', 'Supermarket', 'Department Store', 'Pharmacy', 'Pharmacy', 'Bakery', 'Teahouse', 'Pharmacy', 'Others(Practice Facility)', 'Pharmacy', 'Pharmacy'],\n",
      "    'place_address': ['서울 강남구 대치동 507-2', '서울 강남구 대치동 507-2', '서울 강남구 대치동 507-2', '서울 강남구 대치동 937', '서울 강남구 대치동 937', '서울 강남구 대치동 937', '서울 강남구 대치1동 507-2', '서울 강남구 대치동 507-2', '서울 강남구 대치1동 507-2', '서울 강남구 대치1동 507-2', '서울 강남구 도곡동 467-29', '서울 강남구 대치동 937', '서울 강남구 대치동 937', '서울 강남구 대치동 937', '서울 강남구 대치동 937', '서울 강남구 대치동 937', '서울 강남구 대치동 507-2', '서울 강남구 대치동 507-2', '서울 강남구 대치1동 507-2', '서울 강남구 대치1동 507-2', '서울 강남구 신사동 579-6', '서울 강남구 신사동 579-6', '서울 강남구 대치동 511', '서울 강남구 대치1동 507-2', '서울 강남구 대치1동\n",
      "['2018-01-05'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" column in the visit history. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To do this, we can use the pandas groupby function to group the data by date and then count the number of visits for each date. Finally, we can find the date with the maximum number of visits.\n",
      "\n",
      "Here is the code to find the date with the most visits:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Create the visit history dataframe\n",
      "visit_history = pd.DataFrame({\n",
      "    'date': ['2017-12-19', '2017-12-20', '2017-12-20', '2017-12-20', '2017-12-21', '2017-12-21', '2017-12-21', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-22', '2017-12-24', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-25', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-26', '2017-12-30', '2017-12-30', '2017-12-30', '2018-01-01', '2018-01-03', '2018-01-04', '2018-01-04', '2018-01-04', '2018-01-05', '2018-01-05', '2018-01-05', '2018-01-05'],\n",
      "    'hour': [20, 12, 21, 21, 10, 18, 19, 11, 12, 19, 20, 20, 14, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 19, 11, 19, 20, 20, 16, 16, 17, 16, 19, 8, 11, 12, 11, 12, 19, 19],\n",
      "    'place_name': ['서울5호선 서대문역 방화행 4-4 / 상일동 마천행 4-4', 'OHUI LG광화문점', '서울5호선 서대문역 방화행 2-4 / 상일동 마천행 7-1', '버거킹 영등포KT점', 'Nature collection LG광화문사옥점', '김가네 정동점', '서울5호선 애오개역 방화행 2-2', '덕수궁피자', '할리스커피 광화문LG점', '아이파크몰 /디지털소형가전/토이하비/디지털관', '여로집 영등포본관/오징어볶음', '서울1호선 용산역 / 경의중앙선 용산역 동인천 천안급행 2-1 / 문산행 8-4', '버거킹 영등포KT점', '서울1호선 구일역 소요산행 7-1', '이철헤어커커 개봉역점', '타임스퀘어/나이키', '타임스퀘어/UNIQLO 타임스퀘어점', '타임스퀘어/모던하우스 타임스퀘어점', '타임스퀘어/MUJI 타임스퀘어점', '이마트 영등포점/일렉트로마트 영등포점', '이마트 영등포점 /식품 외', '이마트 영등포점/일렉트로마트 영등포점', '이마트 영등포점 /식품 외', '할리스커피 당산역점', '미스터피자 정동점', '타임스퀘어/오월의종&카페리브레 타임스퀘어점', '이마트 영등포점 /식품 외', '타임스퀘어/교보문고 영등포점', '현대백화점 디큐브시티점 /식품유플렉스', '현대백화점 디큐브시티점 /유플렉스 외', '현대백화점 디큐브시티\n",
      "['2017-12-31'] 2017-12-27\n",
      "json_wont\n",
      "['2018-01-02', '2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-19', '2018-01-04', '2018-01-03'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-18', '2018-01-01', '2018-01-02', '2018-01-03'] The date with the most visits is 2017-12-15.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-26', '2017-12-31'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-06'] The date with the most visits is 2017-12-06.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-11', '2017-12-12'] The date with the most visits is 2017-12-11.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-18', '2018-01-05'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-10'] The date with the most visits is 2017-12-10.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29', '2017-12-31'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-03.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-17'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-28', '2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-08'] The date with the most visits is 2017-12-08.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "['2018-01-04'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-17', '2017-12-23'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-10', '2017-12-26'] The date with the most visits is 2017-12-10.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-16', '2017-12-23', '2017-12-26', '2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-31', '2018-01-02', '2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-30', '2017-12-19'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] The date with the most visits is 2017-12-22.\n",
      "['2018-01-01'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-12'] The date with the most visits is 2017-12-12.\n",
      "['2018-01-03', '2018-01-05'] 2017-12-27\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-23', '2018-01-04'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-13'] The date with the most visits is 2017-12-13.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-14.\n",
      "['2018-01-04', '2017-12-29'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-23.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-18.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-27.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-12.\n",
      "['2017-12-20', '2018-01-03'] The date with the most visits is 2017-12-16.\n",
      "['2018-01-05'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-21', '2017-12-27'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "tabsep\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-28'] 2017-12-27\n",
      "['2017-12-19', '2018-01-04', '2018-01-03'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-18', '2018-01-01', '2018-01-02', '2018-01-03'] The date with the most visits is 2017-12-15.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-26', '2017-12-31'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-29'] The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-11', '2017-12-12'] The date with the most visits is 2017-12-11.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-18', '2018-01-05'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29', '2017-12-31'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] 2018-01-03\n",
      "['2018-01-05'] The date with the most visits can be determined by analyzing the visit history based on the \"date\" feature. By counting the number of visits for each date and selecting the date with the highest count, we can identify the date with the most visits.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-28', '2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-08'] The date with the most visits is 2017-12-08.\n",
      "['2018-01-04'] The date with the most visits is 2018-01-04.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-17', '2017-12-23'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-10', '2017-12-26'] The date with the most visits is 2017-12-10.\n",
      "['2017-12-27'] The key feature that could be useful in answering the question is the \"date\" feature. By analyzing the dates in the visit history, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we need to count the number of visits for each date and then identify the date with the highest count.\n",
      "\n",
      "Here is the answer: 2017-12-27\n",
      "['2017-12-15', '2017-12-16', '2017-12-23', '2017-12-26', '2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-05'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. By counting the number of visits for each date, we can identify the date with the highest visit count.\n",
      "\n",
      "Here is the analysis of the visit history:\n",
      "\n",
      "- 2018-01-03: 13 visits\n",
      "- 2018-01-04: 5 visits\n",
      "- 2018-01-05: 12 visits\n",
      "\n",
      "Based on the analysis, the date with the most visits is 2018-01-03, with a total of 13 visits.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-30', '2017-12-19'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-22.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] The date with the most visits is 2017-12-24.\n",
      "['2018-01-01'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-12'] The date with the most visits is 2017-12-12.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-23', '2018-01-04'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-13'] The date with the most visits is 2017-12-13.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-14.\n",
      "['2018-01-04', '2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-30'] 2017-12-28\n",
      "['2018-01-03'] The date with the most visits is 2017-12-18.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-27.\n",
      "['2018-01-02'] 2017-12-12\n",
      "['2017-12-20', '2018-01-03'] The date with the most visits is 2017-12-16.\n",
      "['2018-01-05'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-21', '2017-12-27'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-31'] 2017-12-27\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "commasep\n",
      "['2018-01-02', '2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-18'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "['2017-12-26'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "['2017-12-29'] To determine the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can identify the date with the highest count, which corresponds to the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-29.\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-19', '2018-01-04', '2018-01-03'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-31'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-27\".\n",
      "['2017-12-15', '2017-12-18', '2018-01-01', '2018-01-02', '2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "The date with the most visits is 2017-12-15.\n",
      "['2018-01-03'] To find the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "Here is the count of visits for each date:\n",
      "\n",
      "2017-12-26: 2 visits\n",
      "2017-12-27: 6 visits\n",
      "2017-12-28: 2 visits\n",
      "2017-12-29: 3 visits\n",
      "2017-12-31: 1 visit\n",
      "2018-01-01: 1 visit\n",
      "2018-01-02: 5 visits\n",
      "2018-01-03: 7 visits\n",
      "2018-01-04: 4 visits\n",
      "2018-01-05: 4 visits\n",
      "\n",
      "From the counts, we can see that the date with the most visits is 2018-01-03, with a total of 7 visits.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-03'] To find the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2018-01-03.\n",
      "['2017-12-27'] To determine the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-25\".\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-26', '2017-12-31'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. By counting the number of visits for each date, we can identify the date with the highest visit count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-31.\n",
      "['2017-12-06'] The date with the most visits is 2017-12-06.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "The date with the most visits is 2017-12-24.\n",
      "['2017-12-29'] The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-11', '2017-12-12'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-11\".\n",
      "['2017-12-18'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-23'] To determine the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can identify the date with the highest count, which corresponds to the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-27.\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-28\".\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "['2017-12-27'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-25'] To determine the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date.\n",
      "['2017-12-18', '2018-01-05'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2018-01-05.\n",
      "['2017-12-28'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2017-12-10'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-21'] To find the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can determine the date with the most visits.\n",
      "['2018-01-02'] To determine the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can identify the date with the most visits.\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] To find the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29', '2017-12-31'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and find the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-03.\n",
      "['2018-01-05'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. By counting the number of visits for each date, we can identify the date with the highest visit count.\n",
      "\n",
      "Here is the analysis of the visit history:\n",
      "\n",
      "- 2017-12-31: 1 visit\n",
      "- 2018-01-02: 5 visits\n",
      "- 2018-01-03: 10 visits\n",
      "- 2018-01-04: 6 visits\n",
      "- 2018-01-05: 8 visits\n",
      "\n",
      "Based on the analysis, the date with the most visits is 2018-01-03, with a total of 10 visits.\n",
      "['2017-12-29'] To find the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date format is in \"year-month-day\".\n",
      "['2017-12-21'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we need to count the number of visits for each date in the visit history.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-23'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2017-12-25'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-25.\n",
      "['2017-12-17'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-28', '2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] To determine the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can identify the date with the highest count, which corresponds to the date with the most visits.\n",
      "\n",
      "Here is the visit count for each date:\n",
      "\n",
      "2017-12-21: 1 visit\n",
      "2017-12-22: 1 visit\n",
      "2017-12-23: 3 visits\n",
      "2017-12-24: 5 visits\n",
      "2017-12-25: 1 visit\n",
      "2017-12-26: 3 visits\n",
      "2017-12-27: 3 visits\n",
      "2017-12-28: 1 visit\n",
      "2017-12-29: 3 visits\n",
      "2017-12-30: 5 visits\n",
      "2018-01-01: 1 visit\n",
      "2018-01-02: 5 visits\n",
      "2018-01-03: 3 visits\n",
      "2018-01-04: 3 visits\n",
      "2018-01-05: 2 visits\n",
      "\n",
      "From the above count, we can see that the date with the most visits is 2017-12-24, with a total of 5 visits.\n",
      "['2017-12-08'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "The date with the most visits is 2017-12-08.\n",
      "['2017-12-22'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we can count the number of occurrences of each date in the visit history and then identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-22\".\n",
      "['2018-01-04'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2017-12-21'] The key feature that could be useful in answering the question is the \"date\" feature. By analyzing the dates in the visit history, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we need to count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-21\".\n",
      "['2017-12-30'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-17', '2017-12-23'] To find the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences of each date, we can determine the date with the most visits.\n",
      "['2017-12-10', '2017-12-26'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-10.\n",
      "['2017-12-27'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-15', '2017-12-16', '2017-12-23', '2017-12-26', '2017-12-29'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-31', '2018-01-02', '2018-01-05'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2018-01-05\".\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-05'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2018-01-05.\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-30', '2017-12-19'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-25'] To find the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-25.\n",
      "['2017-12-21'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-21\".\n",
      "['2017-12-18'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-16'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "['2017-12-29'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. By counting the number of logs for each date, we can identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-29.\n",
      "['2017-12-26'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-24.\n",
      "['2017-12-27'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-27.\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] To determine the date with the most visits, we need to analyze the \"date\" feature in the user's visit history. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-22.\n",
      "['2018-01-01'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-21'] The key feature that could be useful in answering the question is the \"date\" feature. We need to find the date with the most visits.\n",
      "['2018-01-03', '2018-01-05'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. By counting the number of logs for each date, we can identify the date with the highest visit count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2018-01-03.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-12'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-12.\n",
      "['2018-01-03', '2018-01-05'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2018-01-04.\n",
      "['2017-12-29'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-18'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-26'] To determine the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can identify the date with the highest count, which corresponds to the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-23', '2018-01-04'] To find the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-23.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-25'] To find the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-25.\n",
      "['2017-12-24'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-13'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-15'] To determine the date with the most visits, we need to count the number of visits for each date. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date with the highest count will be the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-15.\n",
      "['2018-01-04', '2017-12-29'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-30'] To find the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature.\n",
      "\n",
      "By counting the number of occurrences for each date, we can determine the date with the most visits.\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-14'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-14.\n",
      "['2017-12-30'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2018-01-03'] To determine the date with the most visits, we need to analyze the visit history based on the date feature. We can count the number of visits for each date and identify the date with the highest count.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is 2017-12-18.\n",
      "['2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2018-01-02'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-20', '2018-01-03'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "Based on the provided visit history, the date with the most visits is \"2017-12-16\".\n",
      "['2018-01-05'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "\n",
      "To answer the question, we need to analyze the \"date\" feature and count the occurrences of each date.\n",
      "['2017-12-21', '2017-12-27'] To determine the date with the most visits, we need to count the number of visits for each date in the visit history. The key feature that we need to focus on is the \"date\" feature. We can extract the date from each log and count the occurrences of each date. The date format is in \"year-month-day\" format.\n",
      "['2017-12-25'] The key feature that could be useful in answering the question is the \"date\" feature. We need to count the number of visits for each date and find the date with the most visits.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "totext\n",
      "['2018-01-02', '2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-19', '2018-01-04', '2018-01-03'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-18', '2018-01-01', '2018-01-02', '2018-01-03'] The date with the most visits is 2017-12-15.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-26', '2017-12-31'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-06'] The date with the most visits is 2017-12-06.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-11', '2017-12-12'] The date with the most visits is 2017-12-11.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-20.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-18', '2018-01-05'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-10'] The date with the most visits is 2017-12-10.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29', '2017-12-31'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-03.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-17'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-28', '2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-08'] The date with the most visits is 2017-12-08.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "['2018-01-04'] The date with the most visits is 2018-01-04.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-17', '2017-12-23'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-10', '2017-12-26'] The date with the most visits is 2017-12-10.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-16', '2017-12-23', '2017-12-26', '2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-31', '2018-01-02', '2018-01-05'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-30', '2017-12-19'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] The date with the most visits is 2017-12-24.\n",
      "['2018-01-01'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-12'] The date with the most visits is 2017-12-12.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-23.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-23', '2018-01-04'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-13'] The date with the most visits is 2017-12-13.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-14.\n",
      "['2018-01-04', '2017-12-29'] The date with the most visits is 2017-12-13.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-23.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-20.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-18.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-20', '2018-01-03'] The date with the most visits is 2017-12-20.\n",
      "['2018-01-05'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-21', '2017-12-27'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n",
      "totextvisited\n",
      "['2018-01-02', '2018-01-03'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-19', '2018-01-04', '2018-01-03'] The key features of the user's visit history that could be useful in answering the question are the visited dates and hours for each place. By analyzing the dates and hours, we can determine the date with the most visits.\n",
      "\n",
      "To find the date with the most visits, we need to count the number of visits for each date. Here is the count of visits for each date:\n",
      "\n",
      "- 2017-12-16: 2 visits\n",
      "- 2017-12-17: 1 visit\n",
      "- 2017-12-19: 2 visits\n",
      "- 2017-12-22: 2 visits\n",
      "- 2017-12-23: 2 visits\n",
      "- 2017-12-24: 1 visit\n",
      "- 2017-12-25: 1 visit\n",
      "- 2017-12-26: 3 visits\n",
      "- 2017-12-27: 1 visit\n",
      "- 2017-12-29: 3 visits\n",
      "- 2017-12-30: 2 visits\n",
      "- 2017-12-31: 2 visits\n",
      "- 2018-01-01: 1 visit\n",
      "- 2018-01-02: 2 visits\n",
      "- 2018-01-03: 3 visits\n",
      "- 2018-01-04: 4 visits\n",
      "- 2018-01-05: 1 visit\n",
      "\n",
      "From the count, we can see that the date with the most visits is 2018-01-04, with 4 visits.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-18', '2018-01-01', '2018-01-02', '2018-01-03'] The date with the most visits is 2017-12-15.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-26', '2017-12-31'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-06'] The date with the most visits is 2017-12-06.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-11', '2017-12-12'] The date with the most visits is 2017-12-11.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-18', '2018-01-05'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-10'] The date with the most visits is 2017-12-10.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-19.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05', '2018-01-04', '2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-12.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29', '2017-12-31'] The date with the most visits is 2017-12-29.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-04.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-17'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-28', '2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-24', '2017-12-30', '2018-01-02'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-08'] The date with the most visits is 2017-12-08.\n",
      "['2017-12-22'] The date with the most visits is 2018-01-04.\n",
      "['2018-01-04'] The date with the most visits is 2018-01-04.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-30.\n",
      "['2017-12-17', '2017-12-23'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-10', '2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-15', '2017-12-16', '2017-12-23', '2017-12-26', '2017-12-29'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-31', '2018-01-02', '2018-01-05'] The date with the most visits is 2018-01-02.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-05'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-30', '2017-12-19'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-28'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-27'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-24', '2017-12-25', '2018-01-04'] The date with the most visits is 2017-12-24.\n",
      "['2018-01-01'] The date with the most visits is 2017-12-31.\n",
      "['2017-12-21'] The date with the most visits is 2017-12-21.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-12.\n",
      "['2017-12-12'] The date with the most visits is 2017-12-12.\n",
      "['2018-01-03', '2018-01-05'] The date with the most visits is 2018-01-05.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-28.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-23.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-02'] The date with the most visits is 2018-01-02.\n",
      "['2017-12-23'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-18'] The date with the most visits is 2017-12-19.\n",
      "['2017-12-26'] The date with the most visits is 2017-12-26.\n",
      "['2017-12-16'] The date with the most visits is 2017-12-16.\n",
      "['2017-12-23', '2018-01-04'] The date with the most visits is 2017-12-23.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-15.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-24'] The date with the most visits is 2017-12-24.\n",
      "['2017-12-13'] The date with the most visits is 2017-12-13.\n",
      "['2017-12-15'] The date with the most visits is 2017-12-14.\n",
      "['2018-01-04', '2017-12-29'] The date with the most visits is 2017-12-17.\n",
      "['2017-12-29'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-23.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2017-12-14'] The date with the most visits is 2017-12-14.\n",
      "['2017-12-30'] The date with the most visits is 2017-12-28.\n",
      "['2018-01-03'] The date with the most visits is 2017-12-18.\n",
      "['2018-01-03'] The date with the most visits is 2018-01-03.\n",
      "['2018-01-02'] The date with the most visits is 2017-12-18.\n",
      "['2017-12-20', '2018-01-03'] The date with the most visits is 2017-12-20.\n",
      "['2018-01-05'] The date with the most visits is 2017-12-29.\n",
      "['2017-12-21', '2017-12-27'] The date with the most visits is 2017-12-21.\n",
      "['2017-12-25'] The date with the most visits is 2017-12-25.\n",
      "['2017-12-31'] The date with the most visits is 2017-12-27.\n",
      "['2017-12-22'] The date with the most visits is 2017-12-22.\n"
     ]
    }
   ],
   "source": [
    "# ds_most_visited_date_pred_dfloader_score = []\n",
    "oi_most_visited_date_pred_dfloader_wont_score = []\n",
    "# ds_most_visited_date_pred_json_score = []\n",
    "oi_most_visited_date_pred_json_wont_score = []\n",
    "oi_most_visited_date_pred_tabsep_score = []\n",
    "oi_most_visited_date_pred_commasep_score = []\n",
    "oi_most_visited_date_pred_totext_score = []\n",
    "oi_most_visited_date_pred_totextvisited_score = []\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(most_visited_date_ans, ds_most_visited_date_pred_dfloader):\n",
    "#     ds_most_visited_date_pred_dfloader_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi, ai==bi)\n",
    "        \n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(most_visited_date_ans, oi_most_visited_date_pred_dfloader_wont):\n",
    "    oi_most_visited_date_pred_dfloader_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(most_visited_date_ans, ds_most_visited_date_pred_json):\n",
    "#     ds_most_visited_date_pred_json_score.append(bi in ai)\n",
    "#     if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(most_visited_date_ans, oi_most_visited_date_pred_json_wont):\n",
    "    oi_most_visited_date_pred_json_wont_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(most_visited_date_ans, oi_most_visited_date_pred_tabsep):\n",
    "    oi_most_visited_date_pred_tabsep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(most_visited_date_ans, oi_most_visited_date_pred_commasep):\n",
    "    oi_most_visited_date_pred_commasep_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(most_visited_date_ans, oi_most_visited_date_pred_totext):\n",
    "    oi_most_visited_date_pred_totext_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)\n",
    "    \n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(most_visited_date_ans, oi_most_visited_date_pred_totextvisited):\n",
    "    oi_most_visited_date_pred_totextvisited_score.append(bi in ai)\n",
    "    if (bi in ai) == False : print(ai, bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "76ca2999-eb7a-459a-aed4-fef6f7a256cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16071428571428573\n",
      "0.0\n",
      "0.15178571428571427\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# print(sum(oi_most_visited_date_pred_dfloader_score)/user_number)\n",
    "print(sum(oi_most_visited_date_pred_dfloader_wont_score)/user_number)\n",
    "# print(sum(oi_most_visited_date_pred_json_score)/user_number)\n",
    "print(sum(oi_most_visited_date_pred_json_wont_score)/user_number)\n",
    "print(sum(oi_most_visited_date_pred_tabsep_score)/user_number)\n",
    "print(sum(oi_most_visited_date_pred_commasep_score)/user_number)\n",
    "print(sum(oi_most_visited_date_pred_totext_score)/user_number)\n",
    "print(sum(oi_most_visited_date_pred_totextvisited_score)/user_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "87ce83eb-337b-460a-b429-11a021aa41ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0 -------\n",
      "----- 1 -------\n",
      "----- 2 -------\n",
      "----- 3 -------\n",
      "----- 4 -------\n",
      "----- 5 -------\n",
      "----- 6 -------\n",
      "----- 7 -------\n",
      "----- 8 -------\n",
      "----- 9 -------\n",
      "----- 10 -------\n",
      "----- 11 -------\n",
      "----- 12 -------\n",
      "----- 13 -------\n",
      "----- 14 -------\n",
      "----- 15 -------\n",
      "----- 16 -------\n",
      "----- 17 -------\n",
      "----- 18 -------\n",
      "----- 19 -------\n",
      "----- 20 -------\n",
      "----- 21 -------\n",
      "----- 22 -------\n",
      "----- 23 -------\n",
      "----- 24 -------\n",
      "----- 25 -------\n",
      "----- 26 -------\n",
      "----- 27 -------\n",
      "----- 28 -------\n",
      "----- 29 -------\n",
      "----- 30 -------\n",
      "----- 31 -------\n",
      "----- 32 -------\n",
      "----- 33 -------\n",
      "----- 34 -------\n",
      "----- 35 -------\n",
      "----- 36 -------\n",
      "----- 37 -------\n",
      "----- 38 -------\n",
      "----- 39 -------\n",
      "----- 40 -------\n",
      "----- 41 -------\n",
      "----- 42 -------\n",
      "----- 43 -------\n",
      "----- 44 -------\n",
      "----- 45 -------\n",
      "----- 46 -------\n",
      "----- 47 -------\n",
      "----- 48 -------\n",
      "----- 49 -------\n",
      "----- 50 -------\n",
      "----- 51 -------\n",
      "----- 52 -------\n",
      "----- 53 -------\n",
      "----- 54 -------\n",
      "----- 55 -------\n",
      "----- 56 -------\n",
      "----- 57 -------\n",
      "----- 58 -------\n",
      "----- 59 -------\n",
      "----- 60 -------\n",
      "----- 61 -------\n",
      "----- 62 -------\n",
      "----- 63 -------\n",
      "----- 64 -------\n",
      "----- 65 -------\n",
      "----- 66 -------\n",
      "----- 67 -------\n",
      "----- 68 -------\n",
      "----- 69 -------\n",
      "----- 70 -------\n",
      "----- 71 -------\n",
      "----- 72 -------\n",
      "----- 73 -------\n",
      "----- 74 -------\n",
      "----- 75 -------\n",
      "----- 76 -------\n",
      "----- 77 -------\n",
      "----- 78 -------\n",
      "----- 79 -------\n",
      "----- 80 -------\n",
      "----- 81 -------\n",
      "----- 82 -------\n",
      "----- 83 -------\n",
      "----- 84 -------\n",
      "----- 85 -------\n",
      "----- 86 -------\n",
      "----- 87 -------\n",
      "----- 88 -------\n",
      "----- 89 -------\n",
      "----- 90 -------\n",
      "----- 91 -------\n",
      "----- 92 -------\n",
      "----- 93 -------\n",
      "----- 94 -------\n",
      "----- 95 -------\n",
      "----- 96 -------\n",
      "----- 97 -------\n",
      "----- 98 -------\n",
      "----- 99 -------\n",
      "----- 100 -------\n",
      "----- 101 -------\n",
      "----- 102 -------\n",
      "----- 103 -------\n",
      "----- 104 -------\n",
      "----- 105 -------\n",
      "----- 106 -------\n",
      "----- 107 -------\n",
      "----- 108 -------\n",
      "----- 109 -------\n",
      "----- 110 -------\n",
      "----- 111 -------\n"
     ]
    }
   ],
   "source": [
    "# ds_most_visited_cat_pred_dfloader = []\n",
    "oi_most_visited_cat_pred_dfloader_wont = []\n",
    "# ds_most_visited_cat_pred_json = []\n",
    "oi_most_visited_cat_pred_json_wont = []\n",
    "oi_most_visited_cat_pred_tabsep = []\n",
    "oi_most_visited_cat_pred_commasep = []\n",
    "oi_most_visited_cat_pred_totext = []\n",
    "oi_most_visited_cat_pred_totextvisited = []\n",
    "\n",
    "\n",
    "system_prompt = 'You only answer in the following format: category. Don\\'t answer in a sentence.'\n",
    "\n",
    "user_prompt = 'The user\\'s visit history below is delimited by three backticks. Your goal is to answer the question \\'What is the most visited category?\\' If you have several categories, answer only one category. Look into the features of the user\\'s visit history and put emphasis on key features of the data that could be useful in answering the question.'\n",
    "\n",
    "\n",
    "system_prompt_dfloader = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "1. The visit history is in the format of pandas dataframe loader.    \n",
    "2. Each column name(index, date, hour, place_name, place_category, and place_address) is indicated before each colon and values are represented in a list format after each colon.\n",
    "3. The order of values in each list is kept the same, meaning that nth value in one list and nth value in another list are both included in the person’s one specific visit log information.\n",
    "''' + system_prompt\n",
    "      \n",
    "system_prompt_json = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "1. The visit history is in the format of JSON.\n",
    "2. The number before each colon before each dictionary format indicates the index number of the visit log and the dictionary format data after each colon includes each column name( index, date, hour, place_name, place_category, and place_address) and the value corresponding to the column. \n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_tabsep = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows:\n",
    "1. Each line contains one log of the visit history.\n",
    "2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "3. Each item that corresponds to each feature is separated by a tab.\n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_commasep = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "1. Each line contains one log of the visit history.\n",
    "2. Each line has 6 features (index, date, hour, place_name, place_category, place_address).\n",
    "3. Each item that corresponds to each feature is separated by a comma.\n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_totext = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "1. The visit history is in the text(sentence) format.\n",
    "2. In the sentence, each visit log is included in order of time. \n",
    "3. Each visit log includes date, hour, place_name, place_category, and place_address. \n",
    "''' + system_prompt\n",
    "    \n",
    "system_prompt_totextvisited = '''\n",
    "You will be provided with ''' + str(log_number) + ''' logs of a user’s visit history. The structure of the visit history is as follows: \n",
    "1. The visit history is in the text(sentence) format.\n",
    "2. In the sentence, for each place, its place_name, place_category, and place_address are followed by all visited dates and hours to the place. \n",
    "''' + system_prompt\n",
    "\n",
    "for i in range(user_number):\n",
    "    print('-----', i, '-------')\n",
    "    \n",
    "    user_log = pd.read_csv(f'./data/subtasks_temporal/user_log/user_log_{i}.csv')\n",
    "    user_log = user_log[-log_number:]\n",
    "    user_log.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # print('format 1')\n",
    "    # output, tok = oi_api(system_prompt_dfloader, user_prompt, dfloader(user_log))\n",
    "    # ds_most_visited_cat_pred_dfloader.append(output)\n",
    "    \n",
    "    # print('format 2')\n",
    "    output, tok = oi_api(system_prompt_dfloader, user_prompt, dfloader_wont(user_log))\n",
    "    oi_most_visited_cat_pred_dfloader_wont.append(output)\n",
    "    \n",
    "    # print('format 3')\n",
    "    # output, tok = gpt_api(system_prompt_json, user_prompt, json(user_log))\n",
    "    # ds_most_visited_cat_pred_json.append(output)\n",
    "    \n",
    "    # print('format 4')\n",
    "    output, tok = oi_api(system_prompt_json, user_prompt, json_wont(user_log))\n",
    "    oi_most_visited_cat_pred_json_wont.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_tabsep, user_prompt, tabsep(user_log))\n",
    "    oi_most_visited_cat_pred_tabsep.append(output)\n",
    "\n",
    "    output, tok = oi_api(system_prompt_commasep, user_prompt, commasep(user_log))\n",
    "    oi_most_visited_cat_pred_commasep.append(output)\n",
    "    \n",
    "    # print('format 5')\n",
    "    output, tok = oi_api(system_prompt_totext, user_prompt, totext(user_log))\n",
    "    oi_most_visited_cat_pred_totext.append(output)\n",
    "    \n",
    "    # print('format 6')\n",
    "    output, tok = oi_api(system_prompt_totextvisited, user_prompt, totextvisited(user_log))\n",
    "    oi_most_visited_cat_pred_totextvisited.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f41dd6e8-f03b-42c0-8e41-b221ee5e6d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfloader_wont\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] department store\n",
      "['subway train'] subway station\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['outlet/ shopping mall'] korean food restaurants\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station', 'outlet/ shopping mall'] coffee shop\n",
      "['subway station'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] furniture shop\n",
      "['real estate agency'] convenience store\n",
      "['subway station'] korean food restaurants\n",
      "['convenience store'] others(restaurants)\n",
      "['subway station'] chinese food restaurants\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['general hospital'] supermarket\n",
      "['subway station'] discount department store\n",
      "['discount department store'] dermatology clinic\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['pharmacy'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] convenience store\n",
      "['subway station'] coffee shop\n",
      "json_wont\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['general hospital'] supermarket\n",
      "['subway station'] discount department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "tabsep\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway train'] subway station\n",
      "['subway station'] subway train\n",
      "['subway station'] bookstore\n",
      "['general hospital'] supermarket\n",
      "['subway station'] discount department store\n",
      "['subway station'] korean food restaurants\n",
      "commasep\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['subway station'] subway train\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] furniture shop\n",
      "['convenience store'] others(restaurants)\n",
      "['subway train'] subway station\n",
      "['subway station'] subway train\n",
      "['subway station'] bookstore\n",
      "['general hospital'] supermarket\n",
      "['subway station'] discount department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] convenience store\n",
      "totext\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['coffee shop', 'outlet/ shopping mall'] convenience store\n",
      "['subway station'] clothing store\n",
      "['subway station'] coffee shop\n",
      "['subway train'] subway station\n",
      "['subway station'] restaurants\n",
      "['outlet/ shopping mall'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['outlet/ shopping mall'] convenience store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['karaoke'] akaraoke\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] convenience store\n",
      "['subway station'] coffee shop\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station', 'outlet/ shopping mall'] burger/sandwich\n",
      "['subway station'] department store\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] furniture shop\n",
      "['subway station'] korean food restaurants\n",
      "['convenience store'] others(restaurants)\n",
      "['subway train'] outlet/ shopping mall\n",
      "['subway station'] others(restaurants)\n",
      "['subway station'] convenience store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] bookstore\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet\n",
      "['general hospital'] supermarket\n",
      "['subway station'] bakery\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] convenience store\n",
      "['subway station'] cosmetics shop\n",
      "['others(restaurants)', 'discount department store'] restaurants\n",
      "totextvisited\n",
      "['subway station'] korean food restaurants\n",
      "['icecream shop'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['coffee shop', 'outlet/ shopping mall'] convenience store\n",
      "['physical fitness facility', 'discount department store'] others\n",
      "['internal medicine clinic'] chicken\n",
      "['subway station'] convenience store\n",
      "['subway station'] clothing store\n",
      "['protestant church'] movie theater\n",
      "['korean food restaurants'] restaurant\n",
      "['hair salon'] others(retail)\n",
      "['subway station'] restaurants\n",
      "['subway station'] subway train\n",
      "['subway train'] subway station\n",
      "['subway station'] restaurants\n",
      "['subway station'] coffee shop\n",
      "['coffee shop'] convenience store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet/ shopping mall\n",
      "['karaoke'] outlet/ shopping mall\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station', 'cosmetics shop'] clothing store\n",
      "['subway station'] shopping mall\n",
      "['discount department store'] outlet/ shopping mall\n",
      "['subway station'] clothing store\n",
      "['subway station'] outlet/ shopping mall\n",
      "['coffee shop', 'discount department store'] korean food restaurants\n",
      "['subway station', 'outlet/ shopping mall'] burger/sandwich\n",
      "['subway station'] restaurant\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] korean food restaurants\n",
      "['real estate agency'] convenience store\n",
      "['subway station'] korean food restaurants\n",
      "['convenience store'] others(restaurants)\n",
      "['subway station'] convenience store\n",
      "['subway train'] coffee shop\n",
      "['subway station'] restaurants\n",
      "['subway station'] chicken\n",
      "['subway station'] outlet/ shopping mall\n",
      "['subway station'] coffee shop\n",
      "['department store'] convenience store\n",
      "['subway train'] subway station\n",
      "['catholic church'] restaurant\n",
      "['subway station'] coffee shop\n",
      "['subway station'] coffee shop\n",
      "['subway station'] outlet\n",
      "['general hospital'] restaurant\n",
      "['subway station'] bakery\n",
      "['discount department store'] coffee shop\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] coffee shop\n",
      "['pharmacy'] department store\n",
      "['subway station'] korean food restaurants\n",
      "['subway station'] convenience store\n",
      "['subway station'] cosmetics shop\n",
      "['others(restaurants)', 'discount department store'] restaurants\n"
     ]
    }
   ],
   "source": [
    "# ds_most_visited_cat_pred_dfloader_score = []\n",
    "oi_most_visited_cat_pred_dfloader_wont_score = []\n",
    "# ds_most_visited_cat_pred_json_score = []\n",
    "oi_most_visited_cat_pred_json_wont_score = []\n",
    "oi_most_visited_cat_pred_tabsep_score = []\n",
    "oi_most_visited_cat_pred_commasep_score = []\n",
    "oi_most_visited_cat_pred_totext_score = []\n",
    "oi_most_visited_cat_pred_totextvisited_score = []\n",
    "\n",
    "# print('dfloader')\n",
    "# for ai, bi in zip(most_visited_cat_ans, ds_most_visited_cat_pred_dfloader):\n",
    "#     ds_most_visited_cat_pred_dfloader_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "#     if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('dfloader_wont')\n",
    "for ai, bi in zip(most_visited_cat_ans, oi_most_visited_cat_pred_dfloader_wont):\n",
    "    oi_most_visited_cat_pred_dfloader_wont_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "    \n",
    "\n",
    "# print('json')\n",
    "# for ai, bi in zip(most_visited_cat_ans, ds_most_visited_cat_pred_json):\n",
    "#     ds_most_visited_cat_pred_json_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "#     if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "    \n",
    "\n",
    "print('json_wont')\n",
    "for ai, bi in zip(most_visited_cat_ans, oi_most_visited_cat_pred_json_wont):\n",
    "    oi_most_visited_cat_pred_json_wont_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('tabsep')\n",
    "for ai, bi in zip(most_visited_cat_ans, oi_most_visited_cat_pred_tabsep):\n",
    "    oi_most_visited_cat_pred_tabsep_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('commasep')\n",
    "for ai, bi in zip(most_visited_cat_ans, oi_most_visited_cat_pred_commasep):\n",
    "    oi_most_visited_cat_pred_commasep_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('totext')\n",
    "for ai, bi in zip(most_visited_cat_ans, oi_most_visited_cat_pred_totext):\n",
    "    oi_most_visited_cat_pred_totext_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())\n",
    "\n",
    "\n",
    "print('totextvisited')\n",
    "for ai, bi in zip(most_visited_cat_ans, oi_most_visited_cat_pred_totextvisited):\n",
    "    oi_most_visited_cat_pred_totextvisited_score.append(bi.lower() in [x.lower() for x in ai])\n",
    "    if (bi.lower() in [x.lower() for x in ai]) == False : print([x.lower() for x in ai], bi.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c5467e1-f86a-4c34-b6a2-28597f6d7b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517857142857143\n",
      "0.7589285714285714\n",
      "0.7767857142857143\n",
      "0.7767857142857143\n",
      "0.5982142857142857\n",
      "0.48214285714285715\n"
     ]
    }
   ],
   "source": [
    "# print(sum(ds_most_visited_cat_pred_dfloader_score)/user_number)\n",
    "print(sum(oi_most_visited_cat_pred_dfloader_wont_score)/user_number)\n",
    "# print(sum(ds_most_visited_cat_pred_json_score)/user_number)\n",
    "print(sum(oi_most_visited_cat_pred_json_wont_score)/user_number)\n",
    "print(sum(oi_most_visited_cat_pred_tabsep_score)/user_number)\n",
    "print(sum(oi_most_visited_cat_pred_commasep_score)/user_number)\n",
    "print(sum(oi_most_visited_cat_pred_totext_score)/user_number)\n",
    "print(sum(oi_most_visited_cat_pred_totextvisited_score)/user_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
